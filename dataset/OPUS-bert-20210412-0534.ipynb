{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTALL\n",
    "- FAISS - \n",
    "- Sent2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "name = \"OPUS-bert-\"+ str(time.strftime(\"%Y%m%d-%H%M\"))\n",
    "\n",
    "!mkdir $name\n",
    "path = os.getcwd() + \"/\" + name\n",
    "os.chdir(path)\n",
    "\n",
    "!pwd\n",
    "\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.chdir(\"/home/lw/clc_fairseq/TED-20210121-1335\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/hoangtrungchinh/clc_data/raw/master/opus-100-corpus.zip\n",
    "!mkdir data_bin\n",
    "!unzip 'opus-100-corpus.zip' -d 'data_bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "en_files = sorted(glob.glob(\"data_bin/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"data_bin/*.vi\"))\n",
    "print(en_files)\n",
    "print(vi_files)\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "  with open(file) as file_in:\n",
    "    for line in file_in:\n",
    "      lst_en.append(line)\n",
    "\n",
    "for file in vi_files:\n",
    "  with open(file) as file_in:\n",
    "    for line in file_in:\n",
    "      lst_vi.append(line)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPLIT TRAIN, TEST, VALID\n",
    "from sklearn.model_selection import train_test_split\n",
    "en_train, en_test_valid, vi_train, vi_test_valid =  train_test_split(lst_en, lst_vi, test_size=0.2, random_state=123)\n",
    "en_valid, en_test, vi_valid, vi_test = train_test_split(en_test_valid, vi_test_valid, test_size=0.5, random_state=123)\n",
    "print(len(en_train))\n",
    "print(len(vi_train))\n",
    "print(len(en_valid))\n",
    "print(len(vi_valid))\n",
    "print(len(en_test))\n",
    "print(len(vi_test))\n",
    "print(en_train[20])\n",
    "print(vi_train[20])\n",
    "print(en_valid[-1])\n",
    "print(vi_valid[-1])\n",
    "print(en_test[-1])\n",
    "print(vi_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_variable = [en_train,vi_train,en_valid,vi_valid,en_test,vi_test]\n",
    "file_names = [\"en_train\",\"vi_train\",\"en_valid\",\"vi_valid\",\"en_test\",\"vi_test\"]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "  with open(file_names[i], 'w') as f:\n",
    "    for item in file_variable[i]:\n",
    "      f.write(item.strip() + \"\\n\")\n",
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('stsb-bert-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "srcfile = \"en_train\"\n",
    "tarfile = \"vi_train\"\n",
    "lst_srcfile = en_train\n",
    "lst_tarfile = vi_train\n",
    "\n",
    "vec_lst_srcfile = model.encode(lst_srcfile)\n",
    "print('=== Ending, Total time (second): ', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "vec_lst_srcfile_copy = vec_lst_srcfile.copy()\n",
    "start = time.time()\n",
    "index = faiss.IndexFlatIP(vec_lst_srcfile_copy.shape[1])\n",
    "index.ntotal\n",
    "faiss.normalize_L2(vec_lst_srcfile_copy)\n",
    "index.add(vec_lst_srcfile_copy)\n",
    "k = 6\n",
    "distance, index = index.search(vec_lst_srcfile_copy, k)\n",
    "\n",
    "print('=== Ending, Total time (second): ', time.time() - start)\n",
    "print(len(distance))\n",
    "print(len(index))\n",
    "\n",
    "print(index)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial import distance as dt\n",
    "\n",
    "count = 0\n",
    "for i in range(len(lst_srcfile)):\n",
    "    j = 1 #1 is index of biggest simmilarity\n",
    "    score = distance[i][j]\n",
    "    a = vec_lst_srcfile[i]\n",
    "    b = vec_lst_srcfile[index[i][j]]\n",
    "    \n",
    "    dot_product = np.dot(a, b) # x.y\n",
    "    norm_a = np.linalg.norm(a) #|x|\n",
    "    norm_b = np.linalg.norm(b) #|y|\n",
    "    sim_res = dot_product / (norm_a * norm_b)\n",
    "\n",
    "    if score >=0.98 :\n",
    "        count+=1\n",
    "        print(\"==========================\")\n",
    "        for m in range(len(index[i])):\n",
    "            print(\"--------\", distance[i][m])\n",
    "        print(i, index[i][j], distance[i][j], sim_res, 1-dt.cosine(a,b))\n",
    "        print(lst_srcfile[i])\n",
    "        print(lst_srcfile[index[i][j]])\n",
    "        print(\"==========================\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "saperate = \" || \"\n",
    "\n",
    "src_label = \"S\"\n",
    "emb_label = \"E\"\n",
    "thres_arr = [0.8, 0.85, 0.9, 0.95]\n",
    "for i in range(len(thres_arr)):\n",
    "    threshold = thres_arr[i]\n",
    "    out_file_write = open(\"en_train_EM_\"+str(thres_arr[i]), 'w')\n",
    "    out_file_write_score = open(\"en_train_EM_score_\"+str(thres_arr[i]), 'w')\n",
    "    out_file_write_factor = open(\"en_train_EM_factor_\"+str(thres_arr[i]), 'w')\n",
    "    num_gth_thres = 0\n",
    "\n",
    "    for i in range(len(lst_srcfile)):\n",
    "        j=5\n",
    "        score = distance[i][j]\n",
    "        content = \"\"\n",
    "        content_label_arr = []\n",
    "        if score >= threshold and score <0.999:\n",
    "            num_gth_thres += 1\n",
    "            best_simi_index = index[i][j]\n",
    "            content = lst_srcfile[i].strip() + saperate + lst_tarfile[best_simi_index].strip()\n",
    "\n",
    "            content_label = [src_label] * len(lst_srcfile[i].split())\n",
    "            content_label.append(emb_label)\n",
    "            content_label = content_label + [emb_label] * len(lst_tarfile[best_simi_index].split())\n",
    "\n",
    "            content_label_arr = \" \".join(content_label)\n",
    "        else:\n",
    "            content = lst_srcfile[i].strip()\n",
    "            content_label = [src_label] * len(lst_srcfile[i].split())\n",
    "            content_label_arr = \" \".join(content_label)\n",
    " \n",
    "        out_file_write.writelines(content+ \"\\n\")    \n",
    "        out_file_write_factor.writelines(content_label_arr + \"\\n\")\n",
    "        out_file_write_score.writelines(str(score) + \"\\n\")\n",
    "\n",
    "    print('threshold =', threshold, \"EM sentences =\", num_gth_thres, \"/\", len(lst_srcfile), num_gth_thres*100/len(lst_srcfile), \"%\" )\n",
    "\n",
    "    out_file_write.close()\n",
    "    out_file_write_score.close()\n",
    "    out_file_write_factor.close()\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print('=== Ending, Total time (second): ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lst_tarfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
