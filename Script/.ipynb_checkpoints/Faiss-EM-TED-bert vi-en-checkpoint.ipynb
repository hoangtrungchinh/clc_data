{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTALL\n",
    "- FAISS - \n",
    "- Sent2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "name = \"Faiss-EM-TED-bert-vi-en\"+ str(time.strftime(\"%Y%m%d-%H%M\"))\n",
    "\n",
    "!mkdir $name\n",
    "path = os.getcwd() + \"/\" + name\n",
    "os.chdir(path)\n",
    "\n",
    "!pwd\n",
    "\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.chdir(\"/home/lw/clc_fairseq/TED-20210121-1335\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/hoangtrungchinh/clc_data/raw/master/en_vi_iwslt.tar.gz\n",
    "!mkdir data_bin\n",
    "!tar -xvf  'en_vi_iwslt.tar.gz' -C 'data_bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "en_files = sorted(glob.glob(\"data_bin/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"data_bin/*.vi\"))\n",
    "print(en_files)\n",
    "print(vi_files)\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "  with open(file) as file_in:\n",
    "    for line in file_in:\n",
    "      lst_en.append(line)\n",
    "\n",
    "for file in vi_files:\n",
    "  with open(file) as file_in:\n",
    "    for line in file_in:\n",
    "      lst_vi.append(line)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPLIT TRAIN, TEST, VALID\n",
    "from sklearn.model_selection import train_test_split\n",
    "en_train, en_test_valid, vi_train, vi_test_valid =  train_test_split(lst_en, lst_vi, test_size=0.2, random_state=123)\n",
    "en_valid, en_test, vi_valid, vi_test = train_test_split(en_test_valid, vi_test_valid, test_size=0.5, random_state=123)\n",
    "print(len(en_train))\n",
    "print(len(vi_train))\n",
    "print(len(en_valid))\n",
    "print(len(vi_valid))\n",
    "print(len(en_test))\n",
    "print(len(vi_test))\n",
    "print(en_train[20])\n",
    "print(vi_train[20])\n",
    "print(en_valid[-1])\n",
    "print(vi_valid[-1])\n",
    "print(en_test[-1])\n",
    "print(vi_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_variable = [en_train,vi_train,en_valid,vi_valid,en_test,vi_test]\n",
    "file_names = [\"en_train\",\"vi_train\",\"en_valid\",\"vi_valid\",\"en_test\",\"vi_test\"]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "  with open(file_names[i], 'w') as f:\n",
    "    for item in file_variable[i]:\n",
    "      f.write(item)\n",
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('stsb-bert-large')\n",
    "# # model = SentenceTransformer('LaBSE')\n",
    "# #Sentences are encoded by calling model.encode()\n",
    "# emb1 = model.encode(\"This is a red cat with a hat.\")\n",
    "# emb2 = model.encode(\"Have you seen my red cat?\")\n",
    "\n",
    "# cos_sim = util.pytorch_cos_sim(emb1, emb2)\n",
    "# print(\"Cosine-Similarity:\", cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cos_sim.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "srcfile = \"vi_train\"\n",
    "tarfile = \"en_train\"\n",
    "# lst_srcfile = open(srcfile, \"r\").readlines()\n",
    "# lst_tarfile = open(tarfile, \"r\").readlines()\n",
    "lst_srcfile = vi_train\n",
    "lst_tarfile = en_train\n",
    "\n",
    "vec_lst_srcfile = model.encode(lst_srcfile)\n",
    "print('=== Ending, Total time (second): ', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Cosin similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "# print(vec_lst_srcfile.shape[1])\n",
    "start = time.time()\n",
    "index = faiss.IndexFlatL2(vec_lst_srcfile.shape[1])\n",
    "index.ntotal\n",
    "faiss.normalize_L2(vec_lst_srcfile)\n",
    "index.add(vec_lst_srcfile)\n",
    "k = 6\n",
    "distance, index = index.search(vec_lst_srcfile, k)\n",
    "\n",
    "print('=== Ending, Total time (second): ', time.time() - start)\n",
    "print(len(distance))\n",
    "print(len(index))\n",
    "\n",
    "print(index)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "j = k-1\n",
    "print(index[i][j])\n",
    "print(\"==================================\")\n",
    "print(distance[i][j])\n",
    "a = vec_lst_srcfile[i]\n",
    "# print(a)\n",
    "b = vec_lst_srcfile[index[i][j]]\n",
    "# TEST\n",
    "dist_squared = np.sum(np.square(a - b))\n",
    "print(dist_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "saperate = \" || \"\n",
    "\n",
    "src_label = \"S\"\n",
    "emb_label = \"E\"\n",
    "thres_arr = [0.9, 0.8, 0.7, 0.6]\n",
    "for i in range(len(thres_arr)):\n",
    "    threshold = thres_arr[i]\n",
    "    out_file_write = open(\"vi_train_EM_\"+str(thres_arr[i]), 'w')\n",
    "    out_file_write_score = open(\"vi_train_EM_score_\"+str(thres_arr[i]), 'w')\n",
    "    out_file_write_factor = open(\"vi_train_EM_factor_\"+str(thres_arr[i]), 'w')\n",
    "    num_gth_thres = 0\n",
    "\n",
    "    for i in range(len(lst_srcfile)):\n",
    "        score = distance[i][1]\n",
    "        content = \"\"\n",
    "        content_label_arr = []\n",
    "        if score >= threshold:\n",
    "            num_gth_thres += 1\n",
    "            best_simi_index = index[i][1]\n",
    "            content = lst_srcfile[i].strip() + saperate + lst_tarfile[best_simi_index].strip()\n",
    "\n",
    "            content_label = [src_label] * len(lst_srcfile[i].split())\n",
    "            content_label.append(emb_label)\n",
    "            content_label = content_label + [emb_label] * len(lst_tarfile[best_simi_index].split())\n",
    "\n",
    "            content_label_arr = \" \".join(content_label)\n",
    "        else:\n",
    "            content = lst_srcfile[i].strip()\n",
    "            content_label = [src_label] * len(lst_srcfile[i].split())\n",
    "            content_label_arr = \" \".join(content_label)\n",
    " \n",
    "        out_file_write.writelines(content+ \"\\n\")    \n",
    "        out_file_write_factor.writelines(content_label_arr + \"\\n\")\n",
    "        out_file_write_score.writelines(str(score) + \"\\n\")\n",
    "\n",
    "    print('threshold =', threshold, \"EM sentences =\", num_gth_thres, \"/\", len(lst_srcfile), num_gth_thres/len(lst_srcfile), \"%\" )\n",
    "\n",
    "    out_file_write.close()\n",
    "    out_file_write_score.close()\n",
    "    out_file_write_factor.close()\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print('=== Ending, Total time (second): ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
