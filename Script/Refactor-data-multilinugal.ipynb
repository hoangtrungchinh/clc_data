{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def is_containt_splcharacter(test):\n",
    "    string_check= re.compile('[@_#$&*<>/\\|}{~]')\n",
    "    return False if(string_check.search(test) == None) else True \n",
    "\n",
    "def is_containt_valid_character(test):\n",
    "    string_check= re.compile('[@_#$&*<>/\\|}{~]')\n",
    "    return False if(string_check.search(test) == None) else True \n",
    "\n",
    "def readfile(fp):\n",
    "    Lines = []\n",
    "    with open(fp) as file_in:\n",
    "        for line in file_in:\n",
    "            Lines.append(line.strip())    \n",
    "    return Lines\n",
    "\n",
    "def find_err_index(content):\n",
    "    error_line_index = []\n",
    "    count = 0\n",
    "    for i in range(len(content)):\n",
    "        l = content[i]\n",
    "        if is_containt_splcharacter(l)==True or len(l)<10:\n",
    "            error_line_index.append(i)\n",
    "            count+=1\n",
    "        \n",
    "    print(count)\n",
    "    return error_line_index\n",
    "\n",
    "def add_to_error_line():\n",
    "    count = 0\n",
    "    arr = []\n",
    "    for i in range(len(vi_cont)):\n",
    "        if vi_cont[i]==en_cont[i]:\n",
    "            count+=1\n",
    "            arr.append(i) \n",
    "    print(\"number the same lines:\", count)\n",
    "    return arr\n",
    "\n",
    "def remove_content(content):\n",
    "    new_content = []\n",
    "    for i in range(len(content)):\n",
    "        if i not in error_line_index_unique:\n",
    "            new_content.append(content[i])\n",
    "    return new_content\n",
    "\n",
    "def write_file(fp, content):\n",
    "    with open(fp+\"_ok\", \"wt\") as fw:\n",
    "        for i in range(len(content)):\n",
    "            fw.writelines(content[i])\n",
    "            fw.writelines(\"\\n\")\n",
    "\n",
    "def remove_content_with_index(content, index_arr):\n",
    "    new_content = []\n",
    "    for i in range(len(content)):\n",
    "        if i not in index_arr:\n",
    "            new_content.append(content[i])\n",
    "    return new_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def split_sentence(fp):\n",
    "    arr = []\n",
    "    cont = readfile(fp)\n",
    "    for i in range(len(cont)):\n",
    "        tmp = sent_tokenize(cont[i])\n",
    "        for j in range(len(tmp)):\n",
    "            arr.append(tmp[j])\n",
    "            \n",
    "    return arr, len(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81783\n",
      "75737\n",
      "number the same lines: 29018\n",
      "After join: 119258\n"
     ]
    }
   ],
   "source": [
    "file_path = [\"../NDT/1.en\", \"../NDT/1.vi\"]\n",
    "\n",
    "en_cont = readfile(\"../NDT/1.en\")\n",
    "error_line_en = find_err_index(en_cont)\n",
    "\n",
    "vi_cont = readfile(\"../NDT/1.vi\")\n",
    "error_line_vi = find_err_index(vi_cont)\n",
    "\n",
    "content = [en_cont, vi_cont]\n",
    "\n",
    "# Keep Unique index\n",
    "error_line_index_unique = list(dict.fromkeys(error_line_en + error_line_vi + add_to_error_line()))\n",
    "print(\"After join:\", len(error_line_index_unique))\n",
    "\n",
    "write_file(file_path[0], remove_content(en_cont))\n",
    "write_file(file_path[1], remove_content(vi_cont))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET LAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../law/CIVIL-CODE.en 2959\n",
      "../law/CODE-OF-CIVIL-PROCEDURE.en 3083\n",
      "../law/CRIMINAL-CODE.en 4922\n",
      "../law/CRIMINAL-PROCEDURE-CODE.en 2889\n",
      "../law/LABOR-CODE.en 1298\n",
      "../law/LAW-ON-ADMINISTRATIVE-PROCEDURES.en 2163\n",
      "../law/LAW-ON-BANKRUPTCY.en 877\n",
      "../law/LAW-ON-ORGANIZATION-OF-PEOPLE-COURTS.en 604\n",
      "../law/LAW-On-Support-for-Small--and-Medium-sized-Enterprises.en 228\n",
      "../law/Law-On-Foreign-Trade-Management.en 728\n",
      "../law/Law-on-Enterprises.en 1983\n",
      "../law/Law-on-organizing-the-government.en 271\n",
      "../law/LawOnImportDutyandExportDuty.en 191\n",
      "../law/ORGANIZATION-OF-PEOPLEтАЩS-PROCURACIES.en 657\n",
      "../law/ORGANIZATION-OF-THE-NATIONALASSEMBLY.en 508\n",
      "../law/VIETNAM-MARITIME-CODE.en 1860\n",
      "../law/lawland.en 1784\n",
      "../law/CIVIL-CODE.vi 2959\n",
      "../law/CODE-OF-CIVIL-PROCEDURE.vi 3083\n",
      "../law/CRIMINAL-CODE.vi 4922\n",
      "../law/CRIMINAL-PROCEDURE-CODE.vi 2889\n",
      "../law/LABOR-CODE.vi 1298\n",
      "../law/LAW-ON-ADMINISTRATIVE-PROCEDURES.vi 2163\n",
      "../law/LAW-ON-BANKRUPTCY.vi 877\n",
      "../law/LAW-ON-ORGANIZATION-OF-PEOPLE-COURTS.vi 604\n",
      "../law/LAW-On-Support-for-Small--and-Medium-sized-Enterprises.vi 228\n",
      "../law/Law-On-Foreign-Trade-Management.vi 728\n",
      "../law/Law-on-Enterprises.vi 1983\n",
      "../law/Law-on-organizing-the-government.vi 271\n",
      "../law/LawOnImportDutyandExportDuty.vi 191\n",
      "../law/ORGANIZATION-OF-PEOPLEтАЩS-PROCURACIES.vi 657\n",
      "../law/ORGANIZATION-OF-THE-NATIONALASSEMBLY.vi 508\n",
      "../law/VIETNAM-MARITIME-CODE.vi 1860\n",
      "../law/lawland.vi 1784\n",
      "27005\n",
      "27005\n"
     ]
    }
   ],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "en_files = sorted(glob.glob(\"../law/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"../law/*.vi\"))\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_en.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "for file in vi_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_vi.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15597\n"
     ]
    }
   ],
   "source": [
    "remove_index = []\n",
    "remove_sent_contain = [\"chapter\", \"section\", \"part\"]\n",
    "arr_lst = [lst_en, lst_vi]\n",
    "for k in arr_lst:\n",
    "    seen = []\n",
    "    for i in range(len(k)):\n",
    "        sent = k[i]\n",
    "        \n",
    "        if len(sent_tokenize(sent))!=1:\n",
    "            remove_index.append(i)\n",
    "        if any(ext in sent.lower() for ext in remove_sent_contain):\n",
    "            remove_index.append(i)\n",
    "        if len(sent) <10:\n",
    "            remove_index.append(i)\n",
    "        if sent.isupper():\n",
    "            remove_index.append(i)  \n",
    "#       remove duplicate sentences\n",
    "        if sent.lower() in seen:\n",
    "            remove_index.append(i)\n",
    "        else:\n",
    "            seen.append(sent.lower())\n",
    "\n",
    "error_line_index_unique = list(dict.fromkeys(remove_index))\n",
    "print(\"number index removed: \", len(remove_index))\n",
    "\n",
    "# write file\n",
    "write_file(\"../law/_law.en\", remove_content_with_index(lst_en, error_line_index_unique))\n",
    "write_file(\"../law/_law.vi\", remove_content_with_index(lst_vi, error_line_index_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET BUDDHISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Buddhism/Bat chanh dao-con duong den hanh phuc.en 4955\n",
      "../Buddhism/Chi ton ca.en 693\n",
      "../Buddhism/Hanh trinh cua linh hon.en 3000\n",
      "../Buddhism/Hanh trinh den chanh niem.en 1806\n",
      "../Buddhism/Hay mo tam bao la nhu dai duong.en 1028\n",
      "../Buddhism/The first and last freedom.en 3615\n",
      "../Buddhism/Bat chanh dao-con duong den hanh phuc.vi 4955\n",
      "../Buddhism/Chi ton ca.vi 693\n",
      "../Buddhism/Hanh trinh cua linh hon.vi 3000\n",
      "../Buddhism/Hanh trinh den chanh niem.vi 1806\n",
      "../Buddhism/Hay mo tam bao la nhu dai duong.vi 1028\n",
      "../Buddhism/The first and last freedom.vi 3615\n",
      "15097\n",
      "15097\n"
     ]
    }
   ],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "en_files = sorted(glob.glob(\"../Buddhism/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"../Buddhism/*.vi\"))\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_en.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "for file in vi_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_vi.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number index removed:  3783\n"
     ]
    }
   ],
   "source": [
    "para_index = []\n",
    "\n",
    "remove_index = []\n",
    "remove_sent_contain = [\"chapter\", \"section\", \"part\"]\n",
    "arr_lst = [lst_en, lst_vi]\n",
    "for k in arr_lst:\n",
    "    seen = []\n",
    "    for i in range(len(k)):\n",
    "        sent = k[i]\n",
    "        \n",
    "        if len(sent_tokenize(sent))!=1:\n",
    "            remove_index.append(i)\n",
    "            para_index.append(i)\n",
    "        if any(ext in sent.lower() for ext in remove_sent_contain):\n",
    "            remove_index.append(i)\n",
    "        if len(sent) <10:\n",
    "            remove_index.append(i)\n",
    "        if sent.isupper():\n",
    "            remove_index.append(i)  \n",
    "#       remove duplicate sentences\n",
    "        if sent.lower() in seen:\n",
    "            remove_index.append(i)\n",
    "        else:\n",
    "            seen.append(sent.lower())\n",
    "\n",
    "error_line_index_unique = list(dict.fromkeys(remove_index))\n",
    "print(\"number index removed: \", len(remove_index))\n",
    "\n",
    "# write file\n",
    "en1 = remove_content_with_index(lst_en, error_line_index_unique)\n",
    "vi1 = remove_content_with_index(lst_vi, error_line_index_unique)\n",
    "write_file(\"../Buddhism/1.en\", en1)\n",
    "write_file(\"../Buddhism/1.vi\", vi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n"
     ]
    }
   ],
   "source": [
    "para_index_unique = list(dict.fromkeys(para_index))\n",
    "print(len(para_index_unique))\n",
    "\n",
    "lst_en_para = []\n",
    "for i in range(len(lst_en)):\n",
    "    if i in para_index_unique:\n",
    "        lst_en_para.append(lst_en[i])\n",
    "        \n",
    "lst_vi_para = []\n",
    "for i in range(len(lst_vi)):\n",
    "    if i in para_index_unique:\n",
    "        lst_vi_para.append(lst_vi[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number index removed:  241\n"
     ]
    }
   ],
   "source": [
    "en_res = []\n",
    "vi_res = []\n",
    "for i in range(len(lst_en_para)):\n",
    "    en = sent_tokenize(lst_en_para[i])\n",
    "    vi = sent_tokenize(lst_vi_para[i])\n",
    "    if len(en) == len(vi):\n",
    "        for j in range(len(en)):\n",
    "            en_res.append(en[j])\n",
    "            vi_res.append(vi[j])    \n",
    "\n",
    "            \n",
    "remove_index = []\n",
    "remove_sent_contain = [\"chapter\", \"section\", \"part\"]\n",
    "arr_lst = [en_res, vi_res]\n",
    "for k in arr_lst:\n",
    "    seen = []\n",
    "    for i in range(len(k)):\n",
    "        sent = k[i]\n",
    "        \n",
    "        if len(sent_tokenize(sent))!=1:\n",
    "            remove_index.append(i)\n",
    "        if any(ext in sent.lower() for ext in remove_sent_contain):\n",
    "            remove_index.append(i)\n",
    "        if len(sent) <10:\n",
    "            remove_index.append(i)\n",
    "        if sent.isupper():\n",
    "            remove_index.append(i)  \n",
    "#       remove duplicate sentences\n",
    "        if sent.lower() in seen:\n",
    "            remove_index.append(i)\n",
    "        else:\n",
    "            seen.append(sent.lower())\n",
    "\n",
    "error_line_index_unique = list(dict.fromkeys(remove_index))\n",
    "print(\"number index removed: \", len(remove_index))\n",
    "\n",
    "# write file\n",
    "en2 = remove_content_with_index(en_res, error_line_index_unique)\n",
    "vi2 = remove_content_with_index(vi_res, error_line_index_unique)\n",
    "write_file(\"../Buddhism/2.en\", en2)\n",
    "write_file(\"../Buddhism/2.vi\", vi2)\n",
    "\n",
    "write_file(\"../Buddhism/Buddhism.en\", en1+en2)\n",
    "write_file(\"../Buddhism/Buddhism.vi\", vi1+vi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET TED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../en_vi_iwslt/IWSLT15.TED.tst2012.en-vi.en 1553\n",
      "../en_vi_iwslt/IWSLT15.TED.tst2013.en-vi.en 1267\n",
      "../en_vi_iwslt/IWSLT15.TED.tst2015.en-vi.en 1080\n",
      "../en_vi_iwslt/train.en 117053\n",
      "../en_vi_iwslt/IWSLT15.TED.tst2012.en-vi.vi 1553\n",
      "../en_vi_iwslt/IWSLT15.TED.tst2013.en-vi.vi 1267\n",
      "../en_vi_iwslt/IWSLT15.TED.tst2015.en-vi.vi 1080\n",
      "../en_vi_iwslt/train.vi 117053\n",
      "120953\n",
      "120953\n"
     ]
    }
   ],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "en_files = sorted(glob.glob(\"../en_vi_iwslt/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"../en_vi_iwslt/*.vi\"))\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_en.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "for file in vi_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_vi.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number index removed:  28698\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "def is_containt_splcharacter(test):\n",
    "    string_check= re.compile('[<>/]')\n",
    "    return False if(string_check.search(test) == None) else True \n",
    "\n",
    "remove_index = []\n",
    "arr_lst = [lst_en, lst_vi]\n",
    "for k in arr_lst:\n",
    "    seen = []\n",
    "    for i in range(len(k)):\n",
    "        sent = k[i]\n",
    "        \n",
    "        if len(sent_tokenize(sent))!=1:\n",
    "            remove_index.append(i)\n",
    "        elif is_containt_splcharacter(sent):\n",
    "            remove_index.append(i)\n",
    "        elif len(sent) <10:\n",
    "            remove_index.append(i)\n",
    "        elif sent.isupper():\n",
    "            remove_index.append(i)  \n",
    "#       remove duplicate sentences\n",
    "        elif sent.lower() in seen:\n",
    "            remove_index.append(i)\n",
    "        else:\n",
    "            seen.append(sent.lower())\n",
    "\n",
    "error_line_index_unique = list(dict.fromkeys(remove_index))\n",
    "print(\"number index removed: \", len(remove_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"../en_vi_iwslt/TED.en\", remove_content_with_index(lst_en, error_line_index_unique))\n",
    "write_file(\"../en_vi_iwslt/TED.vi\", remove_content_with_index(lst_vi, error_line_index_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"< speaker > Rachel Pike < / speaker >\"\n",
    "def is_containt_splcharacter2(test):\n",
    "    string_check= re.compile('[<>/]')\n",
    "    return False if(string_check.search(test) == None) else True \n",
    "is_containt_splcharacter2(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET RYM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../rym/1.en 569\n",
      "../rym/1.vi 569\n",
      "569\n",
      "569\n"
     ]
    }
   ],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "en_files = sorted(glob.glob(\"../rym/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"../rym/*.vi\"))\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_en.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "for file in vi_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_vi.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number index removed:  436\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "def is_containt_splcharacter(test):\n",
    "    string_check= re.compile('[<>/]')\n",
    "    return False if(string_check.search(test) == None) else True \n",
    "\n",
    "def split_para(lst):\n",
    "    res = []\n",
    "    for inx, val in enumerate(lst):\n",
    "        sents = sent_tokenize(val)\n",
    "        if len(sents)>1:\n",
    "            for j in sents:\n",
    "                res.append(str(j))\n",
    "        else:\n",
    "            res.append(val)\n",
    "    return res\n",
    "\n",
    "def is_sent_ok(sent):\n",
    "    if is_containt_splcharacter(sent):\n",
    "        return False\n",
    "    elif len(sent) <27:\n",
    "        return False\n",
    "    elif sent.isupper():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def is_para_ok(para):\n",
    "    sents =  sent_tokenize(para)\n",
    "    for k in sents:\n",
    "        if is_sent_ok(k)==False:\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "\n",
    "remove_index = []\n",
    "arr_lst = [lst_en, lst_vi]\n",
    "for k in arr_lst:\n",
    "    seen = []\n",
    "    for i in range(len(k)):\n",
    "        sent = k[i]\n",
    "        len_en = len(sent_tokenize(lst_en[i]))\n",
    "        len_vi = len(sent_tokenize(lst_vi[i]))     \n",
    "        \n",
    "        if len_en!=len_vi:\n",
    "            remove_index.append(i)\n",
    "        elif is_para_ok(sent) == False:\n",
    "            remove_index.append(i)\n",
    "        elif sent.lower() in seen:\n",
    "            remove_index.append(i)\n",
    "        else:\n",
    "            seen.append(sent.lower())\n",
    "\n",
    "error_line_index_unique = list(dict.fromkeys(remove_index))\n",
    "print(\"number index removed: \", len(remove_index))\n",
    "\n",
    "lst_en = remove_content_with_index(lst_en, error_line_index_unique)\n",
    "lst_vi = remove_content_with_index(lst_vi, error_line_index_unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"../rym/ok.en\", split_para(lst_en))\n",
    "write_file(\"../rym/ok.vi\", split_para(lst_vi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET Catechism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Catechism/1.en 844\n",
      "../Catechism/1.vi 844\n",
      "844\n",
      "844\n"
     ]
    }
   ],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "en_files = sorted(glob.glob(\"../Catechism/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"../Catechism/*.vi\"))\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_en.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "for file in vi_files:\n",
    "    count = 0\n",
    "    with open(file) as file_in:\n",
    "        for line in file_in:\n",
    "            lst_vi.append(line.strip())\n",
    "            count+=1\n",
    "    print(file, count)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number index removed:  725\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "def is_containt_splcharacter(test):\n",
    "    string_check= re.compile('[<>/]')\n",
    "    return False if(string_check.search(test) == None) else True \n",
    "\n",
    "def split_para(lst):\n",
    "    res = []\n",
    "    for inx, val in enumerate(lst):\n",
    "        sents = sent_tokenize(val)\n",
    "        if len(sents)>1:\n",
    "            for j in sents:\n",
    "                res.append(str(j))\n",
    "        else:\n",
    "            res.append(val)\n",
    "    return res\n",
    "\n",
    "def is_sent_ok(sent):\n",
    "    if is_containt_splcharacter(sent):\n",
    "        return False\n",
    "    elif len(sent) <25:\n",
    "        return False\n",
    "    elif sent.isupper():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def is_para_ok(para):\n",
    "    sents =  sent_tokenize(para)\n",
    "    for k in sents:\n",
    "        if is_sent_ok(k)==False:\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "\n",
    "remove_index = []\n",
    "arr_lst = [lst_en, lst_vi]\n",
    "for k in arr_lst:\n",
    "    seen = []\n",
    "    for i in range(len(k)):\n",
    "        sent = k[i]\n",
    "        len_en = len(sent_tokenize(lst_en[i]))\n",
    "        len_vi = len(sent_tokenize(lst_vi[i]))     \n",
    "        \n",
    "        if len_en!=len_vi:\n",
    "            remove_index.append(i)\n",
    "        elif is_para_ok(sent) == False:\n",
    "            remove_index.append(i)\n",
    "        elif sent.lower() in seen:\n",
    "            remove_index.append(i)\n",
    "        else:\n",
    "            seen.append(sent.lower())\n",
    "\n",
    "error_line_index_unique = list(dict.fromkeys(remove_index))\n",
    "print(\"number index removed: \", len(remove_index))\n",
    "\n",
    "lst_en = remove_content_with_index(lst_en, error_line_index_unique)\n",
    "lst_vi = remove_content_with_index(lst_vi, error_line_index_unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\"../Catechism/ok.en\", split_para(lst_en))\n",
    "write_file(\"../Catechism/ok.vi\", split_para(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
