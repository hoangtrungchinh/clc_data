{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTALL\n",
    "- FAISS - \n",
    "- Sent2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chinh/clc_data/Script/Statistic-Faiss-EM-TED-en-vi20210303-1549\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "name = \"Statistic-Faiss-EM-TED-en-vi\"+ str(time.strftime(\"%Y%m%d-%H%M\"))\n",
    "\n",
    "!mkdir $name\n",
    "path = os.getcwd() + \"/\" + name\n",
    "os.chdir(path)\n",
    "\n",
    "!pwd\n",
    "\n",
    "\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-03 15:49:18--  https://github.com/hoangtrungchinh/clc_data/raw/master/en_vi_iwslt.tar.gz\n",
      "Resolving github.com (github.com)... 13.250.177.223\n",
      "Connecting to github.com (github.com)|13.250.177.223|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/en_vi_iwslt.tar.gz [following]\n",
      "--2021-03-03 15:49:19--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/en_vi_iwslt.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9044100 (8,6M) [application/octet-stream]\n",
      "Saving to: ‘en_vi_iwslt.tar.gz’\n",
      "\n",
      "en_vi_iwslt.tar.gz  100%[===================>]   8,62M  6,39MB/s    in 1,4s    \n",
      "\n",
      "2021-03-03 15:49:22 (6,39 MB/s) - ‘en_vi_iwslt.tar.gz’ saved [9044100/9044100]\n",
      "\n",
      "IWSLT15.TED.tst2013.en-vi.en\n",
      "IWSLT15.TED.tst2013.en-vi.vi\n",
      "IWSLT15.TED.tst2012.en-vi.en\n",
      "IWSLT15.TED.tst2012.en-vi.vi\n",
      "train.en\n",
      "train.vi\n",
      "IWSLT15.TED.tst2015.en-vi.en\n",
      "IWSLT15.TED.tst2015.en-vi.vi\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/hoangtrungchinh/clc_data/raw/master/en_vi_iwslt.tar.gz\n",
    "!mkdir data_bin\n",
    "!tar -xvf  'en_vi_iwslt.tar.gz' -C 'data_bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_bin/IWSLT15.TED.tst2012.en-vi.en', 'data_bin/IWSLT15.TED.tst2013.en-vi.en', 'data_bin/IWSLT15.TED.tst2015.en-vi.en', 'data_bin/train.en']\n",
      "['data_bin/IWSLT15.TED.tst2012.en-vi.vi', 'data_bin/IWSLT15.TED.tst2013.en-vi.vi', 'data_bin/IWSLT15.TED.tst2015.en-vi.vi', 'data_bin/train.vi']\n",
      "120956\n",
      "120956\n"
     ]
    }
   ],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "en_files = sorted(glob.glob(\"data_bin/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"data_bin/*.vi\"))\n",
    "print(en_files)\n",
    "print(vi_files)\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "  with open(file) as file_in:\n",
    "    for line in file_in:\n",
    "      lst_en.append(line)\n",
    "\n",
    "for file in vi_files:\n",
    "  with open(file) as file_in:\n",
    "    for line in file_in:\n",
    "      lst_vi.append(line)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sents_en =  120956\n",
      "Sents_vi =  120956\n",
      "L_mean_en = 20.762409471212674\n",
      "L_mean_vi = 24.4882767287278\n",
      "Vocab_en = 51443\n",
      "Vocab_vi = 27340\n"
     ]
    }
   ],
   "source": [
    "print(\"Sents_en = \", len(lst_en))\n",
    "print(\"Sents_vi = \", len(lst_vi))\n",
    "\n",
    "L_mean_en = (sum([len(sen.split(\" \")) for sen in lst_en]))/len(lst_en)\n",
    "print(\"L_mean_en =\",L_mean_en)\n",
    "\n",
    "L_mean_vi = (sum([len(sen.split(\" \")) for sen in lst_vi]))/len(lst_vi)\n",
    "print(\"L_mean_vi =\",L_mean_vi)\n",
    "\n",
    "Vocab_en = (\" \".join(lst_en)).split(\" \")  \n",
    "print(\"Vocab_en =\",len(set(Vocab_en)))\n",
    "\n",
    "Vocab_vi = (\" \".join(lst_vi)).split(\" \")  \n",
    "print(\"Vocab_vi =\",len(set(Vocab_vi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPLIT TRAIN, TEST, VALID\n",
    "from sklearn.model_selection import train_test_split\n",
    "en_train, en_test_valid, vi_train, vi_test_valid =  train_test_split(lst_en, lst_vi, test_size=0.2, random_state=123)\n",
    "en_valid, en_test, vi_valid, vi_test = train_test_split(en_test_valid, vi_test_valid, test_size=0.5, random_state=123)\n",
    "print(len(en_train))\n",
    "print(len(vi_train))\n",
    "print(len(en_valid))\n",
    "print(len(vi_valid))\n",
    "print(len(en_test))\n",
    "print(len(vi_test))\n",
    "print(en_train[20])\n",
    "print(vi_train[20])\n",
    "print(en_valid[-1])\n",
    "print(vi_valid[-1])\n",
    "print(en_test[-1])\n",
    "print(vi_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_variable = [en_train,vi_train,en_valid,vi_valid,en_test,vi_test]\n",
    "file_names = [\"en_train\",\"vi_train\",\"en_valid\",\"vi_valid\",\"en_test\",\"vi_test\"]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "  with open(file_names[i], 'w') as f:\n",
    "    for item in file_variable[i]:\n",
    "      f.write(item)\n",
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "import sent2vec\n",
    "model = sent2vec.Sent2vecModel()\n",
    "model.load_model('../../../wiki_unigrams.bin')\n",
    "\n",
    "print('=== Ending, Total time (second): ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcfile = \"en_train\"\n",
    "tarfile = \"vi_train\"\n",
    "# lst_srcfile = open(srcfile, \"r\").readlines()\n",
    "# lst_tarfile = open(tarfile, \"r\").readlines()\n",
    "lst_srcfile = en_train\n",
    "lst_tarfile = vi_train\n",
    "\n",
    "vec_lst_srcfile = model.embed_sentences(lst_srcfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Cosin similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "start = time.time()\n",
    "vec_lst_srcfile = model.embed_sentences(lst_srcfile)\n",
    "index = faiss.IndexFlatL2(600)\n",
    "index.ntotal\n",
    "faiss.normalize_L2(vec_lst_srcfile)\n",
    "index.add(vec_lst_srcfile)\n",
    "k = 6\n",
    "distance, index = index.search(vec_lst_srcfile, k)\n",
    "\n",
    "print('=== Ending, Total time (second): ', time.time() - start)\n",
    "print(len(distance))\n",
    "print(len(index))\n",
    "\n",
    "print(index)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(vec_lst_srcfile))\n",
    "print(vec_lst_srcfile.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "j = k-1\n",
    "print(index[i][j])\n",
    "print(\"==================================\")\n",
    "print(distance[i][j])\n",
    "a = vec_lst_srcfile[i]\n",
    "# print(a)\n",
    "b = vec_lst_srcfile[index[i][j]]\n",
    "# TEST\n",
    "dist_squared = np.sum(np.square(a - b))\n",
    "print(dist_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "saperate = \" || \"\n",
    "\n",
    "src_label = \"S\"\n",
    "emb_label = \"E\"\n",
    "thres_arr = [0.9, 0.8, 0.7, 0.6]\n",
    "for i in range(len(thres_arr)):\n",
    "    threshold = thres_arr[i]\n",
    "    out_file_write = open(\"en_train_EM_\"+str(thres_arr[i]), 'w')\n",
    "    out_file_write_score = open(\"en_train_EM_score_\"+str(thres_arr[i]), 'w')\n",
    "    out_file_write_factor = open(\"en_train_EM_factor_\"+str(thres_arr[i]), 'w')\n",
    "    num_gth_thres = 0\n",
    "\n",
    "    for i in range(len(lst_srcfile)):\n",
    "        score = distance[i][1]\n",
    "        content = \"\"\n",
    "        content_label_arr = []\n",
    "        if score >= threshold:\n",
    "            num_gth_thres += 1\n",
    "            best_simi_index = index[i][1]\n",
    "            content = lst_srcfile[i].strip() + saperate + lst_tarfile[best_simi_index].strip()\n",
    "\n",
    "            content_label = [src_label] * len(lst_srcfile[i].split())\n",
    "            content_label.append(emb_label)\n",
    "            content_label = content_label + [emb_label] * len(lst_tarfile[best_simi_index].split())\n",
    "\n",
    "            content_label_arr = \" \".join(content_label)\n",
    "        else:\n",
    "            content = lst_srcfile[i].strip()\n",
    "            content_label = [src_label] * len(lst_srcfile[i].split())\n",
    "            content_label_arr = \" \".join(content_label)\n",
    " \n",
    "        out_file_write.writelines(content+ \"\\n\")    \n",
    "        out_file_write_factor.writelines(content_label_arr + \"\\n\")\n",
    "        out_file_write_score.writelines(str(score) + \"\\n\")\n",
    "\n",
    "    print('threshold =', threshold, \"EM sentences =\", num_gth_thres, \"/\", len(lst_srcfile), num_gth_thres/len(lst_srcfile), \"%\" )\n",
    "\n",
    "    out_file_write.close()\n",
    "    out_file_write_score.close()\n",
    "    out_file_write_factor.close()\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print('=== Ending, Total time (second): ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
