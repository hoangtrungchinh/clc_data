{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTALL\n",
    "- FAISS - \n",
    "- Sent2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chinh/clc_data/Script/Faiss-EM-NDT-bert-en-vi-0.999-20210402-1607\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "name = \"Faiss-EM-NDT-bert-en-vi-0.999-\"+ str(time.strftime(\"%Y%m%d-%H%M\"))\n",
    "\n",
    "!mkdir $name\n",
    "path = os.getcwd() + \"/\" + name\n",
    "os.chdir(path)\n",
    "\n",
    "!pwd\n",
    "\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "# import os\n",
    "# os.chdir(\"/home/lw/clc_fairseq/TED-20210121-1335\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-02 16:07:03--  https://github.com/hoangtrungchinh/clc_data/raw/master/nguyenductuan.tar.gz\n",
      "Resolving github.com (github.com)... 52.74.223.119\n",
      "Connecting to github.com (github.com)|52.74.223.119|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/nguyenductuan.tar.gz [following]\n",
      "--2021-04-02 16:07:04--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/nguyenductuan.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13394580 (13M) [application/octet-stream]\n",
      "Saving to: ‘nguyenductuan.tar.gz’\n",
      "\n",
      "nguyenductuan.tar.g 100%[===================>]  12,77M  7,74MB/s    in 1,7s    \n",
      "\n",
      "2021-04-02 16:07:06 (7,74 MB/s) - ‘nguyenductuan.tar.gz’ saved [13394580/13394580]\n",
      "\n",
      "1.vi\n",
      "1.en\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/hoangtrungchinh/clc_data/raw/master/nguyenductuan.tar.gz\n",
    "!mkdir data_bin\n",
    "!tar -xvf  'nguyenductuan.tar.gz' -C 'data_bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_bin/1.en']\n",
      "['data_bin/1.vi']\n",
      "380643\n",
      "380643\n"
     ]
    }
   ],
   "source": [
    "# import file\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "en_files = sorted(glob.glob(\"data_bin/*.en\"))\n",
    "vi_files = sorted(glob.glob(\"data_bin/*.vi\"))\n",
    "print(en_files)\n",
    "print(vi_files)\n",
    "\n",
    "lst_en = []\n",
    "lst_vi = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for file in en_files:\n",
    "  with open(file) as file_in:\n",
    "    for line in file_in:\n",
    "      lst_en.append(line)\n",
    "\n",
    "for file in vi_files:\n",
    "  with open(file) as file_in:\n",
    "    for line in file_in:\n",
    "      lst_vi.append(line)\n",
    "\n",
    "print(len(lst_en))\n",
    "print(len(lst_vi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304514\n",
      "304514\n",
      "38064\n",
      "38064\n",
      "38065\n",
      "38065\n",
      "He's out sick for two days.\n",
      "\n",
      "Nghỉ ốm hai ngày rồi.\n",
      "\n",
      "Yeah, she 'sexiled' you or whatever, right?\n",
      "\n",
      "Ừ, cô ấy ép em dâm đãng hay gì đó phải không?\n",
      "\n",
      "You were treated like a sick person.\n",
      "\n",
      "Anh đã được đối xử như một người bệnh.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SPLIT TRAIN, TEST, VALID\n",
    "from sklearn.model_selection import train_test_split\n",
    "en_train, en_test_valid, vi_train, vi_test_valid =  train_test_split(lst_en, lst_vi, test_size=0.2, random_state=123)\n",
    "en_valid, en_test, vi_valid, vi_test = train_test_split(en_test_valid, vi_test_valid, test_size=0.5, random_state=123)\n",
    "print(len(en_train))\n",
    "print(len(vi_train))\n",
    "print(len(en_valid))\n",
    "print(len(vi_valid))\n",
    "print(len(en_test))\n",
    "print(len(vi_test))\n",
    "print(en_train[20])\n",
    "print(vi_train[20])\n",
    "print(en_valid[-1])\n",
    "print(vi_valid[-1])\n",
    "print(en_test[-1])\n",
    "print(vi_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 46760\r\n",
      "drwxrwxr-x  3 chinh chinh     4096 Thg 4   2 16:07 .\r\n",
      "drwxrwxr-x 11 chinh chinh     4096 Thg 4   2 16:07 ..\r\n",
      "drwxrwxr-x  2 chinh chinh     4096 Thg 4   2 16:07 data_bin\r\n",
      "-rw-rw-r--  1 chinh chinh  1478082 Thg 4   2 16:07 en_test\r\n",
      "-rw-rw-r--  1 chinh chinh 11817828 Thg 4   2 16:07 en_train\r\n",
      "-rw-rw-r--  1 chinh chinh  1475267 Thg 4   2 16:07 en_valid\r\n",
      "-rw-rw-r--  1 chinh chinh 13394580 Thg 4   2 16:07 nguyenductuan.tar.gz\r\n",
      "-rw-rw-r--  1 chinh chinh  1968735 Thg 4   2 16:07 vi_test\r\n",
      "-rw-rw-r--  1 chinh chinh 15754152 Thg 4   2 16:07 vi_train\r\n",
      "-rw-rw-r--  1 chinh chinh  1963918 Thg 4   2 16:07 vi_valid\r\n"
     ]
    }
   ],
   "source": [
    "file_variable = [en_train,vi_train,en_valid,vi_valid,en_test,vi_test]\n",
    "file_names = [\"en_train\",\"vi_train\",\"en_valid\",\"vi_valid\",\"en_test\",\"vi_test\"]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "  with open(file_names[i], 'w') as f:\n",
    "    for item in file_variable[i]:\n",
    "      f.write(item)\n",
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('stsb-bert-large')\n",
    "# # model = SentenceTransformer('LaBSE')\n",
    "# #Sentences are encoded by calling model.encode()\n",
    "# emb1 = model.encode(\"This is a red cat with a hat.\")\n",
    "# emb2 = model.encode(\"Have you seen my red cat?\")\n",
    "\n",
    "# cos_sim = util.pytorch_cos_sim(emb1, emb2)\n",
    "# print(\"Cosine-Similarity:\", cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cos_sim.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ending, Total time (second):  1839.3935627937317\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "srcfile = \"en_train\"\n",
    "tarfile = \"vi_train\"\n",
    "# lst_srcfile = open(srcfile, \"r\").readlines()\n",
    "# lst_tarfile = open(tarfile, \"r\").readlines()\n",
    "lst_srcfile = en_train\n",
    "lst_tarfile = vi_train\n",
    "\n",
    "vec_lst_srcfile = model.encode(lst_srcfile)\n",
    "print('=== Ending, Total time (second): ', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Cosin similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ending, Total time (second):  499.39041900634766\n",
      "304514\n",
      "304514\n",
      "[[     0 171197  87709 280882 217664 171131]\n",
      " [     1  57310 292296  75844 131819 157372]\n",
      " [     2    866  26867 116090 244699  77922]\n",
      " ...\n",
      " [304511 190585  69923 190053 181708 283756]\n",
      " [304512 155584 271476 277073 280816  32471]\n",
      " [304513 147507 249537 235763 275394 278257]]\n",
      "[[0.0000000e+00 3.1040883e-01 3.4955812e-01 3.7668610e-01 3.8552010e-01\n",
      "  4.0213704e-01]\n",
      " [2.3841858e-07 9.4573152e-01 9.6817505e-01 9.7280025e-01 9.7517765e-01\n",
      "  9.8701441e-01]\n",
      " [0.0000000e+00 6.7612147e-01 8.3577967e-01 8.9306748e-01 9.0530157e-01\n",
      "  9.0685022e-01]\n",
      " ...\n",
      " [0.0000000e+00 1.6155887e-01 1.6896379e-01 1.7248940e-01 2.0367694e-01\n",
      "  2.0367718e-01]\n",
      " [0.0000000e+00 7.1165085e-01 7.9599035e-01 8.4876978e-01 8.6626041e-01\n",
      "  8.8183188e-01]\n",
      " [0.0000000e+00 6.7183733e-02 6.9432139e-02 6.9432259e-02 7.4913740e-02\n",
      "  1.2175012e-01]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "# print(vec_lst_srcfile.shape[1])\n",
    "start = time.time()\n",
    "index = faiss.IndexFlatL2(vec_lst_srcfile.shape[1])\n",
    "index.ntotal\n",
    "faiss.normalize_L2(vec_lst_srcfile)\n",
    "index.add(vec_lst_srcfile)\n",
    "k = 6\n",
    "distance, index = index.search(vec_lst_srcfile, k)\n",
    "\n",
    "print('=== Ending, Total time (second): ', time.time() - start)\n",
    "print(len(distance))\n",
    "print(len(index))\n",
    "\n",
    "print(index)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147155\n",
      "==================================\n",
      "0.81918657\n",
      "0.8191867\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "j = k-1\n",
    "print(index[i][j])\n",
    "print(\"==================================\")\n",
    "print(distance[i][j])\n",
    "a = vec_lst_srcfile[i]\n",
    "# print(a)\n",
    "b = vec_lst_srcfile[index[i][j]]\n",
    "# TEST\n",
    "dist_squared = np.sum(np.square(a - b))\n",
    "print(dist_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold = 0.95 EM sentences = 3514 / 304514 0.011539699324169003 %\n",
      "threshold = 0.99 EM sentences = 1669 / 304514 0.005480864590790571 %\n",
      "threshold = 0.995 EM sentences = 1496 / 304514 0.004912746211996821 %\n",
      "threshold = 0.999 EM sentences = 1378 / 304514 0.0045252435027617775 %\n",
      "=== Ending, Total time (second):  12.267041206359863\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "saperate = \" || \"\n",
    "\n",
    "src_label = \"S\"\n",
    "emb_label = \"E\"\n",
    "thres_arr = [0.95, 0.99, 0.995, 0.999]\n",
    "for i in range(len(thres_arr)):\n",
    "    threshold = thres_arr[i]\n",
    "    out_file_write = open(\"en_train_EM_\"+str(thres_arr[i]), 'w')\n",
    "    out_file_write_score = open(\"en_train_EM_score_\"+str(thres_arr[i]), 'w')\n",
    "    out_file_write_factor = open(\"en_train_EM_factor_\"+str(thres_arr[i]), 'w')\n",
    "    num_gth_thres = 0\n",
    "\n",
    "    for i in range(len(lst_srcfile)):\n",
    "        score = distance[i][1]\n",
    "        content = \"\"\n",
    "        content_label_arr = []\n",
    "        if score >= threshold:\n",
    "            num_gth_thres += 1\n",
    "            best_simi_index = index[i][1]\n",
    "            content = lst_srcfile[i].strip() + saperate + lst_tarfile[best_simi_index].strip()\n",
    "\n",
    "            content_label = [src_label] * len(lst_srcfile[i].split())\n",
    "            content_label.append(emb_label)\n",
    "            content_label = content_label + [emb_label] * len(lst_tarfile[best_simi_index].split())\n",
    "\n",
    "            content_label_arr = \" \".join(content_label)\n",
    "        else:\n",
    "            content = lst_srcfile[i].strip()\n",
    "            content_label = [src_label] * len(lst_srcfile[i].split())\n",
    "            content_label_arr = \" \".join(content_label)\n",
    " \n",
    "        out_file_write.writelines(content+ \"\\n\")    \n",
    "        out_file_write_factor.writelines(content_label_arr + \"\\n\")\n",
    "        out_file_write_score.writelines(str(score) + \"\\n\")\n",
    "\n",
    "    print('threshold =', threshold, \"EM sentences =\", num_gth_thres, \"/\", len(lst_srcfile), num_gth_thres/len(lst_srcfile), \"%\" )\n",
    "\n",
    "    out_file_write.close()\n",
    "    out_file_write_score.close()\n",
    "    out_file_write_factor.close()\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print('=== Ending, Total time (second): ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
