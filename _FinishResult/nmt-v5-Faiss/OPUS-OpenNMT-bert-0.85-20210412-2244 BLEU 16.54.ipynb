{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OPUS-OpenNMT-bert-0.85-20210412-2244 BLEU 16.54.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267449253,"user_tz":-420,"elapsed":20193,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"5adf9b4a-279e-4b67-853d-afe8df3e26a0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267451733,"user_tz":-420,"elapsed":22662,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"83c4566a-e3d8-4b5f-ab78-66bcadeb4844"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"OPUS-OpenNMT-bert-0.85-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/OPUS-OpenNMT-bert-0.9-20210412-0158'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/OPUS-OpenNMT-bert-0.85-20210412-2244\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267451734,"user_tz":-420,"elapsed":22660,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"4691b846-e621-4a89-d4fa-1b230644d15e"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mon Apr 12 22:44:10 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267464926,"user_tz":-420,"elapsed":35849,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"606671fe-0370-46d6-c82b-58ec0320a082"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\r\u001b[K     |█▊                              | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 22.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 26.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 21.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 12.2MB/s \n","\u001b[?25hCollecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\r\u001b[K     |██████▏                         | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 28.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 30.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Collecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 18.9MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=2b17aab0af1910d00e9dcc6736dd581157fa8f909a547f9eaf314304a287119a\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: torchtext, waitress, configargparse, pyonmttok, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267472762,"user_tz":-420,"elapsed":43682,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"ad5f8dea-eb87-431f-aefc-3e4fd0260fc0"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/opus_bert.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'opus_bert.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-12 22:44:24--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/opus_bert.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 100661014 (96M) [application/octet-stream]\n","Saving to: ‘opus_bert.tar.gz’\n","\n","opus_bert.tar.gz    100%[===================>]  96.00M  96.5MB/s    in 1.0s    \n","\n","2021-04-12 22:44:28 (96.5 MB/s) - ‘opus_bert.tar.gz’ saved [100661014/100661014]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267529673,"user_tz":-420,"elapsed":100591,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"3e5240ea-880b-41cd-d8a9-336318c6de13"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.85' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-12 22:44:35,490 INFO] Extracting features...\n","[2021-04-12 22:44:35,496 INFO]  * number of source features: 0.\n","[2021-04-12 22:44:35,496 INFO]  * number of target features: 0.\n","[2021-04-12 22:44:35,496 INFO] Building `Fields` object...\n","[2021-04-12 22:44:35,496 INFO] Building & saving training data...\n","[2021-04-12 22:44:36,696 INFO] Building shard 0.\n","[2021-04-12 22:45:05,709 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-12 22:45:22,486 INFO]  * tgt vocab size: 50004.\n","[2021-04-12 22:45:22,871 INFO]  * src vocab size: 50002.\n","[2021-04-12 22:45:23,522 INFO] Building & saving validation data...\n","[2021-04-12 22:45:24,138 INFO] Building shard 0.\n","[2021-04-12 22:45:26,138 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618281965686,"user_tz":-420,"elapsed":14536601,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e8885fbd-bbaf-41de-936b-b85a5da0d8b1"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-12 22:45:32,426 INFO]  * src vocab size = 50002\n","[2021-04-12 22:45:32,426 INFO]  * tgt vocab size = 50004\n","[2021-04-12 22:45:32,426 INFO] Building model...\n","[2021-04-12 22:45:41,029 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50002, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=50004, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-12 22:45:41,095 INFO] encoder: 44516352\n","[2021-04-12 22:45:41,096 INFO] decoder: 76479316\n","[2021-04-12 22:45:41,096 INFO] * number of parameters: 120995668\n","[2021-04-12 22:45:41,100 INFO] Starting training on GPU: [0]\n","[2021-04-12 22:45:41,100 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-12 22:45:41,100 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 22:45:58,285 INFO] number of examples: 802829\n","[2021-04-12 22:52:16,358 INFO] Step 1000/30000; acc:  13.35; ppl: 563.62; xent: 6.33; lr: 0.00012; 14509/16478 tok/s;    395 sec\n","[2021-04-12 22:52:16,359 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 22:52:17,922 INFO] number of examples: 100400\n","[2021-04-12 22:53:18,739 INFO] Validation perplexity: 294.977\n","[2021-04-12 22:53:18,739 INFO] Validation accuracy: 18.3643\n","[2021-04-12 22:53:20,264 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-12 22:53:46,864 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 22:54:08,756 INFO] number of examples: 802829\n","[2021-04-12 23:00:12,320 INFO] Step 2000/30000; acc:  26.67; ppl: 74.45; xent: 4.31; lr: 0.00025; 12083/13698 tok/s;    871 sec\n","[2021-04-12 23:00:12,321 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 23:00:13,604 INFO] number of examples: 100400\n","[2021-04-12 23:01:13,199 INFO] Validation perplexity: 58.4003\n","[2021-04-12 23:01:13,200 INFO] Validation accuracy: 35.5945\n","[2021-04-12 23:01:14,754 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-12 23:02:01,919 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 23:02:33,570 INFO] number of examples: 802829\n","[2021-04-12 23:08:13,263 INFO] Step 3000/30000; acc:  38.35; ppl: 27.28; xent: 3.31; lr: 0.00037; 11960/13552 tok/s;   1352 sec\n","[2021-04-12 23:08:13,264 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 23:08:17,923 INFO] number of examples: 100400\n","[2021-04-12 23:09:18,097 INFO] Validation perplexity: 28.7409\n","[2021-04-12 23:09:18,098 INFO] Validation accuracy: 42.4574\n","[2021-04-12 23:09:19,629 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-12 23:10:28,508 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 23:10:51,940 INFO] number of examples: 802829\n","[2021-04-12 23:16:09,391 INFO] Step 4000/30000; acc:  43.51; ppl: 17.06; xent: 2.84; lr: 0.00049; 12097/13708 tok/s;   1828 sec\n","[2021-04-12 23:16:09,392 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 23:16:10,729 INFO] number of examples: 100400\n","[2021-04-12 23:17:10,755 INFO] Validation perplexity: 22.3435\n","[2021-04-12 23:17:10,756 INFO] Validation accuracy: 45.2002\n","[2021-04-12 23:17:12,304 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-12 23:18:42,026 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 23:19:02,029 INFO] number of examples: 802829\n","[2021-04-12 23:24:04,802 INFO] Step 5000/30000; acc:  46.20; ppl: 13.37; xent: 2.59; lr: 0.00062; 12069/13686 tok/s;   2304 sec\n","[2021-04-12 23:24:04,803 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 23:24:06,146 INFO] number of examples: 100400\n","[2021-04-12 23:25:06,396 INFO] Validation perplexity: 19.5346\n","[2021-04-12 23:25:06,396 INFO] Validation accuracy: 46.2544\n","[2021-04-12 23:25:07,945 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-12 23:26:57,760 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 23:27:31,875 INFO] number of examples: 802829\n","[2021-04-12 23:32:09,916 INFO] Step 6000/30000; acc:  48.09; ppl: 11.38; xent: 2.43; lr: 0.00074; 11820/13398 tok/s;   2789 sec\n","[2021-04-12 23:32:09,917 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 23:32:17,892 INFO] number of examples: 100400\n","[2021-04-12 23:33:17,934 INFO] Validation perplexity: 18.2984\n","[2021-04-12 23:33:17,934 INFO] Validation accuracy: 46.8201\n","[2021-04-12 23:33:19,494 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-12 23:35:29,488 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 23:36:05,305 INFO] number of examples: 802829\n","[2021-04-12 23:40:23,091 INFO] Step 7000/30000; acc:  49.42; ppl: 10.19; xent: 2.32; lr: 0.00086; 11618/13216 tok/s;   3282 sec\n","[2021-04-12 23:40:23,092 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 23:40:24,455 INFO] number of examples: 100400\n","[2021-04-12 23:41:23,845 INFO] Validation perplexity: 17.3333\n","[2021-04-12 23:41:23,845 INFO] Validation accuracy: 47.8215\n","[2021-04-12 23:41:25,337 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-12 23:43:54,539 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 23:44:15,259 INFO] number of examples: 802829\n","[2021-04-12 23:48:18,873 INFO] Step 8000/30000; acc:  50.63; ppl:  9.27; xent: 2.23; lr: 0.00099; 12062/13658 tok/s;   3758 sec\n","[2021-04-12 23:48:18,874 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 23:48:20,261 INFO] number of examples: 100400\n","[2021-04-12 23:49:20,643 INFO] Validation perplexity: 16.6055\n","[2021-04-12 23:49:20,644 INFO] Validation accuracy: 48.2473\n","[2021-04-12 23:49:22,219 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-12 23:52:12,609 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 23:52:47,835 INFO] number of examples: 802829\n","[2021-04-12 23:56:26,254 INFO] Step 9000/30000; acc:  51.95; ppl:  8.42; xent: 2.13; lr: 0.00093; 11747/13363 tok/s;   4245 sec\n","[2021-04-12 23:56:26,256 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 23:56:34,556 INFO] number of examples: 100400\n","[2021-04-12 23:57:35,027 INFO] Validation perplexity: 16.1781\n","[2021-04-12 23:57:35,027 INFO] Validation accuracy: 48.8133\n","[2021-04-12 23:57:36,591 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-13 00:00:46,555 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 00:01:22,552 INFO] number of examples: 802829\n","[2021-04-13 00:04:39,744 INFO] Step 10000/30000; acc:  53.92; ppl:  7.41; xent: 2.00; lr: 0.00088; 11645/13145 tok/s;   4739 sec\n","[2021-04-13 00:04:39,745 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 00:04:41,132 INFO] number of examples: 100400\n","[2021-04-13 00:05:40,707 INFO] Validation perplexity: 15.7619\n","[2021-04-13 00:05:40,708 INFO] Validation accuracy: 49.3617\n","[2021-04-13 00:05:42,260 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-13 00:09:12,242 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 00:09:40,043 INFO] number of examples: 802829\n","[2021-04-13 00:12:37,478 INFO] Step 11000/30000; acc:  55.72; ppl:  6.66; xent: 1.90; lr: 0.00084; 11980/13612 tok/s;   5216 sec\n","[2021-04-13 00:12:37,479 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 00:12:38,904 INFO] number of examples: 100400\n","[2021-04-13 00:13:39,739 INFO] Validation perplexity: 15.7049\n","[2021-04-13 00:13:39,739 INFO] Validation accuracy: 49.5563\n","[2021-04-13 00:13:41,311 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-13 00:17:33,155 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 00:17:54,966 INFO] number of examples: 802829\n","[2021-04-13 00:20:31,740 INFO] Step 12000/30000; acc:  57.48; ppl:  6.02; xent: 1.80; lr: 0.00081; 12086/13688 tok/s;   5691 sec\n","[2021-04-13 00:20:31,741 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 00:20:39,980 INFO] number of examples: 100400\n","[2021-04-13 00:21:40,448 INFO] Validation perplexity: 15.9114\n","[2021-04-13 00:21:40,448 INFO] Validation accuracy: 49.7262\n","[2021-04-13 00:21:42,045 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-13 00:25:53,846 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 00:26:29,620 INFO] number of examples: 802829\n","[2021-04-13 00:28:46,187 INFO] Step 13000/30000; acc:  58.95; ppl:  5.56; xent: 1.72; lr: 0.00078; 11595/13161 tok/s;   6185 sec\n","[2021-04-13 00:28:46,188 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 00:28:47,612 INFO] number of examples: 100400\n","[2021-04-13 00:29:47,409 INFO] Validation perplexity: 16.0533\n","[2021-04-13 00:29:47,409 INFO] Validation accuracy: 49.7142\n","[2021-04-13 00:29:49,039 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-13 00:34:21,053 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 00:34:46,512 INFO] number of examples: 802829\n","[2021-04-13 00:36:43,204 INFO] Step 14000/30000; acc:  60.44; ppl:  5.14; xent: 1.64; lr: 0.00075; 12035/13632 tok/s;   6662 sec\n","[2021-04-13 00:36:43,205 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 00:36:51,435 INFO] number of examples: 100400\n","[2021-04-13 00:37:52,015 INFO] Validation perplexity: 16.1415\n","[2021-04-13 00:37:52,015 INFO] Validation accuracy: 50.003\n","[2021-04-13 00:37:53,594 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-13 00:42:45,097 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 00:43:21,215 INFO] number of examples: 802829\n","[2021-04-13 00:44:57,746 INFO] Step 15000/30000; acc:  61.70; ppl:  4.82; xent: 1.57; lr: 0.00072; 11609/13158 tok/s;   7157 sec\n","[2021-04-13 00:44:57,747 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 00:44:59,244 INFO] number of examples: 100400\n","[2021-04-13 00:45:59,780 INFO] Validation perplexity: 16.5994\n","[2021-04-13 00:45:59,780 INFO] Validation accuracy: 50.0481\n","[2021-04-13 00:46:01,364 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-13 00:51:14,283 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 00:51:40,086 INFO] number of examples: 802829\n","[2021-04-13 00:52:55,328 INFO] Step 16000/30000; acc:  62.95; ppl:  4.53; xent: 1.51; lr: 0.00070; 12005/13619 tok/s;   7634 sec\n","[2021-04-13 00:52:55,329 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 00:52:56,754 INFO] number of examples: 100400\n","[2021-04-13 00:53:56,466 INFO] Validation perplexity: 16.8079\n","[2021-04-13 00:53:56,466 INFO] Validation accuracy: 50.1676\n","[2021-04-13 00:53:58,035 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-13 00:59:36,531 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 01:00:12,793 INFO] number of examples: 802829\n","[2021-04-13 01:01:07,732 INFO] Step 17000/30000; acc:  64.07; ppl:  4.29; xent: 1.46; lr: 0.00068; 11653/13162 tok/s;   8127 sec\n","[2021-04-13 01:01:07,733 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 01:01:09,117 INFO] number of examples: 100400\n","[2021-04-13 01:02:08,681 INFO] Validation perplexity: 17.0923\n","[2021-04-13 01:02:08,681 INFO] Validation accuracy: 50.2679\n","[2021-04-13 01:02:10,252 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-13 01:08:02,546 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 01:08:29,357 INFO] number of examples: 802829\n","[2021-04-13 01:09:03,264 INFO] Step 18000/30000; acc:  65.11; ppl:  4.09; xent: 1.41; lr: 0.00066; 12049/13655 tok/s;   8602 sec\n","[2021-04-13 01:09:03,265 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 01:09:04,667 INFO] number of examples: 100400\n","[2021-04-13 01:10:04,306 INFO] Validation perplexity: 18.8938\n","[2021-04-13 01:10:04,306 INFO] Validation accuracy: 49.8671\n","[2021-04-13 01:10:05,835 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-13 01:16:17,830 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 01:16:44,439 INFO] number of examples: 802829\n","[2021-04-13 01:16:58,361 INFO] Step 19000/30000; acc:  66.02; ppl:  3.91; xent: 1.36; lr: 0.00064; 12070/13716 tok/s;   9077 sec\n","[2021-04-13 01:16:58,362 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 01:16:59,818 INFO] number of examples: 100400\n","[2021-04-13 01:17:59,753 INFO] Validation perplexity: 18.4237\n","[2021-04-13 01:17:59,753 INFO] Validation accuracy: 50.0392\n","[2021-04-13 01:18:01,419 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-13 01:24:23,052 INFO] Step 20000/30000; acc:  66.88; ppl:  3.76; xent: 1.32; lr: 0.00062; 12889/14679 tok/s;   9522 sec\n","[2021-04-13 01:24:23,053 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 01:24:24,442 INFO] number of examples: 100400\n","[2021-04-13 01:25:24,275 INFO] Validation perplexity: 18.3591\n","[2021-04-13 01:25:24,276 INFO] Validation accuracy: 50.1411\n","[2021-04-13 01:25:25,828 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-13 01:25:45,270 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 01:26:11,768 INFO] number of examples: 802829\n","[2021-04-13 01:32:18,477 INFO] Step 21000/30000; acc:  67.74; ppl:  3.61; xent: 1.28; lr: 0.00061; 12088/13688 tok/s;   9997 sec\n","[2021-04-13 01:32:18,478 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 01:32:26,491 INFO] number of examples: 100400\n","[2021-04-13 01:33:26,523 INFO] Validation perplexity: 19.2933\n","[2021-04-13 01:33:26,523 INFO] Validation accuracy: 50.2847\n","[2021-04-13 01:33:28,069 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-13 01:34:09,240 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 01:34:43,763 INFO] number of examples: 802829\n","[2021-04-13 01:40:29,599 INFO] Step 22000/30000; acc:  68.50; ppl:  3.49; xent: 1.25; lr: 0.00060; 11711/13280 tok/s;  10488 sec\n","[2021-04-13 01:40:29,600 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 01:40:30,976 INFO] number of examples: 100400\n","[2021-04-13 01:41:30,909 INFO] Validation perplexity: 19.4168\n","[2021-04-13 01:41:30,909 INFO] Validation accuracy: 50.2412\n","[2021-04-13 01:41:32,458 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-13 01:42:34,109 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 01:42:59,420 INFO] number of examples: 802829\n","[2021-04-13 01:48:25,184 INFO] Step 23000/30000; acc:  69.23; ppl:  3.38; xent: 1.22; lr: 0.00058; 12099/13712 tok/s;  10964 sec\n","[2021-04-13 01:48:25,185 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 01:48:33,292 INFO] number of examples: 100400\n","[2021-04-13 01:49:33,316 INFO] Validation perplexity: 20.2989\n","[2021-04-13 01:49:33,317 INFO] Validation accuracy: 50.1978\n","[2021-04-13 01:49:34,860 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-13 01:50:57,282 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 01:51:32,779 INFO] number of examples: 802829\n","[2021-04-13 01:56:37,305 INFO] Step 24000/30000; acc:  69.97; ppl:  3.28; xent: 1.19; lr: 0.00057; 11681/13254 tok/s;  11456 sec\n","[2021-04-13 01:56:37,306 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 01:56:38,698 INFO] number of examples: 100400\n","[2021-04-13 01:57:37,698 INFO] Validation perplexity: 19.9532\n","[2021-04-13 01:57:37,698 INFO] Validation accuracy: 50.3385\n","[2021-04-13 01:57:39,206 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-13 01:59:21,092 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 01:59:46,515 INFO] number of examples: 802829\n","[2021-04-13 02:04:37,681 INFO] Step 25000/30000; acc:  70.66; ppl:  3.18; xent: 1.16; lr: 0.00056; 11935/13537 tok/s;  11937 sec\n","[2021-04-13 02:04:37,682 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 02:04:39,087 INFO] number of examples: 100400\n","[2021-04-13 02:05:38,974 INFO] Validation perplexity: 20.4474\n","[2021-04-13 02:05:38,974 INFO] Validation accuracy: 50.3681\n","[2021-04-13 02:05:40,519 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-13 02:07:44,018 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 02:08:19,016 INFO] number of examples: 802829\n","[2021-04-13 02:12:43,902 INFO] Step 26000/30000; acc:  71.32; ppl:  3.09; xent: 1.13; lr: 0.00055; 11805/13387 tok/s;  12423 sec\n","[2021-04-13 02:12:43,903 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 02:12:45,334 INFO] number of examples: 100400\n","[2021-04-13 02:13:46,038 INFO] Validation perplexity: 20.7145\n","[2021-04-13 02:13:46,039 INFO] Validation accuracy: 50.4052\n","[2021-04-13 02:13:47,612 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-13 02:16:16,704 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 02:16:53,160 INFO] number of examples: 802829\n","[2021-04-13 02:20:57,804 INFO] Step 27000/30000; acc:  71.86; ppl:  3.02; xent: 1.10; lr: 0.00054; 11603/13174 tok/s;  12917 sec\n","[2021-04-13 02:20:57,805 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 02:20:59,203 INFO] number of examples: 100400\n","[2021-04-13 02:21:58,926 INFO] Validation perplexity: 20.1592\n","[2021-04-13 02:21:58,926 INFO] Validation accuracy: 50.5251\n","[2021-04-13 02:22:00,490 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-13 02:24:43,894 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 02:25:11,353 INFO] number of examples: 802829\n","[2021-04-13 02:28:55,857 INFO] Step 28000/30000; acc:  72.43; ppl:  2.95; xent: 1.08; lr: 0.00053; 11988/13589 tok/s;  13395 sec\n","[2021-04-13 02:28:55,858 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 02:28:57,258 INFO] number of examples: 100400\n","[2021-04-13 02:29:57,188 INFO] Validation perplexity: 22.3449\n","[2021-04-13 02:29:57,188 INFO] Validation accuracy: 50.0268\n","[2021-04-13 02:29:58,755 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-13 02:33:01,751 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 02:33:29,685 INFO] number of examples: 802829\n","[2021-04-13 02:36:53,976 INFO] Step 29000/30000; acc:  73.00; ppl:  2.88; xent: 1.06; lr: 0.00052; 12004/13602 tok/s;  13873 sec\n","[2021-04-13 02:36:53,978 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 02:36:55,410 INFO] number of examples: 100400\n","[2021-04-13 02:37:55,826 INFO] Validation perplexity: 20.8093\n","[2021-04-13 02:37:55,826 INFO] Validation accuracy: 50.5716\n","[2021-04-13 02:37:57,458 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-13 02:41:20,446 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-13 02:41:41,925 INFO] number of examples: 802829\n","[2021-04-13 02:44:45,432 INFO] Step 30000/30000; acc:  73.50; ppl:  2.82; xent: 1.04; lr: 0.00051; 12152/13779 tok/s;  14344 sec\n","[2021-04-13 02:44:45,433 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-13 02:44:53,639 INFO] number of examples: 100400\n","[2021-04-13 02:45:53,430 INFO] Validation perplexity: 22.161\n","[2021-04-13 02:45:53,430 INFO] Validation accuracy: 50.5793\n","[2021-04-13 02:45:54,972 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618281965687,"user_tz":-420,"elapsed":14536600,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"5d1f4734-3ac4-4eec-f2e0-7ae55906442d"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 43403085\n","-rw------- 1 root root 1481491775 Apr 13 00:05 en-vi_step_10000.pt\n","-rw------- 1 root root 1481491775 Apr 12 22:53 en-vi_step_1000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:13 en-vi_step_11000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:21 en-vi_step_12000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:29 en-vi_step_13000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:37 en-vi_step_14000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:46 en-vi_step_15000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:54 en-vi_step_16000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:02 en-vi_step_17000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:10 en-vi_step_18000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:18 en-vi_step_19000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:25 en-vi_step_20000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:01 en-vi_step_2000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:33 en-vi_step_21000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:41 en-vi_step_22000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:49 en-vi_step_23000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:57 en-vi_step_24000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:05 en-vi_step_25000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:13 en-vi_step_26000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:22 en-vi_step_27000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:30 en-vi_step_28000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:38 en-vi_step_29000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:46 en-vi_step_30000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:09 en-vi_step_3000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:17 en-vi_step_4000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:25 en-vi_step_5000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:33 en-vi_step_6000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:41 en-vi_step_7000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:49 en-vi_step_8000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:57 en-vi_step_9000.pt\n","\n","model/:\n","total 43403085\n","-rw------- 1 root root 1481491775 Apr 13 00:05 en-vi_step_10000.pt\n","-rw------- 1 root root 1481491775 Apr 12 22:53 en-vi_step_1000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:13 en-vi_step_11000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:21 en-vi_step_12000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:29 en-vi_step_13000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:37 en-vi_step_14000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:46 en-vi_step_15000.pt\n","-rw------- 1 root root 1481491775 Apr 13 00:54 en-vi_step_16000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:02 en-vi_step_17000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:10 en-vi_step_18000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:18 en-vi_step_19000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:25 en-vi_step_20000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:01 en-vi_step_2000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:33 en-vi_step_21000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:41 en-vi_step_22000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:49 en-vi_step_23000.pt\n","-rw------- 1 root root 1481491775 Apr 13 01:57 en-vi_step_24000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:05 en-vi_step_25000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:13 en-vi_step_26000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:22 en-vi_step_27000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:30 en-vi_step_28000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:38 en-vi_step_29000.pt\n","-rw------- 1 root root 1481491775 Apr 13 02:46 en-vi_step_30000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:09 en-vi_step_3000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:17 en-vi_step_4000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:25 en-vi_step_5000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:33 en-vi_step_6000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:41 en-vi_step_7000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:49 en-vi_step_8000.pt\n","-rw------- 1 root root 1481491775 Apr 12 23:57 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618291865649,"user_tz":-420,"elapsed":24436560,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"22ea3a3d-299a-423a-d56f-9db7ad741a41"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-13 02:46:13,374 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-13 03:02:33,473 INFO] PRED AVG SCORE: -0.6370, PRED PPL: 1.8908\n","[2021-04-13 03:02:33,473 INFO] GOLD AVG SCORE: -3.0937, GOLD PPL: 22.0587\n","[2021-04-13 03:02:33,492 INFO] Translating shard 1.\n","tcmalloc: large alloc 1518125056 bytes == 0x55e9a6a54000 @  0x7f97b2cdeb6b 0x7f97b2cfe379 0x7f975f43725e 0x7f975f4389d2 0x7f979c11b8e6 0x7f979c57ddd9 0x7f979ca8877a 0x7f979ca53ef9 0x7f979ca0a657 0x7f979c8ae929 0x7f979c3c6516 0x7f979ca897af 0x7f979c838846 0x7f979c83de6f 0x7f979e121bcc 0x7f979e12213f 0x7f979cc8aa86 0x7f979cc8ecaf 0x7f979c3b816a 0x7f979c3b8b3a 0x7f979cb9d7f8 0x7f979cb9d83f 0x7f979c838846 0x7f979c83e22f 0x7f979c39c0b1 0x7f979cb9c4c0 0x7f979cbbf05d 0x7f979c98fa59 0x7f97adead8de 0x55e92a72e050 0x55e92a72dde0\n","tcmalloc: large alloc 1518125056 bytes == 0x55ea01220000 @  0x7f97b2cdeb6b 0x7f97b2cfe379 0x7f975f43725e 0x7f975f4389d2 0x7f979c11b8e6 0x7f979c57ddd9 0x7f979ca8877a 0x7f979ca53ef9 0x7f979ca0a657 0x7f979c8ae929 0x7f979c5876a2 0x7f979c5175c5 0x7f979ca89573 0x7f979c9f9904 0x7f979c863f09 0x7f979e0ab444 0x7f979e0ab783 0x7f979c9f9904 0x7f979c863f09 0x7f979c5105d0 0x7f979cb9d0e0 0x7f979cb9d132 0x7f979ca07054 0x7f979ccab735 0x7f97adc0af4f 0x55e92a72e050 0x55e92a81f99d 0x55e92a7a1fe9 0x55e92a79cb0e 0x55e92a72f77a 0x55e92a79e86a\n","[2021-04-13 03:18:50,553 INFO] PRED AVG SCORE: -0.6383, PRED PPL: 1.8933\n","[2021-04-13 03:18:50,553 INFO] GOLD AVG SCORE: -3.1000, GOLD PPL: 22.1982\n","[2021-04-13 03:18:50,573 INFO] Translating shard 2.\n","[2021-04-13 03:35:26,412 INFO] PRED AVG SCORE: -0.6372, PRED PPL: 1.8911\n","[2021-04-13 03:35:26,412 INFO] GOLD AVG SCORE: -3.1013, GOLD PPL: 22.2274\n","[2021-04-13 03:35:26,432 INFO] Translating shard 3.\n","[2021-04-13 03:51:49,688 INFO] PRED AVG SCORE: -0.6395, PRED PPL: 1.8956\n","[2021-04-13 03:51:49,688 INFO] GOLD AVG SCORE: -3.0732, GOLD PPL: 21.6107\n","[2021-04-13 03:51:49,708 INFO] Translating shard 4.\n","[2021-04-13 04:08:25,530 INFO] PRED AVG SCORE: -0.6366, PRED PPL: 1.8901\n","[2021-04-13 04:08:25,530 INFO] GOLD AVG SCORE: -3.1020, GOLD PPL: 22.2428\n","[2021-04-13 04:08:25,549 INFO] Translating shard 5.\n","[2021-04-13 04:25:07,555 INFO] PRED AVG SCORE: -0.6373, PRED PPL: 1.8913\n","[2021-04-13 04:25:07,556 INFO] GOLD AVG SCORE: -3.0804, GOLD PPL: 21.7666\n","[2021-04-13 04:25:07,576 INFO] Translating shard 6.\n","[2021-04-13 04:41:41,331 INFO] PRED AVG SCORE: -0.6390, PRED PPL: 1.8945\n","[2021-04-13 04:41:41,331 INFO] GOLD AVG SCORE: -3.0716, GOLD PPL: 21.5766\n","[2021-04-13 04:41:41,351 INFO] Translating shard 7.\n","[2021-04-13 04:57:58,816 INFO] PRED AVG SCORE: -0.6379, PRED PPL: 1.8925\n","[2021-04-13 04:57:58,817 INFO] GOLD AVG SCORE: -3.0676, GOLD PPL: 21.4911\n","[2021-04-13 04:57:58,837 INFO] Translating shard 8.\n","[2021-04-13 05:14:02,683 INFO] PRED AVG SCORE: -0.6389, PRED PPL: 1.8944\n","[2021-04-13 05:14:02,683 INFO] GOLD AVG SCORE: -3.0962, GOLD PPL: 22.1143\n","[2021-04-13 05:14:02,703 INFO] Translating shard 9.\n","[2021-04-13 05:30:23,395 INFO] PRED AVG SCORE: -0.6405, PRED PPL: 1.8974\n","[2021-04-13 05:30:23,395 INFO] GOLD AVG SCORE: -3.0804, GOLD PPL: 21.7672\n","[2021-04-13 05:30:23,414 INFO] Translating shard 10.\n","[2021-04-13 05:31:04,166 INFO] PRED AVG SCORE: -0.6375, PRED PPL: 1.8918\n","[2021-04-13 05:31:04,166 INFO] GOLD AVG SCORE: -2.9996, GOLD PPL: 20.0777\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618291865651,"user_tz":-420,"elapsed":24436561,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"4d144513-d6b9-450d-ba54-47a73fd57cb8"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["And nobody questions him, because they don't want to hear the answer because it's a lie!\n","Kubo?\n","Họ rất vui vẻ, và lúc nào cũng hát với nến.\n","Nghe này, anh không thể nói chuyện bây giờ được.\n","Vậy thì con có thể dùng trí tưởng tượng của mình.\n","Không hề.\n","Tôi đang nhìn hắn ngay lúc này đây.\n","Bác không để tâm chứ?\n","Anh nghĩ cậu ta phản ứng với thuốc?\n","Bị làm sao mà anh lại đi dự lễ đặt tên em bé của Cuddy chứ?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618291894522,"user_tz":-420,"elapsed":24465430,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"78f70ac1-c459-4675-b9aa-ff46586735a1"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 29, done.\u001b[K\n","remote: Counting objects: 100% (29/29), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 17114 (delta 7), reused 8 (delta 4), pack-reused 17085\u001b[K\n","Receiving objects: 100% (17114/17114), 273.05 MiB | 12.12 MiB/s, done.\n","Resolving deltas: 100% (12323/12323), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618291894523,"user_tz":-420,"elapsed":24465429,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"91e2c27e-5632-4111-b917-71396f8ab218"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 376593\n","drwx------  2 root root      4096 Apr 12 22:44 data_bin\n","-rw-------  1 root root   3318349 Apr 12 01:48 en_test\n","-rw-------  1 root root  26563375 Apr 12 01:48 en_train\n","-rw-------  1 root root  34866334 Apr 12 01:07 en_train_EM_0.8\n","-rw-------  1 root root  32006284 Apr 12 01:07 en_train_EM_0.85\n","-rw-------  1 root root  29696900 Apr 12 01:07 en_train_EM_0.9\n","-rw-------  1 root root  27849828 Apr 12 01:07 en_train_EM_0.95\n","-rw-------  1 root root  13223858 Apr 12 01:07 en_train_EM_factor_0.8\n","-rw-------  1 root root  12138268 Apr 12 01:07 en_train_EM_factor_0.85\n","-rw-------  1 root root  11254364 Apr 12 01:07 en_train_EM_factor_0.9\n","-rw-------  1 root root  10539008 Apr 12 01:07 en_train_EM_factor_0.95\n","-rw-------  1 root root   8152745 Apr 12 01:07 en_train_EM_score_0.8\n","-rw-------  1 root root   8152745 Apr 12 01:07 en_train_EM_score_0.85\n","-rw-------  1 root root   8152745 Apr 12 01:07 en_train_EM_score_0.9\n","-rw-------  1 root root   8152745 Apr 12 01:07 en_train_EM_score_0.95\n","-rw-------  1 root root   3328557 Apr 12 01:48 en_valid\n","drwx------  2 root root      4096 Apr 13 02:46 model\n","drwx------ 11 root root      4096 Apr 13 05:31 OpenNMT-py\n","-rw-------  1 root root 100661014 Apr 12 22:44 opus_bert.tar.gz\n","drwx------  2 root root      4096 Apr 12 22:45 output\n","-rw-------  1 root root   3784107 Apr 13 05:31 predict.txt\n","-rw-------  1 root root   4365722 Apr 12 01:48 vi_test\n","-rw-------  1 root root  35019161 Apr 12 01:48 vi_train\n","-rw-------  1 root root   4382771 Apr 12 01:48 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618291901091,"user_tz":-420,"elapsed":24471996,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"0efb41f4-cf7b-47d3-817d-682093542a3d"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 16.54, 41.8/23.4/14.2/9.4 (BP=0.870, ratio=0.878, hyp_len=665898, ref_len=758454)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1618291901092,"user_tz":-420,"elapsed":24471995,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}