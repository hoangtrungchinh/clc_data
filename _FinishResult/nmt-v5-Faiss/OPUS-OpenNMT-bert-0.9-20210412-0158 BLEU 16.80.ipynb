{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OPUS-OpenNMT-bert-0.9-20210412-0158 BLEU 16.80.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267004870,"user_tz":-420,"elapsed":20939,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e6a2c1d9-3fcf-4359-dfe6-80d0c2ca6953"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267024053,"user_tz":-420,"elapsed":2263,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"006eac71-1610-4ffd-99a9-6b16e722b600"},"source":["# import os\n","# path = \"\"\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","# os.chdir(path)\n","# import time\n","# FOLDERNAME = \"OPUS-OpenNMT-bert-0.9-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","# !mkdir $FOLDERNAME\n","\n","# path = path + FOLDERNAME\n","# os.chdir(path)\n","# !pwd\n","\n","import os\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/OPUS-OpenNMT-bert-0.9-20210412-0158'\n","os.chdir(path)\n","!pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/OPUS-OpenNMT-bert-0.9-20210412-0158\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267027021,"user_tz":-420,"elapsed":821,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"3a3932fb-2f48-477b-daf0-388579b7ffdd"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mon Apr 12 22:37:06 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267045317,"user_tz":-420,"elapsed":14072,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"16da704e-4358-4c90-9b21-a57dd58f8f3b"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\r\u001b[K     |█▊                              | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 10.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Collecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Collecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n","\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 27.2MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=cdb604d9a97b777bead7cac66253b4961c4dd15bdde10f2089e1ddb16ff5ebaf\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: configargparse, torchtext, waitress, pyonmttok, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618192718136,"user_tz":-420,"elapsed":45419,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"a7d4d6b3-6826-4e32-d1a4-9c9006c25c20"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/opus_bert.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'opus_bert.tar.gz'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-04-12 01:58:31--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/opus_bert.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 100661014 (96M) [application/octet-stream]\n","Saving to: ‘opus_bert.tar.gz’\n","\n","opus_bert.tar.gz    100%[===================>]  96.00M  64.8MB/s    in 1.5s    \n","\n","2021-04-12 01:58:33 (64.8 MB/s) - ‘opus_bert.tar.gz’ saved [100661014/100661014]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618192779234,"user_tz":-420,"elapsed":106514,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"d7ea0ec9-3783-4c18-9032-f552db5c5f85"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.9' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2021-04-12 01:58:41,724 INFO] Extracting features...\n","[2021-04-12 01:58:41,733 INFO]  * number of source features: 0.\n","[2021-04-12 01:58:41,733 INFO]  * number of target features: 0.\n","[2021-04-12 01:58:41,733 INFO] Building `Fields` object...\n","[2021-04-12 01:58:41,733 INFO] Building & saving training data...\n","[2021-04-12 01:58:43,068 INFO] Building shard 0.\n","[2021-04-12 01:59:14,478 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-12 01:59:32,198 INFO]  * tgt vocab size: 50004.\n","[2021-04-12 01:59:32,517 INFO]  * src vocab size: 50002.\n","[2021-04-12 01:59:33,130 INFO] Building & saving validation data...\n","[2021-04-12 01:59:33,691 INFO] Building shard 0.\n","[2021-04-12 01:59:35,967 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618217201708,"user_tz":-420,"elapsed":4977150,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"c8f19910-202e-4cf5-97a6-a717a863d18b"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-12 01:59:42,348 INFO]  * src vocab size = 50002\n","[2021-04-12 01:59:42,349 INFO]  * tgt vocab size = 50004\n","[2021-04-12 01:59:42,349 INFO] Building model...\n","[2021-04-12 01:59:50,356 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50002, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=50004, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-12 01:59:50,363 INFO] encoder: 44516352\n","[2021-04-12 01:59:50,363 INFO] decoder: 76479316\n","[2021-04-12 01:59:50,363 INFO] * number of parameters: 120995668\n","[2021-04-12 01:59:50,367 INFO] Starting training on GPU: [0]\n","[2021-04-12 01:59:50,368 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-12 01:59:50,368 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 02:00:08,719 INFO] number of examples: 802833\n","[2021-04-12 02:11:24,605 INFO] Step 1000/30000; acc:  13.52; ppl: 561.41; xent: 6.33; lr: 0.00012; 8033/9824 tok/s;    694 sec\n","[2021-04-12 02:11:24,607 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 02:11:26,299 INFO] number of examples: 100400\n","[2021-04-12 02:13:00,477 INFO] Validation perplexity: 272.865\n","[2021-04-12 02:13:00,477 INFO] Validation accuracy: 19.0278\n","[2021-04-12 02:13:01,991 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-12 02:13:12,207 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 02:13:38,748 INFO] number of examples: 802833\n","[2021-04-12 02:24:56,400 INFO] Step 2000/30000; acc:  27.45; ppl: 70.03; xent: 4.25; lr: 0.00025; 6869/8403 tok/s;   1506 sec\n","[2021-04-12 02:24:56,401 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 02:24:57,832 INFO] number of examples: 100400\n","[2021-04-12 02:26:30,777 INFO] Validation perplexity: 56.7713\n","[2021-04-12 02:26:30,777 INFO] Validation accuracy: 35.7875\n","[2021-04-12 02:26:32,274 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-12 02:26:46,719 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 02:27:19,956 INFO] number of examples: 802833\n","[2021-04-12 02:38:30,631 INFO] Step 3000/30000; acc:  38.74; ppl: 26.28; xent: 3.27; lr: 0.00037; 6842/8378 tok/s;   2320 sec\n","[2021-04-12 02:38:30,633 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 02:38:35,473 INFO] number of examples: 100400\n","[2021-04-12 02:40:07,924 INFO] Validation perplexity: 28.2904\n","[2021-04-12 02:40:07,924 INFO] Validation accuracy: 42.6588\n","[2021-04-12 02:40:09,417 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-12 02:40:27,809 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 02:40:54,106 INFO] number of examples: 802833\n","[2021-04-12 02:51:59,460 INFO] Step 4000/30000; acc:  43.81; ppl: 16.58; xent: 2.81; lr: 0.00049; 6894/8441 tok/s;   3129 sec\n","[2021-04-12 02:51:59,461 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 02:52:00,941 INFO] number of examples: 100400\n","[2021-04-12 02:53:34,108 INFO] Validation perplexity: 21.3603\n","[2021-04-12 02:53:34,108 INFO] Validation accuracy: 45.4233\n","[2021-04-12 02:53:35,597 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-12 02:53:59,031 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 02:54:27,681 INFO] number of examples: 802833\n","[2021-04-12 03:05:29,683 INFO] Step 5000/30000; acc:  46.59; ppl: 12.98; xent: 2.56; lr: 0.00062; 6884/8425 tok/s;   3939 sec\n","[2021-04-12 03:05:29,685 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 03:05:31,156 INFO] number of examples: 100400\n","[2021-04-12 03:07:03,383 INFO] Validation perplexity: 18.8741\n","[2021-04-12 03:07:03,383 INFO] Validation accuracy: 46.7966\n","[2021-04-12 03:07:04,895 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-12 03:07:32,126 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 03:07:59,936 INFO] number of examples: 802833\n","[2021-04-12 03:18:57,605 INFO] Step 6000/30000; acc:  48.37; ppl: 11.12; xent: 2.41; lr: 0.00074; 6903/8438 tok/s;   4747 sec\n","[2021-04-12 03:18:57,606 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 03:18:59,085 INFO] number of examples: 100400\n","[2021-04-12 03:20:31,433 INFO] Validation perplexity: 18.1667\n","[2021-04-12 03:20:31,434 INFO] Validation accuracy: 47.0585\n","[2021-04-12 03:20:32,883 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-12 03:21:03,938 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 03:21:32,146 INFO] number of examples: 802833\n","[2021-04-12 03:32:26,738 INFO] Step 7000/30000; acc:  49.75; ppl:  9.94; xent: 2.30; lr: 0.00086; 6889/8437 tok/s;   5556 sec\n","[2021-04-12 03:32:26,739 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 03:32:28,240 INFO] number of examples: 100400\n","[2021-04-12 03:34:00,533 INFO] Validation perplexity: 17.0527\n","[2021-04-12 03:34:00,533 INFO] Validation accuracy: 47.6517\n","[2021-04-12 03:34:02,031 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-12 03:34:36,617 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 03:35:04,805 INFO] number of examples: 802833\n","[2021-04-12 03:45:54,899 INFO] Step 8000/30000; acc:  50.95; ppl:  9.06; xent: 2.20; lr: 0.00099; 6900/8442 tok/s;   6365 sec\n","[2021-04-12 03:45:54,900 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 03:45:56,437 INFO] number of examples: 100400\n","[2021-04-12 03:47:28,979 INFO] Validation perplexity: 16.7487\n","[2021-04-12 03:47:28,980 INFO] Validation accuracy: 47.9627\n","[2021-04-12 03:47:30,500 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-12 03:48:09,822 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 03:48:32,569 INFO] number of examples: 802833\n","[2021-04-12 03:59:18,679 INFO] Step 9000/30000; acc:  52.43; ppl:  8.16; xent: 2.10; lr: 0.00093; 6936/8484 tok/s;   7168 sec\n","[2021-04-12 03:59:18,681 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 03:59:25,850 INFO] number of examples: 100400\n","[2021-04-12 04:00:58,300 INFO] Validation perplexity: 16.9301\n","[2021-04-12 04:00:58,300 INFO] Validation accuracy: 48.1111\n","[2021-04-12 04:00:59,771 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-12 04:01:42,887 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 04:02:17,291 INFO] number of examples: 802833\n","[2021-04-12 04:12:59,940 INFO] Step 10000/30000; acc:  54.40; ppl:  7.20; xent: 1.97; lr: 0.00088; 6788/8313 tok/s;   7990 sec\n","[2021-04-12 04:12:59,941 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 04:13:01,490 INFO] number of examples: 100400\n","[2021-04-12 04:14:34,220 INFO] Validation perplexity: 16.236\n","[2021-04-12 04:14:34,220 INFO] Validation accuracy: 48.9412\n","[2021-04-12 04:14:35,704 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-12 04:15:22,363 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 04:15:55,382 INFO] number of examples: 802833\n","[2021-04-12 04:26:33,928 INFO] Step 11000/30000; acc:  56.22; ppl:  6.46; xent: 1.87; lr: 0.00084; 6848/8379 tok/s;   8804 sec\n","[2021-04-12 04:26:33,929 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 04:26:35,493 INFO] number of examples: 100400\n","[2021-04-12 04:28:08,226 INFO] Validation perplexity: 16.0056\n","[2021-04-12 04:28:08,227 INFO] Validation accuracy: 49.3258\n","[2021-04-12 04:28:09,768 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-12 04:29:00,606 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 04:29:23,475 INFO] number of examples: 802833\n","[2021-04-12 04:39:57,544 INFO] Step 12000/30000; acc:  57.98; ppl:  5.87; xent: 1.77; lr: 0.00081; 6945/8490 tok/s;   9607 sec\n","[2021-04-12 04:39:57,545 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 04:40:04,911 INFO] number of examples: 100400\n","[2021-04-12 04:41:37,492 INFO] Validation perplexity: 16.4501\n","[2021-04-12 04:41:37,492 INFO] Validation accuracy: 49.5481\n","[2021-04-12 04:41:38,975 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-12 04:42:34,855 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 04:43:09,756 INFO] number of examples: 802833\n","[2021-04-12 04:53:40,386 INFO] Step 13000/30000; acc:  59.52; ppl:  5.40; xent: 1.69; lr: 0.00078; 6775/8294 tok/s;  10430 sec\n","[2021-04-12 04:53:40,387 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 04:53:41,945 INFO] number of examples: 100400\n","[2021-04-12 04:55:14,601 INFO] Validation perplexity: 16.0351\n","[2021-04-12 04:55:14,602 INFO] Validation accuracy: 49.8876\n","[2021-04-12 04:55:16,114 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-12 04:56:15,142 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 04:56:41,934 INFO] number of examples: 802833\n","[2021-04-12 05:07:08,124 INFO] Step 14000/30000; acc:  60.97; ppl:  5.01; xent: 1.61; lr: 0.00075; 6901/8445 tok/s;  11238 sec\n","[2021-04-12 05:07:08,125 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 05:07:15,365 INFO] number of examples: 100400\n","[2021-04-12 05:08:47,780 INFO] Validation perplexity: 16.6305\n","[2021-04-12 05:08:47,780 INFO] Validation accuracy: 49.8881\n","[2021-04-12 05:08:49,228 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-12 05:09:52,224 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 05:10:26,991 INFO] number of examples: 802833\n","[2021-04-12 05:20:49,477 INFO] Step 15000/30000; acc:  62.28; ppl:  4.69; xent: 1.54; lr: 0.00072; 6791/8303 tok/s;  12059 sec\n","[2021-04-12 05:20:49,478 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 05:20:51,049 INFO] number of examples: 100400\n","[2021-04-12 05:22:24,062 INFO] Validation perplexity: 17.0338\n","[2021-04-12 05:22:24,063 INFO] Validation accuracy: 50.091\n","[2021-04-12 05:22:25,573 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-12 05:23:32,759 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 05:24:00,476 INFO] number of examples: 802833\n","[2021-04-12 05:34:19,051 INFO] Step 16000/30000; acc:  63.48; ppl:  4.42; xent: 1.49; lr: 0.00070; 6886/8423 tok/s;  12869 sec\n","[2021-04-12 05:34:19,052 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 05:34:26,429 INFO] number of examples: 100400\n","[2021-04-12 05:35:58,955 INFO] Validation perplexity: 17.0378\n","[2021-04-12 05:35:58,956 INFO] Validation accuracy: 50.1404\n","[2021-04-12 05:36:00,473 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-12 05:37:11,536 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 05:37:46,702 INFO] number of examples: 802833\n","[2021-04-12 05:48:01,263 INFO] Step 17000/30000; acc:  64.58; ppl:  4.19; xent: 1.43; lr: 0.00068; 6778/8300 tok/s;  13691 sec\n","[2021-04-12 05:48:01,264 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 05:48:02,781 INFO] number of examples: 100400\n","[2021-04-12 05:49:35,465 INFO] Validation perplexity: 17.5368\n","[2021-04-12 05:49:35,465 INFO] Validation accuracy: 50.1273\n","[2021-04-12 05:49:37,002 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-12 05:50:52,060 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 05:51:19,645 INFO] number of examples: 802833\n","[2021-04-12 06:01:29,997 INFO] Step 18000/30000; acc:  65.61; ppl:  3.99; xent: 1.38; lr: 0.00066; 6894/8434 tok/s;  14500 sec\n","[2021-04-12 06:01:29,998 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 06:01:37,422 INFO] number of examples: 100400\n","[2021-04-12 06:03:10,409 INFO] Validation perplexity: 18.0194\n","[2021-04-12 06:03:10,409 INFO] Validation accuracy: 50.2394\n","[2021-04-12 06:03:11,945 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-12 06:04:31,004 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 06:05:08,267 INFO] number of examples: 802833\n","[2021-04-12 06:15:16,470 INFO] Step 19000/30000; acc:  66.57; ppl:  3.81; xent: 1.34; lr: 0.00064; 6749/8250 tok/s;  15326 sec\n","[2021-04-12 06:15:16,472 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 06:15:18,099 INFO] number of examples: 100400\n","[2021-04-12 06:16:51,089 INFO] Validation perplexity: 18.2971\n","[2021-04-12 06:16:51,089 INFO] Validation accuracy: 50.2216\n","[2021-04-12 06:16:52,609 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-12 06:18:15,786 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 06:18:45,029 INFO] number of examples: 802833\n","[2021-04-12 06:28:47,099 INFO] Step 20000/30000; acc:  67.50; ppl:  3.66; xent: 1.30; lr: 0.00062; 6881/8409 tok/s;  16137 sec\n","[2021-04-12 06:28:47,100 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 06:28:48,643 INFO] number of examples: 100400\n","[2021-04-12 06:30:22,247 INFO] Validation perplexity: 18.6958\n","[2021-04-12 06:30:22,247 INFO] Validation accuracy: 50.2503\n","[2021-04-12 06:30:23,782 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-12 06:31:51,450 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 06:32:15,413 INFO] number of examples: 802833\n","[2021-04-12 06:42:14,852 INFO] Step 21000/30000; acc:  68.30; ppl:  3.53; xent: 1.26; lr: 0.00061; 6904/8445 tok/s;  16944 sec\n","[2021-04-12 06:42:14,853 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 06:42:22,337 INFO] number of examples: 100400\n","[2021-04-12 06:43:55,271 INFO] Validation perplexity: 19.1766\n","[2021-04-12 06:43:55,271 INFO] Validation accuracy: 50.2641\n","[2021-04-12 06:43:56,757 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-12 06:45:28,526 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 06:46:03,573 INFO] number of examples: 802833\n","[2021-04-12 06:55:57,304 INFO] Step 22000/30000; acc:  69.11; ppl:  3.40; xent: 1.22; lr: 0.00060; 6784/8290 tok/s;  17767 sec\n","[2021-04-12 06:55:57,305 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 06:55:58,826 INFO] number of examples: 100400\n","[2021-04-12 06:57:31,578 INFO] Validation perplexity: 20.3614\n","[2021-04-12 06:57:31,578 INFO] Validation accuracy: 50.2723\n","[2021-04-12 06:57:33,068 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-12 06:59:09,058 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 06:59:42,856 INFO] number of examples: 802833\n","[2021-04-12 07:09:32,640 INFO] Step 23000/30000; acc:  69.84; ppl:  3.30; xent: 1.19; lr: 0.00058; 6840/8364 tok/s;  18582 sec\n","[2021-04-12 07:09:32,641 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 07:09:34,204 INFO] number of examples: 100400\n","[2021-04-12 07:11:06,630 INFO] Validation perplexity: 20.6913\n","[2021-04-12 07:11:06,630 INFO] Validation accuracy: 50.2142\n","[2021-04-12 07:11:08,113 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-12 07:12:48,137 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 07:13:11,346 INFO] number of examples: 802833\n","[2021-04-12 07:22:57,831 INFO] Step 24000/30000; acc:  70.53; ppl:  3.20; xent: 1.16; lr: 0.00057; 6926/8481 tok/s;  19387 sec\n","[2021-04-12 07:22:57,832 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 07:23:05,312 INFO] number of examples: 100400\n","[2021-04-12 07:24:38,779 INFO] Validation perplexity: 20.5004\n","[2021-04-12 07:24:38,779 INFO] Validation accuracy: 50.281\n","[2021-04-12 07:24:40,346 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-12 07:26:24,311 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 07:27:00,151 INFO] number of examples: 802833\n","[2021-04-12 07:36:43,822 INFO] Step 25000/30000; acc:  71.20; ppl:  3.11; xent: 1.13; lr: 0.00056; 6748/8257 tok/s;  20213 sec\n","[2021-04-12 07:36:43,823 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 07:36:45,359 INFO] number of examples: 100400\n","[2021-04-12 07:38:18,439 INFO] Validation perplexity: 20.3658\n","[2021-04-12 07:38:18,439 INFO] Validation accuracy: 50.4277\n","[2021-04-12 07:38:20,035 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-12 07:40:08,964 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 07:40:36,359 INFO] number of examples: 802833\n","[2021-04-12 07:50:14,591 INFO] Step 26000/30000; acc:  71.83; ppl:  3.03; xent: 1.11; lr: 0.00055; 6878/8414 tok/s;  21024 sec\n","[2021-04-12 07:50:14,592 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 07:50:22,013 INFO] number of examples: 100400\n","[2021-04-12 07:51:55,173 INFO] Validation perplexity: 21.1427\n","[2021-04-12 07:51:55,173 INFO] Validation accuracy: 50.3178\n","[2021-04-12 07:51:56,702 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-12 07:53:49,007 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 07:54:24,462 INFO] number of examples: 802833\n","[2021-04-12 08:03:58,597 INFO] Step 27000/30000; acc:  72.43; ppl:  2.95; xent: 1.08; lr: 0.00054; 6768/8278 tok/s;  21848 sec\n","[2021-04-12 08:03:58,598 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 08:04:00,173 INFO] number of examples: 100400\n","[2021-04-12 08:05:33,406 INFO] Validation perplexity: 22.4296\n","[2021-04-12 08:05:33,407 INFO] Validation accuracy: 50.4217\n","[2021-04-12 08:05:34,936 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-12 08:07:31,838 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 08:08:05,508 INFO] number of examples: 802833\n","[2021-04-12 08:17:35,047 INFO] Step 28000/30000; acc:  72.98; ppl:  2.88; xent: 1.06; lr: 0.00053; 6832/8352 tok/s;  22665 sec\n","[2021-04-12 08:17:35,048 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 08:17:36,625 INFO] number of examples: 100400\n","[2021-04-12 08:19:09,921 INFO] Validation perplexity: 22.7051\n","[2021-04-12 08:19:09,921 INFO] Validation accuracy: 50.4449\n","[2021-04-12 08:19:11,444 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-12 08:21:12,147 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 08:21:35,694 INFO] number of examples: 802833\n","[2021-04-12 08:31:07,840 INFO] Step 29000/30000; acc:  73.53; ppl:  2.82; xent: 1.04; lr: 0.00052; 6863/8393 tok/s;  23477 sec\n","[2021-04-12 08:31:07,841 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 08:31:09,432 INFO] number of examples: 100400\n","[2021-04-12 08:32:42,290 INFO] Validation perplexity: 22.3976\n","[2021-04-12 08:32:42,290 INFO] Validation accuracy: 50.3095\n","[2021-04-12 08:32:43,868 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-12 08:34:49,093 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-12 08:35:24,167 INFO] number of examples: 802833\n","[2021-04-12 08:44:46,022 INFO] Step 30000/30000; acc:  74.05; ppl:  2.76; xent: 1.02; lr: 0.00051; 6814/8332 tok/s;  24296 sec\n","[2021-04-12 08:44:46,023 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-12 08:44:53,521 INFO] number of examples: 100400\n","[2021-04-12 08:46:27,410 INFO] Validation perplexity: 22.814\n","[2021-04-12 08:46:27,410 INFO] Validation accuracy: 50.193\n","[2021-04-12 08:46:28,974 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618217201710,"user_tz":-420,"elapsed":26,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"31ecdb61-8720-4104-85bb-13d5ba3a6a2c"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 43400745\n","-rw------- 1 root root 1481411711 Apr 12 04:14 en-vi_step_10000.pt\n","-rw------- 1 root root 1481411711 Apr 12 02:13 en-vi_step_1000.pt\n","-rw------- 1 root root 1481411711 Apr 12 04:28 en-vi_step_11000.pt\n","-rw------- 1 root root 1481411711 Apr 12 04:41 en-vi_step_12000.pt\n","-rw------- 1 root root 1481411711 Apr 12 04:55 en-vi_step_13000.pt\n","-rw------- 1 root root 1481411711 Apr 12 05:08 en-vi_step_14000.pt\n","-rw------- 1 root root 1481411711 Apr 12 05:22 en-vi_step_15000.pt\n","-rw------- 1 root root 1481411711 Apr 12 05:36 en-vi_step_16000.pt\n","-rw------- 1 root root 1481411711 Apr 12 05:49 en-vi_step_17000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:03 en-vi_step_18000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:16 en-vi_step_19000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:30 en-vi_step_20000.pt\n","-rw------- 1 root root 1481411711 Apr 12 02:26 en-vi_step_2000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:44 en-vi_step_21000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:57 en-vi_step_22000.pt\n","-rw------- 1 root root 1481411711 Apr 12 07:11 en-vi_step_23000.pt\n","-rw------- 1 root root 1481411711 Apr 12 07:24 en-vi_step_24000.pt\n","-rw------- 1 root root 1481411711 Apr 12 07:38 en-vi_step_25000.pt\n","-rw------- 1 root root 1481411711 Apr 12 07:52 en-vi_step_26000.pt\n","-rw------- 1 root root 1481411711 Apr 12 08:05 en-vi_step_27000.pt\n","-rw------- 1 root root 1481411711 Apr 12 08:19 en-vi_step_28000.pt\n","-rw------- 1 root root 1481411711 Apr 12 08:32 en-vi_step_29000.pt\n","-rw------- 1 root root 1481411711 Apr 12 08:46 en-vi_step_30000.pt\n","-rw------- 1 root root 1481411711 Apr 12 02:40 en-vi_step_3000.pt\n","-rw------- 1 root root 1481411711 Apr 12 02:53 en-vi_step_4000.pt\n","-rw------- 1 root root 1481411711 Apr 12 03:07 en-vi_step_5000.pt\n","-rw------- 1 root root 1481411711 Apr 12 03:20 en-vi_step_6000.pt\n","-rw------- 1 root root 1481411711 Apr 12 03:34 en-vi_step_7000.pt\n","-rw------- 1 root root 1481411711 Apr 12 03:47 en-vi_step_8000.pt\n","-rw------- 1 root root 1481411711 Apr 12 04:01 en-vi_step_9000.pt\n","\n","model/:\n","total 43400745\n","-rw------- 1 root root 1481411711 Apr 12 04:14 en-vi_step_10000.pt\n","-rw------- 1 root root 1481411711 Apr 12 02:13 en-vi_step_1000.pt\n","-rw------- 1 root root 1481411711 Apr 12 04:28 en-vi_step_11000.pt\n","-rw------- 1 root root 1481411711 Apr 12 04:41 en-vi_step_12000.pt\n","-rw------- 1 root root 1481411711 Apr 12 04:55 en-vi_step_13000.pt\n","-rw------- 1 root root 1481411711 Apr 12 05:08 en-vi_step_14000.pt\n","-rw------- 1 root root 1481411711 Apr 12 05:22 en-vi_step_15000.pt\n","-rw------- 1 root root 1481411711 Apr 12 05:36 en-vi_step_16000.pt\n","-rw------- 1 root root 1481411711 Apr 12 05:49 en-vi_step_17000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:03 en-vi_step_18000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:16 en-vi_step_19000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:30 en-vi_step_20000.pt\n","-rw------- 1 root root 1481411711 Apr 12 02:26 en-vi_step_2000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:44 en-vi_step_21000.pt\n","-rw------- 1 root root 1481411711 Apr 12 06:57 en-vi_step_22000.pt\n","-rw------- 1 root root 1481411711 Apr 12 07:11 en-vi_step_23000.pt\n","-rw------- 1 root root 1481411711 Apr 12 07:24 en-vi_step_24000.pt\n","-rw------- 1 root root 1481411711 Apr 12 07:38 en-vi_step_25000.pt\n","-rw------- 1 root root 1481411711 Apr 12 07:52 en-vi_step_26000.pt\n","-rw------- 1 root root 1481411711 Apr 12 08:05 en-vi_step_27000.pt\n","-rw------- 1 root root 1481411711 Apr 12 08:19 en-vi_step_28000.pt\n","-rw------- 1 root root 1481411711 Apr 12 08:32 en-vi_step_29000.pt\n","-rw------- 1 root root 1481411711 Apr 12 08:46 en-vi_step_30000.pt\n","-rw------- 1 root root 1481411711 Apr 12 02:40 en-vi_step_3000.pt\n","-rw------- 1 root root 1481411711 Apr 12 02:53 en-vi_step_4000.pt\n","-rw------- 1 root root 1481411711 Apr 12 03:07 en-vi_step_5000.pt\n","-rw------- 1 root root 1481411711 Apr 12 03:20 en-vi_step_6000.pt\n","-rw------- 1 root root 1481411711 Apr 12 03:34 en-vi_step_7000.pt\n","-rw------- 1 root root 1481411711 Apr 12 03:47 en-vi_step_8000.pt\n","-rw------- 1 root root 1481411711 Apr 12 04:01 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618229462638,"user_tz":-420,"elapsed":12260947,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"389ca62d-3792-4d38-d1d9-400d9d19b697"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-12 08:46:49,554 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-12 09:06:44,620 INFO] PRED AVG SCORE: -0.6386, PRED PPL: 1.8939\n","[2021-04-12 09:06:44,621 INFO] GOLD AVG SCORE: -3.1249, GOLD PPL: 22.7580\n","[2021-04-12 09:06:44,641 INFO] Translating shard 1.\n","tcmalloc: large alloc 1518125056 bytes == 0x55b93cc98000 @  0x7f4ac9267b6b 0x7f4ac9287379 0x7f4a759c025e 0x7f4a759c19d2 0x7f4ab26a48e6 0x7f4ab2b06dd9 0x7f4ab301177a 0x7f4ab2fdcef9 0x7f4ab2f93657 0x7f4ab2e37929 0x7f4ab294f516 0x7f4ab30127af 0x7f4ab2dc1846 0x7f4ab2dc6e6f 0x7f4ab46aabcc 0x7f4ab46ab13f 0x7f4ab3213a86 0x7f4ab3217caf 0x7f4ab294116a 0x7f4ab2941b3a 0x7f4ab31267f8 0x7f4ab312683f 0x7f4ab2dc1846 0x7f4ab2dc722f 0x7f4ab29250b1 0x7f4ab31254c0 0x7f4ab314805d 0x7f4ab2f18a59 0x7f4ac44368de 0x55b8c05cf050 0x55b8c05cede0\n","tcmalloc: large alloc 1518125056 bytes == 0x55b997464000 @  0x7f4ac9267b6b 0x7f4ac9287379 0x7f4a759c025e 0x7f4a759c19d2 0x7f4ab26a48e6 0x7f4ab2b06dd9 0x7f4ab301177a 0x7f4ab2fdcef9 0x7f4ab2f93657 0x7f4ab2e37929 0x7f4ab2b106a2 0x7f4ab2aa05c5 0x7f4ab3012573 0x7f4ab2f82904 0x7f4ab2decf09 0x7f4ab4634444 0x7f4ab4634783 0x7f4ab2f82904 0x7f4ab2decf09 0x7f4ab2a995d0 0x7f4ab31260e0 0x7f4ab3126132 0x7f4ab2f90054 0x7f4ab3234735 0x7f4ac4193f4f 0x55b8c05cf050 0x55b8c06c099d 0x55b8c0642fe9 0x55b8c063db0e 0x55b8c05d077a 0x55b8c063f86a\n","[2021-04-12 09:26:43,349 INFO] PRED AVG SCORE: -0.6376, PRED PPL: 1.8919\n","[2021-04-12 09:26:43,350 INFO] GOLD AVG SCORE: -3.1276, GOLD PPL: 22.8190\n","[2021-04-12 09:26:43,371 INFO] Translating shard 2.\n","[2021-04-12 09:47:16,854 INFO] PRED AVG SCORE: -0.6365, PRED PPL: 1.8898\n","[2021-04-12 09:47:16,854 INFO] GOLD AVG SCORE: -3.1249, GOLD PPL: 22.7580\n","[2021-04-12 09:47:16,875 INFO] Translating shard 3.\n","[2021-04-12 10:08:00,131 INFO] PRED AVG SCORE: -0.6372, PRED PPL: 1.8911\n","[2021-04-12 10:08:00,131 INFO] GOLD AVG SCORE: -3.0933, GOLD PPL: 22.0495\n","[2021-04-12 10:08:00,154 INFO] Translating shard 4.\n","[2021-04-12 10:29:03,798 INFO] PRED AVG SCORE: -0.6381, PRED PPL: 1.8929\n","[2021-04-12 10:29:03,798 INFO] GOLD AVG SCORE: -3.1274, GOLD PPL: 22.8145\n","[2021-04-12 10:29:03,821 INFO] Translating shard 5.\n","[2021-04-12 10:49:56,874 INFO] PRED AVG SCORE: -0.6374, PRED PPL: 1.8916\n","[2021-04-12 10:49:56,874 INFO] GOLD AVG SCORE: -3.1102, GOLD PPL: 22.4266\n","[2021-04-12 10:49:56,898 INFO] Translating shard 6.\n","[2021-04-12 11:10:13,979 INFO] PRED AVG SCORE: -0.6362, PRED PPL: 1.8893\n","[2021-04-12 11:10:13,980 INFO] GOLD AVG SCORE: -3.0928, GOLD PPL: 22.0392\n","[2021-04-12 11:10:14,000 INFO] Translating shard 7.\n","[2021-04-12 11:30:17,973 INFO] PRED AVG SCORE: -0.6377, PRED PPL: 1.8921\n","[2021-04-12 11:30:17,973 INFO] GOLD AVG SCORE: -3.0819, GOLD PPL: 21.7990\n","[2021-04-12 11:30:17,996 INFO] Translating shard 8.\n","[2021-04-12 11:50:16,174 INFO] PRED AVG SCORE: -0.6371, PRED PPL: 1.8911\n","[2021-04-12 11:50:16,175 INFO] GOLD AVG SCORE: -3.1227, GOLD PPL: 22.7085\n","[2021-04-12 11:50:16,196 INFO] Translating shard 9.\n","[2021-04-12 12:10:13,213 INFO] PRED AVG SCORE: -0.6368, PRED PPL: 1.8904\n","[2021-04-12 12:10:13,213 INFO] GOLD AVG SCORE: -3.1158, GOLD PPL: 22.5523\n","[2021-04-12 12:10:13,233 INFO] Translating shard 10.\n","[2021-04-12 12:11:01,520 INFO] PRED AVG SCORE: -0.6478, PRED PPL: 1.9112\n","[2021-04-12 12:11:01,520 INFO] GOLD AVG SCORE: -3.0268, GOLD PPL: 20.6311\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267052462,"user_tz":-420,"elapsed":1238,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"d2fdd733-a4f0-4a44-c731-2b0d9e36930f"},"source":["!tail vi_test"],"execution_count":5,"outputs":[{"output_type":"stream","text":["And nobody questions him, because they don't want to hear the answer because it's a lie!\n","Kubo?\n","Họ rất vui vẻ, và lúc nào cũng hát với nến.\n","Nghe này, anh không thể nói chuyện bây giờ được.\n","Vậy thì con có thể dùng trí tưởng tượng của mình.\n","Không hề.\n","Tôi đang nhìn hắn ngay lúc này đây.\n","Bác không để tâm chứ?\n","Anh nghĩ cậu ta phản ứng với thuốc?\n","Bị làm sao mà anh lại đi dự lễ đặt tên em bé của Cuddy chứ?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618229485009,"user_tz":-420,"elapsed":26,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"183e77e7-d2fb-4395-9814-b8c4f19e16ec"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 376652\n","drwx------  2 root root      4096 Apr 12 01:58 data_bin\n","-rw-------  1 root root   3318349 Apr 12 01:48 en_test\n","-rw-------  1 root root  26563375 Apr 12 01:48 en_train\n","-rw-------  1 root root  34866334 Apr 12 01:07 en_train_EM_0.8\n","-rw-------  1 root root  32006284 Apr 12 01:07 en_train_EM_0.85\n","-rw-------  1 root root  29696900 Apr 12 01:07 en_train_EM_0.9\n","-rw-------  1 root root  27849828 Apr 12 01:07 en_train_EM_0.95\n","-rw-------  1 root root  13223858 Apr 12 01:07 en_train_EM_factor_0.8\n","-rw-------  1 root root  12138268 Apr 12 01:07 en_train_EM_factor_0.85\n","-rw-------  1 root root  11254364 Apr 12 01:07 en_train_EM_factor_0.9\n","-rw-------  1 root root  10539008 Apr 12 01:07 en_train_EM_factor_0.95\n","-rw-------  1 root root   8152745 Apr 12 01:07 en_train_EM_score_0.8\n","-rw-------  1 root root   8152745 Apr 12 01:07 en_train_EM_score_0.85\n","-rw-------  1 root root   8152745 Apr 12 01:07 en_train_EM_score_0.9\n","-rw-------  1 root root   8152745 Apr 12 01:07 en_train_EM_score_0.95\n","-rw-------  1 root root   3328557 Apr 12 01:48 en_valid\n","drwx------  2 root root      4096 Apr 12 08:46 model\n","drwx------ 11 root root      4096 Apr 12 12:11 OpenNMT-py\n","-rw-------  1 root root 100661014 Apr 12 01:58 opus_bert.tar.gz\n","drwx------  2 root root      4096 Apr 12 01:59 output\n","-rw-------  1 root root   3844824 Apr 12 12:11 predict.txt\n","-rw-------  1 root root   4365722 Apr 12 01:48 vi_test\n","-rw-------  1 root root  35019161 Apr 12 01:48 vi_train\n","-rw-------  1 root root   4382771 Apr 12 01:48 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618267069353,"user_tz":-420,"elapsed":10787,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"9520062b-8326-4de9-b467-7dccef4b0795"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":6,"outputs":[{"output_type":"stream","text":["BLEU = 16.80, 41.4/23.1/14.2/9.4 (BP=0.889, ratio=0.895, hyp_len=678535, ref_len=758454)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1618229491978,"user_tz":-420,"elapsed":10,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}