{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OPUS-OpenNMT-bert-0.8 BLEU 15.85.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583602352,"user_tz":-420,"elapsed":19072,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"2a641921-49f8-4380-e98e-9cd4f5e8a9ca"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","executionInfo":{"status":"ok","timestamp":1619583602353,"user_tz":-420,"elapsed":19071,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":["# import os\n","# path = \"\"\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","# os.chdir(path)\n","# import time\n","# FOLDERNAME = \"OPUS-OpenNMT-bert-0.85-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","# !mkdir $FOLDERNAME\n","\n","# path = path + FOLDERNAME\n","# os.chdir(path)\n","# !pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/OPUS-OpenNMT-bert-0.9-20210412-0158'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583602353,"user_tz":-420,"elapsed":19069,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"77f01be7-5f9c-4cb0-e6f5-67eb5fbc1651"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Wed Apr 28 04:20:00 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583616812,"user_tz":-420,"elapsed":33526,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"c0dab866-75b7-4b3b-8841-eeac05075023"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\r\u001b[K     |█▊                              | 10kB 24.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/67/cd64b4c2fd0a83eb1088e31e0217b612281d014299993424420f933df3e7/pyonmttok-1.26.0-cp37-cp37m-manylinux1_x86_64.whl (14.3MB)\n","\u001b[K     |████████████████████████████████| 14.3MB 486kB/s \n","\u001b[?25hCollecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n","\u001b[?25hCollecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n","\u001b[?25hCollecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n","\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (56.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.10.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=7e456abe6298b9c6a10ffcd71c439b5af90a5b6d4d931927c37677ba99dea044\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: pyonmttok, torchtext, waitress, configargparse, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.26.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583620680,"user_tz":-420,"elapsed":37393,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"c797fa54-1e97-4e71-d09d-222775c74e98"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/opus_bert.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'opus_bert.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-28 04:20:14--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/opus_bert.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 100661014 (96M) [application/octet-stream]\n","Saving to: ‘opus_bert.tar.gz’\n","\n","opus_bert.tar.gz    100%[===================>]  96.00M   134MB/s    in 0.7s    \n","\n","2021-04-28 04:20:16 (134 MB/s) - ‘opus_bert.tar.gz’ saved [100661014/100661014]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583675070,"user_tz":-420,"elapsed":91782,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"a7a22c90-fa6b-4772-de5b-060804582d34"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.8' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-28 04:20:22,567 INFO] Extracting features...\n","[2021-04-28 04:20:22,567 INFO]  * number of source features: 0.\n","[2021-04-28 04:20:22,567 INFO]  * number of target features: 0.\n","[2021-04-28 04:20:22,567 INFO] Building `Fields` object...\n","[2021-04-28 04:20:22,567 INFO] Building & saving training data...\n","[2021-04-28 04:20:23,609 INFO] Building shard 0.\n","[2021-04-28 04:20:50,796 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-28 04:21:07,104 INFO]  * tgt vocab size: 50004.\n","[2021-04-28 04:21:07,451 INFO]  * src vocab size: 50002.\n","[2021-04-28 04:21:08,031 INFO] Building & saving validation data...\n","[2021-04-28 04:21:08,548 INFO] Building shard 0.\n","[2021-04-28 04:21:10,466 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619606234039,"user_tz":-420,"elapsed":22650750,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"53936646-974c-441a-9663-5d1158c8ca00"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-28 04:21:15,801 INFO]  * src vocab size = 50002\n","[2021-04-28 04:21:15,801 INFO]  * tgt vocab size = 50004\n","[2021-04-28 04:21:15,801 INFO] Building model...\n","[2021-04-28 04:21:23,314 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50002, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=50004, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-28 04:21:23,341 INFO] encoder: 44516352\n","[2021-04-28 04:21:23,341 INFO] decoder: 76479316\n","[2021-04-28 04:21:23,341 INFO] * number of parameters: 120995668\n","[2021-04-28 04:21:23,344 INFO] Starting training on GPU: [0]\n","[2021-04-28 04:21:23,345 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-28 04:21:23,345 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 04:21:40,089 INFO] number of examples: 802824\n","[2021-04-28 04:32:10,975 INFO] Step 1000/30000; acc:  13.64; ppl: 550.95; xent: 6.31; lr: 0.00012; 9188/9567 tok/s;    648 sec\n","[2021-04-28 04:32:10,976 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 04:32:12,434 INFO] number of examples: 100400\n","[2021-04-28 04:33:37,798 INFO] Validation perplexity: 289.273\n","[2021-04-28 04:33:37,799 INFO] Validation accuracy: 18.5122\n","[2021-04-28 04:33:39,140 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-28 04:34:55,736 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 04:35:16,354 INFO] number of examples: 802824\n","[2021-04-28 04:44:38,067 INFO] Step 2000/30000; acc:  27.58; ppl: 70.23; xent: 4.25; lr: 0.00025; 7940/8263 tok/s;   1395 sec\n","[2021-04-28 04:44:38,068 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 04:44:39,292 INFO] number of examples: 100400\n","[2021-04-28 04:46:04,086 INFO] Validation perplexity: 59.096\n","[2021-04-28 04:46:04,087 INFO] Validation accuracy: 35.5207\n","[2021-04-28 04:46:05,501 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-28 04:48:36,205 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 04:49:04,317 INFO] number of examples: 802824\n","[2021-04-28 04:57:11,524 INFO] Step 3000/30000; acc:  38.31; ppl: 27.40; xent: 3.31; lr: 0.00037; 7854/8161 tok/s;   2148 sec\n","[2021-04-28 04:57:11,525 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 04:57:12,741 INFO] number of examples: 100400\n","[2021-04-28 04:58:37,385 INFO] Validation perplexity: 30.3267\n","[2021-04-28 04:58:37,385 INFO] Validation accuracy: 42.1119\n","[2021-04-28 04:58:38,787 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-28 05:02:20,676 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:02:45,936 INFO] number of examples: 802824\n","[2021-04-28 05:09:40,716 INFO] Step 4000/30000; acc:  43.28; ppl: 17.37; xent: 2.85; lr: 0.00049; 7898/8203 tok/s;   2897 sec\n","[2021-04-28 05:09:40,717 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:09:41,952 INFO] number of examples: 100400\n","[2021-04-28 05:11:06,619 INFO] Validation perplexity: 21.9817\n","[2021-04-28 05:11:06,619 INFO] Validation accuracy: 45.1844\n","[2021-04-28 05:11:07,986 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-28 05:16:01,131 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:16:24,967 INFO] number of examples: 802824\n","[2021-04-28 05:22:09,154 INFO] Step 5000/30000; acc:  45.91; ppl: 13.72; xent: 2.62; lr: 0.00062; 7899/8212 tok/s;   3646 sec\n","[2021-04-28 05:22:09,155 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:22:10,425 INFO] number of examples: 100400\n","[2021-04-28 05:23:35,071 INFO] Validation perplexity: 19.3885\n","[2021-04-28 05:23:35,071 INFO] Validation accuracy: 46.5215\n","[2021-04-28 05:23:36,473 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-28 05:29:41,077 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:30:00,399 INFO] number of examples: 802824\n","[2021-04-28 05:34:33,397 INFO] Step 6000/30000; acc:  47.66; ppl: 11.76; xent: 2.46; lr: 0.00074; 7940/8263 tok/s;   4390 sec\n","[2021-04-28 05:34:33,398 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:34:38,322 INFO] number of examples: 100400\n","[2021-04-28 05:36:03,011 INFO] Validation perplexity: 17.8082\n","[2021-04-28 05:36:03,011 INFO] Validation accuracy: 47.4016\n","[2021-04-28 05:36:04,374 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-28 05:43:19,888 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:43:44,131 INFO] number of examples: 802824\n","[2021-04-28 05:47:04,340 INFO] Step 7000/30000; acc:  49.00; ppl: 10.50; xent: 2.35; lr: 0.00086; 7910/8154 tok/s;   5141 sec\n","[2021-04-28 05:47:04,341 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:47:05,627 INFO] number of examples: 100400\n","[2021-04-28 05:48:30,361 INFO] Validation perplexity: 17.7598\n","[2021-04-28 05:48:30,361 INFO] Validation accuracy: 47.2446\n","[2021-04-28 05:48:31,727 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-28 05:57:00,024 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:57:23,757 INFO] number of examples: 802824\n","[2021-04-28 05:59:34,239 INFO] Step 8000/30000; acc:  50.08; ppl:  9.64; xent: 2.27; lr: 0.00099; 7885/8226 tok/s;   5891 sec\n","[2021-04-28 05:59:34,240 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:59:41,125 INFO] number of examples: 100400\n","[2021-04-28 06:01:05,803 INFO] Validation perplexity: 17.1924\n","[2021-04-28 06:01:05,803 INFO] Validation accuracy: 47.8803\n","[2021-04-28 06:01:07,172 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-28 06:10:45,003 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 06:11:16,278 INFO] number of examples: 802824\n","[2021-04-28 06:12:16,520 INFO] Step 9000/30000; acc:  51.51; ppl:  8.70; xent: 2.16; lr: 0.00093; 7725/8081 tok/s;   6653 sec\n","[2021-04-28 06:12:16,521 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:12:17,811 INFO] number of examples: 100400\n","[2021-04-28 06:13:42,463 INFO] Validation perplexity: 16.8742\n","[2021-04-28 06:13:42,463 INFO] Validation accuracy: 48.1844\n","[2021-04-28 06:13:43,817 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-28 06:24:16,071 INFO] Step 10000/30000; acc:  53.25; ppl:  7.74; xent: 2.05; lr: 0.00088; 8206/8581 tok/s;   7373 sec\n","[2021-04-28 06:24:16,072 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:24:17,381 INFO] number of examples: 100400\n","[2021-04-28 06:25:42,023 INFO] Validation perplexity: 16.2421\n","[2021-04-28 06:25:42,023 INFO] Validation accuracy: 48.6178\n","[2021-04-28 06:25:43,405 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-28 06:26:05,359 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 06:26:29,386 INFO] number of examples: 802824\n","[2021-04-28 06:36:44,877 INFO] Step 11000/30000; acc:  55.01; ppl:  6.94; xent: 1.94; lr: 0.00084; 7947/8271 tok/s;   8122 sec\n","[2021-04-28 06:36:44,878 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:36:51,786 INFO] number of examples: 100400\n","[2021-04-28 06:38:16,521 INFO] Validation perplexity: 15.6958\n","[2021-04-28 06:38:16,521 INFO] Validation accuracy: 49.2157\n","[2021-04-28 06:38:17,886 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-28 06:39:51,180 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 06:40:22,478 INFO] number of examples: 802824\n","[2021-04-28 06:49:24,133 INFO] Step 12000/30000; acc:  56.64; ppl:  6.31; xent: 1.84; lr: 0.00081; 7809/8126 tok/s;   8881 sec\n","[2021-04-28 06:49:24,134 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:49:25,434 INFO] number of examples: 100400\n","[2021-04-28 06:50:50,078 INFO] Validation perplexity: 16.1537\n","[2021-04-28 06:50:50,079 INFO] Validation accuracy: 49.612\n","[2021-04-28 06:50:51,438 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-28 06:53:38,444 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 06:54:03,289 INFO] number of examples: 802824\n","[2021-04-28 07:01:53,499 INFO] Step 13000/30000; acc:  58.12; ppl:  5.82; xent: 1.76; lr: 0.00078; 7893/8215 tok/s;   9630 sec\n","[2021-04-28 07:01:53,500 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:01:54,809 INFO] number of examples: 100400\n","[2021-04-28 07:03:19,872 INFO] Validation perplexity: 16.0409\n","[2021-04-28 07:03:19,872 INFO] Validation accuracy: 49.5791\n","[2021-04-28 07:03:21,269 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-28 07:07:19,027 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:07:44,442 INFO] number of examples: 802824\n","[2021-04-28 07:14:23,526 INFO] Step 14000/30000; acc:  59.53; ppl:  5.40; xent: 1.69; lr: 0.00075; 7888/8187 tok/s;  10380 sec\n","[2021-04-28 07:14:23,527 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:14:24,837 INFO] number of examples: 100400\n","[2021-04-28 07:15:49,555 INFO] Validation perplexity: 16.5197\n","[2021-04-28 07:15:49,556 INFO] Validation accuracy: 49.7644\n","[2021-04-28 07:15:50,920 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-28 07:21:00,690 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:21:24,594 INFO] number of examples: 802824\n","[2021-04-28 07:26:52,710 INFO] Step 15000/30000; acc:  60.77; ppl:  5.06; xent: 1.62; lr: 0.00072; 7897/8219 tok/s;  11129 sec\n","[2021-04-28 07:26:52,711 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:26:59,603 INFO] number of examples: 100400\n","[2021-04-28 07:28:24,296 INFO] Validation perplexity: 16.2892\n","[2021-04-28 07:28:24,296 INFO] Validation accuracy: 49.9554\n","[2021-04-28 07:28:25,656 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-28 07:34:46,112 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:35:17,358 INFO] number of examples: 802824\n","[2021-04-28 07:39:34,218 INFO] Step 16000/30000; acc:  62.03; ppl:  4.75; xent: 1.56; lr: 0.00070; 7766/8041 tok/s;  11891 sec\n","[2021-04-28 07:39:34,219 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:39:35,513 INFO] number of examples: 100400\n","[2021-04-28 07:41:00,226 INFO] Validation perplexity: 16.7694\n","[2021-04-28 07:41:00,226 INFO] Validation accuracy: 50.1369\n","[2021-04-28 07:41:01,597 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-28 07:48:34,495 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:49:04,019 INFO] number of examples: 802824\n","[2021-04-28 07:52:07,850 INFO] Step 17000/30000; acc:  63.03; ppl:  4.51; xent: 1.51; lr: 0.00068; 7874/8147 tok/s;  12645 sec\n","[2021-04-28 07:52:07,851 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:52:09,177 INFO] number of examples: 100400\n","[2021-04-28 07:53:33,894 INFO] Validation perplexity: 17.3381\n","[2021-04-28 07:53:33,894 INFO] Validation accuracy: 49.9924\n","[2021-04-28 07:53:35,274 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-28 08:02:20,565 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:02:41,337 INFO] number of examples: 802824\n","[2021-04-28 08:04:36,713 INFO] Step 18000/30000; acc:  63.99; ppl:  4.32; xent: 1.46; lr: 0.00066; 7882/8260 tok/s;  13393 sec\n","[2021-04-28 08:04:36,714 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:04:43,781 INFO] number of examples: 100400\n","[2021-04-28 08:06:08,486 INFO] Validation perplexity: 17.8202\n","[2021-04-28 08:06:08,487 INFO] Validation accuracy: 49.9511\n","[2021-04-28 08:06:09,857 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-28 08:16:02,719 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:16:33,853 INFO] number of examples: 802824\n","[2021-04-28 08:17:18,604 INFO] Step 19000/30000; acc:  64.98; ppl:  4.11; xent: 1.41; lr: 0.00064; 7730/8085 tok/s;  14155 sec\n","[2021-04-28 08:17:18,604 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:17:19,916 INFO] number of examples: 100400\n","[2021-04-28 08:18:44,567 INFO] Validation perplexity: 17.6726\n","[2021-04-28 08:18:44,567 INFO] Validation accuracy: 50.1115\n","[2021-04-28 08:18:45,921 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-28 08:29:17,335 INFO] Step 20000/30000; acc:  65.79; ppl:  3.96; xent: 1.38; lr: 0.00062; 8230/8578 tok/s;  14874 sec\n","[2021-04-28 08:29:17,336 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:29:18,667 INFO] number of examples: 100400\n","[2021-04-28 08:30:43,411 INFO] Validation perplexity: 18.7396\n","[2021-04-28 08:30:43,411 INFO] Validation accuracy: 50.074\n","[2021-04-28 08:30:44,785 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-28 08:31:23,336 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:31:53,138 INFO] number of examples: 802824\n","[2021-04-28 08:41:51,466 INFO] Step 21000/30000; acc:  66.66; ppl:  3.80; xent: 1.34; lr: 0.00061; 7891/8198 tok/s;  15628 sec\n","[2021-04-28 08:41:51,467 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:41:52,779 INFO] number of examples: 100400\n","[2021-04-28 08:43:17,503 INFO] Validation perplexity: 18.8612\n","[2021-04-28 08:43:17,503 INFO] Validation accuracy: 50.1025\n","[2021-04-28 08:43:18,889 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-28 08:45:09,731 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:45:30,557 INFO] number of examples: 802824\n","[2021-04-28 08:54:17,096 INFO] Step 22000/30000; acc:  67.41; ppl:  3.67; xent: 1.30; lr: 0.00060; 7947/8274 tok/s;  16374 sec\n","[2021-04-28 08:54:17,097 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:54:24,910 INFO] number of examples: 100400\n","[2021-04-28 08:55:51,036 INFO] Validation perplexity: 18.4455\n","[2021-04-28 08:55:51,037 INFO] Validation accuracy: 50.0869\n","[2021-04-28 08:55:52,520 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-28 08:58:57,484 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:59:32,754 INFO] number of examples: 802824\n","[2021-04-28 09:07:10,902 INFO] Step 23000/30000; acc:  68.20; ppl:  3.54; xent: 1.26; lr: 0.00058; 7647/7946 tok/s;  17148 sec\n","[2021-04-28 09:07:10,903 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:07:12,232 INFO] number of examples: 100400\n","[2021-04-28 09:08:38,374 INFO] Validation perplexity: 18.7839\n","[2021-04-28 09:08:38,374 INFO] Validation accuracy: 50.1186\n","[2021-04-28 09:08:39,874 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-28 09:12:56,721 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:13:22,722 INFO] number of examples: 802824\n","[2021-04-28 09:19:48,484 INFO] Step 24000/30000; acc:  68.92; ppl:  3.43; xent: 1.23; lr: 0.00057; 7807/8112 tok/s;  17905 sec\n","[2021-04-28 09:19:48,485 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:19:49,827 INFO] number of examples: 100400\n","[2021-04-28 09:21:15,982 INFO] Validation perplexity: 19.788\n","[2021-04-28 09:21:15,982 INFO] Validation accuracy: 50.0017\n","[2021-04-28 09:21:17,465 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-28 09:26:45,878 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:27:11,230 INFO] number of examples: 802824\n","[2021-04-28 09:32:25,647 INFO] Step 25000/30000; acc:  69.55; ppl:  3.34; xent: 1.21; lr: 0.00056; 7810/8134 tok/s;  18662 sec\n","[2021-04-28 09:32:25,649 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:32:33,809 INFO] number of examples: 100400\n","[2021-04-28 09:34:00,046 INFO] Validation perplexity: 20.1333\n","[2021-04-28 09:34:00,046 INFO] Validation accuracy: 50.1657\n","[2021-04-28 09:34:01,566 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-28 09:40:41,480 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:41:16,380 INFO] number of examples: 802824\n","[2021-04-28 09:45:18,964 INFO] Step 26000/30000; acc:  70.29; ppl:  3.24; xent: 1.17; lr: 0.00055; 7648/7932 tok/s;  19436 sec\n","[2021-04-28 09:45:18,965 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:45:20,300 INFO] number of examples: 100400\n","[2021-04-28 09:46:46,481 INFO] Validation perplexity: 19.6664\n","[2021-04-28 09:46:46,481 INFO] Validation accuracy: 50.2303\n","[2021-04-28 09:46:47,998 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-28 09:54:40,255 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:55:06,349 INFO] number of examples: 802824\n","[2021-04-28 09:57:56,771 INFO] Step 27000/30000; acc:  70.87; ppl:  3.15; xent: 1.15; lr: 0.00054; 7828/8111 tok/s;  20193 sec\n","[2021-04-28 09:57:56,772 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:57:58,101 INFO] number of examples: 100400\n","[2021-04-28 09:59:24,306 INFO] Validation perplexity: 20.5737\n","[2021-04-28 09:59:24,307 INFO] Validation accuracy: 50.2565\n","[2021-04-28 09:59:25,771 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-28 10:08:30,014 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 10:08:55,625 INFO] number of examples: 802824\n","[2021-04-28 10:10:36,296 INFO] Step 28000/30000; acc:  71.32; ppl:  3.09; xent: 1.13; lr: 0.00053; 7766/8133 tok/s;  20953 sec\n","[2021-04-28 10:10:36,297 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 10:10:44,425 INFO] number of examples: 100400\n","[2021-04-28 10:12:10,622 INFO] Validation perplexity: 20.6442\n","[2021-04-28 10:12:10,622 INFO] Validation accuracy: 50.2064\n","[2021-04-28 10:12:12,110 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-28 10:22:25,845 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 10:23:01,045 INFO] number of examples: 802824\n","[2021-04-28 10:23:30,606 INFO] Step 29000/30000; acc:  71.91; ppl:  3.01; xent: 1.10; lr: 0.00052; 7615/7951 tok/s;  21727 sec\n","[2021-04-28 10:23:30,608 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 10:23:31,927 INFO] number of examples: 100400\n","[2021-04-28 10:24:57,864 INFO] Validation perplexity: 21.1097\n","[2021-04-28 10:24:57,864 INFO] Validation accuracy: 50.3475\n","[2021-04-28 10:24:59,319 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-28 10:35:35,299 INFO] Step 30000/30000; acc:  72.33; ppl:  2.96; xent: 1.09; lr: 0.00051; 8200/8531 tok/s;  22452 sec\n","[2021-04-28 10:35:35,301 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 10:35:36,734 INFO] number of examples: 100400\n","[2021-04-28 10:37:02,940 INFO] Validation perplexity: 21.8805\n","[2021-04-28 10:37:02,941 INFO] Validation accuracy: 50.2079\n","[2021-04-28 10:37:04,443 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619606234040,"user_tz":-420,"elapsed":22650750,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"554bce89-89d7-47ce-c3a3-09518c9a0282"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 43405568\n","drwxr-xr-x 2 root root       4096 Apr 28 10:37 .\n","drwxr-xr-x 1 root root       4096 Apr 28 04:21 ..\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:25 en-vi_step_10000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 04:33 en-vi_step_1000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:38 en-vi_step_11000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:50 en-vi_step_12000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:03 en-vi_step_13000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:15 en-vi_step_14000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:28 en-vi_step_15000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:41 en-vi_step_16000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:53 en-vi_step_17000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:06 en-vi_step_18000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:18 en-vi_step_19000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:30 en-vi_step_20000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 04:46 en-vi_step_2000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:43 en-vi_step_21000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:55 en-vi_step_22000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:08 en-vi_step_23000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:21 en-vi_step_24000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:34 en-vi_step_25000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:46 en-vi_step_26000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:59 en-vi_step_27000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 10:12 en-vi_step_28000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 10:25 en-vi_step_29000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 10:37 en-vi_step_30000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 04:58 en-vi_step_3000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 05:11 en-vi_step_4000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 05:23 en-vi_step_5000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 05:36 en-vi_step_6000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 05:48 en-vi_step_7000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:01 en-vi_step_8000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:13 en-vi_step_9000.pt\n","\n","model/:\n","total 43405568\n","drwxr-xr-x 2 root root       4096 Apr 28 10:37 .\n","drwxr-xr-x 1 root root       4096 Apr 28 04:21 ..\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:25 en-vi_step_10000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 04:33 en-vi_step_1000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:38 en-vi_step_11000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:50 en-vi_step_12000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:03 en-vi_step_13000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:15 en-vi_step_14000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:28 en-vi_step_15000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:41 en-vi_step_16000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 07:53 en-vi_step_17000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:06 en-vi_step_18000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:18 en-vi_step_19000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:30 en-vi_step_20000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 04:46 en-vi_step_2000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:43 en-vi_step_21000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 08:55 en-vi_step_22000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:08 en-vi_step_23000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:21 en-vi_step_24000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:34 en-vi_step_25000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:46 en-vi_step_26000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 09:59 en-vi_step_27000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 10:12 en-vi_step_28000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 10:25 en-vi_step_29000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 10:37 en-vi_step_30000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 04:58 en-vi_step_3000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 05:11 en-vi_step_4000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 05:23 en-vi_step_5000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 05:36 en-vi_step_6000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 05:48 en-vi_step_7000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:01 en-vi_step_8000.pt\n","-rw-r--r-- 1 root root 1481570815 Apr 28 06:13 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619615499613,"user_tz":-420,"elapsed":31916322,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"cdb65ae8-23c3-453e-b525-ebc3b2fe8b4d"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-28 10:37:18,424 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-28 10:53:03,854 INFO] PRED AVG SCORE: -0.6417, PRED PPL: 1.8997\n","[2021-04-28 10:53:03,854 INFO] GOLD AVG SCORE: -3.0785, GOLD PPL: 21.7262\n","[2021-04-28 10:53:03,874 INFO] Translating shard 1.\n","tcmalloc: large alloc 1518125056 bytes == 0x55cd75304000 @  0x7f90726b5b6b 0x7f90726d5379 0x7f901ee0e25e 0x7f901ee0f9d2 0x7f905baf28e6 0x7f905bf54dd9 0x7f905c45f77a 0x7f905c42aef9 0x7f905c3e1657 0x7f905c285929 0x7f905bd9d516 0x7f905c4607af 0x7f905c20f846 0x7f905c214e6f 0x7f905daf8bcc 0x7f905daf913f 0x7f905c661a86 0x7f905c665caf 0x7f905bd8f16a 0x7f905bd8fb3a 0x7f905c5747f8 0x7f905c57483f 0x7f905c20f846 0x7f905c21522f 0x7f905bd730b1 0x7f905c5734c0 0x7f905c59605d 0x7f905c366a59 0x7f906d8848de 0x55ccf8c75050 0x55ccf8c74de0\n","tcmalloc: large alloc 1518125056 bytes == 0x55cdcfad0000 @  0x7f90726b5b6b 0x7f90726d5379 0x7f901ee0e25e 0x7f901ee0f9d2 0x7f905baf28e6 0x7f905bf54dd9 0x7f905c45f77a 0x7f905c42aef9 0x7f905c3e1657 0x7f905c285929 0x7f905bf5e6a2 0x7f905beee5c5 0x7f905c460573 0x7f905c3d0904 0x7f905c23af09 0x7f905da82444 0x7f905da82783 0x7f905c3d0904 0x7f905c23af09 0x7f905bee75d0 0x7f905c5740e0 0x7f905c574132 0x7f905c3de054 0x7f905c682735 0x7f906d5e1f4f 0x55ccf8c75050 0x55ccf8d6699d 0x55ccf8ce8fe9 0x55ccf8ce3b0e 0x55ccf8c7677a 0x55ccf8ce586a\n","[2021-04-28 11:08:46,529 INFO] PRED AVG SCORE: -0.6467, PRED PPL: 1.9092\n","[2021-04-28 11:08:46,529 INFO] GOLD AVG SCORE: -3.0924, GOLD PPL: 22.0293\n","[2021-04-28 11:08:46,563 INFO] Translating shard 2.\n","[2021-04-28 11:24:32,356 INFO] PRED AVG SCORE: -0.6429, PRED PPL: 1.9019\n","[2021-04-28 11:24:32,356 INFO] GOLD AVG SCORE: -3.0714, GOLD PPL: 21.5731\n","[2021-04-28 11:24:32,377 INFO] Translating shard 3.\n","[2021-04-28 11:39:36,895 INFO] PRED AVG SCORE: -0.6445, PRED PPL: 1.9051\n","[2021-04-28 11:39:36,895 INFO] GOLD AVG SCORE: -3.0625, GOLD PPL: 21.3803\n","[2021-04-28 11:39:36,917 INFO] Translating shard 4.\n","[2021-04-28 11:55:01,857 INFO] PRED AVG SCORE: -0.6414, PRED PPL: 1.8992\n","[2021-04-28 11:55:01,858 INFO] GOLD AVG SCORE: -3.0913, GOLD PPL: 22.0054\n","[2021-04-28 11:55:01,878 INFO] Translating shard 5.\n","[2021-04-28 12:10:27,955 INFO] PRED AVG SCORE: -0.6434, PRED PPL: 1.9029\n","[2021-04-28 12:10:27,955 INFO] GOLD AVG SCORE: -3.0732, GOLD PPL: 21.6103\n","[2021-04-28 12:10:27,976 INFO] Translating shard 6.\n","[2021-04-28 12:25:41,754 INFO] PRED AVG SCORE: -0.6423, PRED PPL: 1.9009\n","[2021-04-28 12:25:41,754 INFO] GOLD AVG SCORE: -3.0442, GOLD PPL: 20.9940\n","[2021-04-28 12:25:41,773 INFO] Translating shard 7.\n","[2021-04-28 12:40:47,552 INFO] PRED AVG SCORE: -0.6423, PRED PPL: 1.9008\n","[2021-04-28 12:40:47,552 INFO] GOLD AVG SCORE: -3.0515, GOLD PPL: 21.1474\n","[2021-04-28 12:40:47,573 INFO] Translating shard 8.\n","[2021-04-28 12:55:50,227 INFO] PRED AVG SCORE: -0.6421, PRED PPL: 1.9005\n","[2021-04-28 12:55:50,227 INFO] GOLD AVG SCORE: -3.0862, GOLD PPL: 21.8935\n","[2021-04-28 12:55:50,247 INFO] Translating shard 9.\n","[2021-04-28 13:11:00,980 INFO] PRED AVG SCORE: -0.6471, PRED PPL: 1.9101\n","[2021-04-28 13:11:00,980 INFO] GOLD AVG SCORE: -3.0679, GOLD PPL: 21.4957\n","[2021-04-28 13:11:00,998 INFO] Translating shard 10.\n","[2021-04-28 13:11:38,270 INFO] PRED AVG SCORE: -0.6474, PRED PPL: 1.9106\n","[2021-04-28 13:11:38,270 INFO] GOLD AVG SCORE: -3.0102, GOLD PPL: 20.2914\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619615499614,"user_tz":-420,"elapsed":31916322,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"2ab0b06c-652d-43f6-eb1d-6cfcc7ba0501"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["And nobody questions him, because they don't want to hear the answer because it's a lie!\n","Kubo?\n","Họ rất vui vẻ, và lúc nào cũng hát với nến.\n","Nghe này, anh không thể nói chuyện bây giờ được.\n","Vậy thì con có thể dùng trí tưởng tượng của mình.\n","Không hề.\n","Tôi đang nhìn hắn ngay lúc này đây.\n","Bác không để tâm chứ?\n","Anh nghĩ cậu ta phản ứng với thuốc?\n","Bị làm sao mà anh lại đi dự lễ đặt tên em bé của Cuddy chứ?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619615510614,"user_tz":-420,"elapsed":31927321,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"18b6f39d-c649-47d4-af0a-a0214ec8f39c"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 17287, done.\u001b[K\n","remote: Counting objects: 100% (246/246), done.\u001b[K\n","remote: Compressing objects: 100% (167/167), done.\u001b[K\n","remote: Total 17287 (delta 148), reused 135 (delta 77), pack-reused 17041\u001b[K\n","Receiving objects: 100% (17287/17287), 273.51 MiB | 43.56 MiB/s, done.\n","Resolving deltas: 100% (12456/12456), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619615510615,"user_tz":-420,"elapsed":31927320,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"6eb56bb7-c9ff-4c55-d7c0-74f4cf52aa9a"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 376632\n","drwxr-xr-x  1 root root      4096 Apr 28 13:11 .\n","drwxr-xr-x  1 root root      4096 Apr 28 03:57 ..\n","drwxr-xr-x  4 root root      4096 Apr 21 13:38 .config\n","drwxr-xr-x  2 root root      4096 Apr 28 04:20 data_bin\n","drwx------  6 root root      4096 Apr 28 04:19 drive\n","-rw-rw-r--  1 1000 1000   3318349 Apr 12 01:48 en_test\n","-rw-rw-r--  1 1000 1000  26563375 Apr 12 01:48 en_train\n","-rw-rw-r--  1 1000 1000  34866334 Apr 12 01:07 en_train_EM_0.8\n","-rw-rw-r--  1 1000 1000  32006284 Apr 12 01:07 en_train_EM_0.85\n","-rw-rw-r--  1 1000 1000  29696900 Apr 12 01:07 en_train_EM_0.9\n","-rw-rw-r--  1 1000 1000  27849828 Apr 12 01:07 en_train_EM_0.95\n","-rw-rw-r--  1 1000 1000  13223858 Apr 12 01:07 en_train_EM_factor_0.8\n","-rw-rw-r--  1 1000 1000  12138268 Apr 12 01:07 en_train_EM_factor_0.85\n","-rw-rw-r--  1 1000 1000  11254364 Apr 12 01:07 en_train_EM_factor_0.9\n","-rw-rw-r--  1 1000 1000  10539008 Apr 12 01:07 en_train_EM_factor_0.95\n","-rw-rw-r--  1 1000 1000   8152745 Apr 12 01:07 en_train_EM_score_0.8\n","-rw-rw-r--  1 1000 1000   8152745 Apr 12 01:07 en_train_EM_score_0.85\n","-rw-rw-r--  1 1000 1000   8152745 Apr 12 01:07 en_train_EM_score_0.9\n","-rw-rw-r--  1 1000 1000   8152745 Apr 12 01:07 en_train_EM_score_0.95\n","-rw-rw-r--  1 1000 1000   3328557 Apr 12 01:48 en_valid\n","drwxr-xr-x  2 root root      4096 Apr 28 10:37 model\n","drwxr-xr-x 11 root root      4096 Apr 28 13:11 OpenNMT-py\n","-rw-r--r--  1 root root 100661014 Apr 28 04:20 opus_bert.tar.gz\n","drwxr-xr-x  2 root root      4096 Apr 28 04:21 output\n","-rw-r--r--  1 root root   3763734 Apr 28 13:11 predict.txt\n","drwxr-xr-x  1 root root      4096 Apr 21 13:39 sample_data\n","-rw-rw-r--  1 1000 1000   4365722 Apr 12 01:48 vi_test\n","-rw-rw-r--  1 1000 1000  35019161 Apr 12 01:48 vi_train\n","-rw-rw-r--  1 1000 1000   4382771 Apr 12 01:48 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619615516595,"user_tz":-420,"elapsed":31933300,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"3e2f225a-16f1-497b-8612-745fccf5178b"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 15.85, 41.5/22.8/13.6/8.8 (BP=0.864, ratio=0.873, hyp_len=661762, ref_len=758454)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1619615516596,"user_tz":-420,"elapsed":31933299,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}