{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TED-OpenNMT-bert-0.95-20210410-0035 BLEU 23.79.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618014958878,"user_tz":-420,"elapsed":29609,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"0864f6e5-5dac-457c-82d9-d0331c2bf809"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618014961063,"user_tz":-420,"elapsed":31790,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e89411e4-e732-4a81-aba4-2ce7545fae59"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"TED-OpenNMT-bert-0.95-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v3/OpenNMT-TED-EM-bert-ratio-8-2-2-20210128-0637'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/TED-OpenNMT-bert-0.95-20210410-0035\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618014961064,"user_tz":-420,"elapsed":31789,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"21ac3679-580e-491b-f918-c2f3e48a756f"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Sat Apr 10 00:36:00 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618014973831,"user_tz":-420,"elapsed":44555,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"b7108be5-d9f4-434b-de28-d234e6d9e0fb"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 15.7MB/s \n","\u001b[?25hCollecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 27.4MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Collecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n","\u001b[?25hCollecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=14e427603079caeb87715ba7dec96b6361990d7e2ebbdaf01eef11ef8e1934ef\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: pyonmttok, configargparse, waitress, torchtext, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.4MB/s \n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618014976116,"user_tz":-420,"elapsed":46838,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e191c32d-f1ef-41ed-cc5b-c08f5793b217"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'en_vi_iwslt_bert.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-10 00:36:13--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22435544 (21M) [application/octet-stream]\n","Saving to: ‘en_vi_iwslt_bert.tar.gz’\n","\n","en_vi_iwslt_bert.ta 100%[===================>]  21.40M  82.0MB/s    in 0.3s    \n","\n","2021-04-10 00:36:14 (82.0 MB/s) - ‘en_vi_iwslt_bert.tar.gz’ saved [22435544/22435544]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618014987552,"user_tz":-420,"elapsed":58272,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"73a0b4ff-6603-4d00-d83d-fd9445c32652"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.95' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-10 00:36:18,801 INFO] Extracting features...\n","[2021-04-10 00:36:18,804 INFO]  * number of source features: 0.\n","[2021-04-10 00:36:18,804 INFO]  * number of target features: 0.\n","[2021-04-10 00:36:18,804 INFO] Building `Fields` object...\n","[2021-04-10 00:36:18,804 INFO] Building & saving training data...\n","[2021-04-10 00:36:18,960 INFO] Building shard 0.\n","[2021-04-10 00:36:22,246 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-10 00:36:25,054 INFO]  * tgt vocab size: 18250.\n","[2021-04-10 00:36:25,122 INFO]  * src vocab size: 39736.\n","[2021-04-10 00:36:25,332 INFO] Building & saving validation data...\n","[2021-04-10 00:36:25,449 INFO] Building shard 0.\n","[2021-04-10 00:36:25,735 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618033354271,"user_tz":-420,"elapsed":18424990,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"8099c13b-d49b-44ac-d043-61a740556fbe"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-10 00:36:28,302 INFO]  * src vocab size = 39736\n","[2021-04-10 00:36:28,302 INFO]  * tgt vocab size = 18250\n","[2021-04-10 00:36:28,302 INFO] Building model...\n","[2021-04-10 00:36:35,151 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(39736, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(18250, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=18250, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-10 00:36:35,231 INFO] encoder: 39260160\n","[2021-04-10 00:36:35,231 INFO] decoder: 43931466\n","[2021-04-10 00:36:35,231 INFO] * number of parameters: 83191626\n","[2021-04-10 00:36:35,235 INFO] Starting training on GPU: [0]\n","[2021-04-10 00:36:35,235 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-10 00:36:35,235 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:36:37,762 INFO] number of examples: 77471\n","[2021-04-10 00:38:44,083 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:38:47,144 INFO] number of examples: 77471\n","[2021-04-10 00:40:54,046 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:40:56,816 INFO] number of examples: 77471\n","[2021-04-10 00:43:03,284 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:43:06,288 INFO] number of examples: 77471\n","[2021-04-10 00:45:13,288 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:45:16,496 INFO] number of examples: 77471\n","[2021-04-10 00:46:24,714 INFO] Step 1000/30000; acc:  13.36; ppl: 263.55; xent: 5.57; lr: 0.00012; 10325/12966 tok/s;    589 sec\n","[2021-04-10 00:46:24,715 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 00:46:24,994 INFO] number of examples: 10362\n","[2021-04-10 00:46:41,693 INFO] Validation perplexity: 108.103\n","[2021-04-10 00:46:41,693 INFO] Validation accuracy: 25.6108\n","[2021-04-10 00:46:41,869 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-10 00:47:44,584 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:47:47,953 INFO] number of examples: 77471\n","[2021-04-10 00:49:55,184 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:49:58,681 INFO] number of examples: 77471\n","[2021-04-10 00:52:05,529 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:52:08,588 INFO] number of examples: 77471\n","[2021-04-10 00:54:15,857 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:54:18,869 INFO] number of examples: 77471\n","[2021-04-10 00:56:25,686 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:56:29,266 INFO] number of examples: 77471\n","[2021-04-10 00:56:39,117 INFO] Step 2000/30000; acc:  39.84; ppl: 21.77; xent: 3.08; lr: 0.00025; 9915/12464 tok/s;   1204 sec\n","[2021-04-10 00:56:39,118 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 00:56:39,409 INFO] number of examples: 10362\n","[2021-04-10 00:56:56,128 INFO] Validation perplexity: 21.2973\n","[2021-04-10 00:56:56,128 INFO] Validation accuracy: 46.3821\n","[2021-04-10 00:56:56,313 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-10 00:58:57,993 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:59:01,024 INFO] number of examples: 77471\n","[2021-04-10 01:01:07,774 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:01:11,335 INFO] number of examples: 77471\n","[2021-04-10 01:03:18,557 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:03:21,667 INFO] number of examples: 77471\n","[2021-04-10 01:05:28,181 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:05:31,680 INFO] number of examples: 77471\n","[2021-04-10 01:06:48,775 INFO] Step 3000/30000; acc:  56.93; ppl:  6.86; xent: 1.93; lr: 0.00037; 9975/12537 tok/s;   1814 sec\n","[2021-04-10 01:06:48,776 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:06:49,061 INFO] number of examples: 10362\n","[2021-04-10 01:07:05,694 INFO] Validation perplexity: 15.5326\n","[2021-04-10 01:07:05,694 INFO] Validation accuracy: 51.1417\n","[2021-04-10 01:07:05,866 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-10 01:07:59,982 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:08:02,987 INFO] number of examples: 77471\n","[2021-04-10 01:10:09,327 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:10:12,838 INFO] number of examples: 77471\n","[2021-04-10 01:12:19,760 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:12:22,826 INFO] number of examples: 77471\n","[2021-04-10 01:14:29,427 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:14:32,428 INFO] number of examples: 77471\n","[2021-04-10 01:16:39,377 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:16:42,370 INFO] number of examples: 77471\n","[2021-04-10 01:17:00,797 INFO] Step 4000/30000; acc:  65.29; ppl:  4.17; xent: 1.43; lr: 0.00049; 9956/12506 tok/s;   2426 sec\n","[2021-04-10 01:17:00,798 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:17:01,539 INFO] number of examples: 10362\n","[2021-04-10 01:17:18,163 INFO] Validation perplexity: 16.0746\n","[2021-04-10 01:17:18,163 INFO] Validation accuracy: 51.5929\n","[2021-04-10 01:17:18,327 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-10 01:19:10,140 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:19:13,635 INFO] number of examples: 77471\n","[2021-04-10 01:21:20,532 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:21:23,765 INFO] number of examples: 77471\n","[2021-04-10 01:23:30,123 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:23:33,227 INFO] number of examples: 77471\n","[2021-04-10 01:25:40,146 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:25:43,208 INFO] number of examples: 77471\n","[2021-04-10 01:27:09,035 INFO] Step 5000/30000; acc:  71.64; ppl:  3.05; xent: 1.11; lr: 0.00062; 10009/12582 tok/s;   3034 sec\n","[2021-04-10 01:27:09,036 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:27:09,327 INFO] number of examples: 10362\n","[2021-04-10 01:27:25,950 INFO] Validation perplexity: 17.8082\n","[2021-04-10 01:27:25,951 INFO] Validation accuracy: 51.7734\n","[2021-04-10 01:27:26,115 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-10 01:28:10,909 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:28:14,438 INFO] number of examples: 77471\n","[2021-04-10 01:30:21,324 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:30:24,403 INFO] number of examples: 77471\n","[2021-04-10 01:32:30,791 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:32:33,763 INFO] number of examples: 77471\n","[2021-04-10 01:34:40,664 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:34:44,095 INFO] number of examples: 77471\n","[2021-04-10 01:36:50,414 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:36:53,424 INFO] number of examples: 77471\n","[2021-04-10 01:37:21,008 INFO] Step 6000/30000; acc:  76.94; ppl:  2.42; xent: 0.88; lr: 0.00074; 9955/12501 tok/s;   3646 sec\n","[2021-04-10 01:37:21,009 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:37:21,298 INFO] number of examples: 10362\n","[2021-04-10 01:37:37,924 INFO] Validation perplexity: 20.9716\n","[2021-04-10 01:37:37,925 INFO] Validation accuracy: 51.4441\n","[2021-04-10 01:37:38,089 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-10 01:39:21,259 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:39:24,695 INFO] number of examples: 77471\n","[2021-04-10 01:41:31,085 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:41:34,001 INFO] number of examples: 77471\n","[2021-04-10 01:43:40,879 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:43:44,242 INFO] number of examples: 77471\n","[2021-04-10 01:45:50,598 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:45:54,078 INFO] number of examples: 77471\n","[2021-04-10 01:47:29,051 INFO] Step 7000/30000; acc:  81.22; ppl:  2.05; xent: 0.72; lr: 0.00086; 10010/12587 tok/s;   4254 sec\n","[2021-04-10 01:47:29,052 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:47:29,336 INFO] number of examples: 10362\n","[2021-04-10 01:47:45,953 INFO] Validation perplexity: 24.0538\n","[2021-04-10 01:47:45,953 INFO] Validation accuracy: 51.4174\n","[2021-04-10 01:47:46,134 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-10 01:48:23,179 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:48:26,159 INFO] number of examples: 77471\n","[2021-04-10 01:50:32,481 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:50:36,030 INFO] number of examples: 77471\n","[2021-04-10 01:52:42,930 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:52:46,008 INFO] number of examples: 77471\n","[2021-04-10 01:54:52,393 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:54:55,925 INFO] number of examples: 77471\n","[2021-04-10 01:57:02,830 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:57:05,908 INFO] number of examples: 77471\n","[2021-04-10 01:57:41,768 INFO] Step 8000/30000; acc:  84.15; ppl:  1.84; xent: 0.61; lr: 0.00099; 9929/12469 tok/s;   4867 sec\n","[2021-04-10 01:57:41,769 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:57:42,055 INFO] number of examples: 10362\n","[2021-04-10 01:57:58,686 INFO] Validation perplexity: 26.2583\n","[2021-04-10 01:57:58,686 INFO] Validation accuracy: 51.4296\n","[2021-04-10 01:57:58,852 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-10 01:59:33,067 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:59:36,018 INFO] number of examples: 77471\n","[2021-04-10 02:01:42,907 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:01:46,283 INFO] number of examples: 77471\n","[2021-04-10 02:03:52,646 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:03:56,161 INFO] number of examples: 77471\n","[2021-04-10 02:06:03,071 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:06:06,153 INFO] number of examples: 77471\n","[2021-04-10 02:07:49,644 INFO] Step 9000/30000; acc:  87.27; ppl:  1.66; xent: 0.51; lr: 0.00093; 10023/12598 tok/s;   5474 sec\n","[2021-04-10 02:07:49,645 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:07:49,935 INFO] number of examples: 10362\n","[2021-04-10 02:08:06,562 INFO] Validation perplexity: 27.2993\n","[2021-04-10 02:08:06,562 INFO] Validation accuracy: 51.4805\n","[2021-04-10 02:08:06,725 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-10 02:08:33,408 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:08:36,489 INFO] number of examples: 77471\n","[2021-04-10 02:10:43,377 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:10:46,761 INFO] number of examples: 77471\n","[2021-04-10 02:12:53,172 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:12:56,681 INFO] number of examples: 77471\n","[2021-04-10 02:15:03,599 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:15:06,650 INFO] number of examples: 77471\n","[2021-04-10 02:17:13,060 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:17:16,061 INFO] number of examples: 77471\n","[2021-04-10 02:18:01,113 INFO] Step 10000/30000; acc:  91.16; ppl:  1.47; xent: 0.39; lr: 0.00088; 9956/12499 tok/s;   6086 sec\n","[2021-04-10 02:18:01,114 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:18:01,401 INFO] number of examples: 10362\n","[2021-04-10 02:18:18,027 INFO] Validation perplexity: 29.9098\n","[2021-04-10 02:18:18,027 INFO] Validation accuracy: 51.6324\n","[2021-04-10 02:18:18,192 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-10 02:19:44,026 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:19:47,388 INFO] number of examples: 77471\n","[2021-04-10 02:21:53,718 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:21:57,254 INFO] number of examples: 77471\n","[2021-04-10 02:24:04,134 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:24:07,207 INFO] number of examples: 77471\n","[2021-04-10 02:26:13,600 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:26:16,602 INFO] number of examples: 77471\n","[2021-04-10 02:28:09,367 INFO] Step 11000/30000; acc:  93.40; ppl:  1.37; xent: 0.32; lr: 0.00084; 10019/12596 tok/s;   6694 sec\n","[2021-04-10 02:28:09,368 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:28:10,259 INFO] number of examples: 10362\n","[2021-04-10 02:28:26,883 INFO] Validation perplexity: 29.1175\n","[2021-04-10 02:28:26,883 INFO] Validation accuracy: 52.3898\n","[2021-04-10 02:28:27,053 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-10 02:28:45,246 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:28:48,703 INFO] number of examples: 77471\n","[2021-04-10 02:30:55,174 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:30:58,679 INFO] number of examples: 77471\n","[2021-04-10 02:33:05,655 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:33:08,713 INFO] number of examples: 77471\n","[2021-04-10 02:35:15,077 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:35:18,076 INFO] number of examples: 77471\n","[2021-04-10 02:37:24,985 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:37:28,543 INFO] number of examples: 77471\n","[2021-04-10 02:38:22,225 INFO] Step 12000/30000; acc:  94.85; ppl:  1.31; xent: 0.27; lr: 0.00081; 9928/12470 tok/s;   7307 sec\n","[2021-04-10 02:38:22,226 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:38:22,513 INFO] number of examples: 10362\n","[2021-04-10 02:38:39,141 INFO] Validation perplexity: 29.407\n","[2021-04-10 02:38:39,141 INFO] Validation accuracy: 52.6298\n","[2021-04-10 02:38:39,308 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-10 02:39:56,233 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:39:59,199 INFO] number of examples: 77471\n","[2021-04-10 02:42:06,124 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:42:09,623 INFO] number of examples: 77471\n","[2021-04-10 02:44:15,974 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:44:18,900 INFO] number of examples: 77471\n","[2021-04-10 02:46:25,777 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:46:29,205 INFO] number of examples: 77471\n","[2021-04-10 02:48:30,585 INFO] Step 13000/30000; acc:  95.87; ppl:  1.26; xent: 0.23; lr: 0.00078; 10014/12593 tok/s;   7915 sec\n","[2021-04-10 02:48:30,586 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:48:30,874 INFO] number of examples: 10362\n","[2021-04-10 02:48:47,504 INFO] Validation perplexity: 29.9986\n","[2021-04-10 02:48:47,504 INFO] Validation accuracy: 52.8656\n","[2021-04-10 02:48:47,674 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-10 02:48:56,875 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:49:00,609 INFO] number of examples: 77471\n","[2021-04-10 02:51:07,672 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:51:10,707 INFO] number of examples: 77471\n","[2021-04-10 02:53:17,118 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:53:20,121 INFO] number of examples: 77471\n","[2021-04-10 02:55:27,013 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:55:30,464 INFO] number of examples: 77471\n","[2021-04-10 02:57:36,925 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:57:40,533 INFO] number of examples: 77471\n","[2021-04-10 02:58:43,396 INFO] Step 14000/30000; acc:  96.61; ppl:  1.23; xent: 0.21; lr: 0.00075; 9927/12468 tok/s;   8528 sec\n","[2021-04-10 02:58:43,397 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:58:43,686 INFO] number of examples: 10362\n","[2021-04-10 02:59:00,332 INFO] Validation perplexity: 31.0929\n","[2021-04-10 02:59:00,332 INFO] Validation accuracy: 53.3363\n","[2021-04-10 02:59:00,496 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-10 03:00:08,904 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:00:11,972 INFO] number of examples: 77471\n","[2021-04-10 03:02:18,441 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:02:21,446 INFO] number of examples: 77471\n","[2021-04-10 03:04:28,363 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:04:31,802 INFO] number of examples: 77471\n","[2021-04-10 03:06:38,325 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:06:41,312 INFO] number of examples: 77471\n","[2021-04-10 03:08:48,273 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:08:51,662 INFO] number of examples: 77471\n","[2021-04-10 03:08:55,734 INFO] Step 15000/30000; acc:  97.17; ppl:  1.20; xent: 0.19; lr: 0.00072; 9946/12505 tok/s;   9140 sec\n","[2021-04-10 03:08:55,735 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:08:56,025 INFO] number of examples: 10362\n","[2021-04-10 03:09:12,662 INFO] Validation perplexity: 31.1764\n","[2021-04-10 03:09:12,662 INFO] Validation accuracy: 53.1323\n","[2021-04-10 03:09:12,826 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-10 03:11:19,245 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:11:22,835 INFO] number of examples: 77471\n","[2021-04-10 03:13:30,035 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:13:33,065 INFO] number of examples: 77471\n","[2021-04-10 03:15:39,744 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:15:43,389 INFO] number of examples: 77471\n","[2021-04-10 03:17:50,658 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:17:53,887 INFO] number of examples: 77471\n","[2021-04-10 03:19:05,486 INFO] Step 16000/30000; acc:  97.59; ppl:  1.18; xent: 0.17; lr: 0.00070; 9982/12540 tok/s;   9750 sec\n","[2021-04-10 03:19:05,487 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:19:05,779 INFO] number of examples: 10362\n","[2021-04-10 03:19:22,487 INFO] Validation perplexity: 32.4153\n","[2021-04-10 03:19:22,487 INFO] Validation accuracy: 53.0829\n","[2021-04-10 03:19:22,655 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-10 03:20:21,989 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:20:25,175 INFO] number of examples: 77471\n","[2021-04-10 03:22:32,432 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:22:35,972 INFO] number of examples: 77471\n","[2021-04-10 03:24:42,691 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:24:45,724 INFO] number of examples: 77471\n","[2021-04-10 03:26:52,952 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:26:56,516 INFO] number of examples: 77471\n","[2021-04-10 03:29:03,234 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:29:06,288 INFO] number of examples: 77471\n","[2021-04-10 03:29:19,516 INFO] Step 17000/30000; acc:  97.90; ppl:  1.17; xent: 0.16; lr: 0.00068; 9920/12461 tok/s;  10364 sec\n","[2021-04-10 03:29:19,517 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:29:20,412 INFO] number of examples: 10362\n","[2021-04-10 03:29:37,115 INFO] Validation perplexity: 32.7021\n","[2021-04-10 03:29:37,115 INFO] Validation accuracy: 53.3383\n","[2021-04-10 03:29:37,304 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-10 03:31:35,565 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:31:39,796 INFO] number of examples: 77471\n","[2021-04-10 03:33:46,539 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:33:49,757 INFO] number of examples: 77471\n","[2021-04-10 03:35:56,989 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:36:00,172 INFO] number of examples: 77471\n","[2021-04-10 03:38:06,925 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:38:10,079 INFO] number of examples: 77471\n","[2021-04-10 03:39:30,877 INFO] Step 18000/30000; acc:  98.15; ppl:  1.15; xent: 0.14; lr: 0.00066; 9954/12514 tok/s;  10976 sec\n","[2021-04-10 03:39:30,878 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:39:31,167 INFO] number of examples: 10362\n","[2021-04-10 03:39:47,881 INFO] Validation perplexity: 33.6486\n","[2021-04-10 03:39:47,881 INFO] Validation accuracy: 53.1421\n","[2021-04-10 03:39:48,058 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-10 03:40:38,737 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:40:42,377 INFO] number of examples: 77471\n","[2021-04-10 03:42:49,100 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:42:52,303 INFO] number of examples: 77471\n","[2021-04-10 03:44:59,515 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:45:02,577 INFO] number of examples: 77471\n","[2021-04-10 03:47:09,288 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:47:12,907 INFO] number of examples: 77471\n","[2021-04-10 03:49:20,110 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:49:23,219 INFO] number of examples: 77471\n","[2021-04-10 03:49:45,204 INFO] Step 19000/30000; acc:  98.35; ppl:  1.14; xent: 0.13; lr: 0.00064; 9920/12455 tok/s;  11590 sec\n","[2021-04-10 03:49:45,205 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:49:45,499 INFO] number of examples: 10362\n","[2021-04-10 03:50:02,207 INFO] Validation perplexity: 33.5263\n","[2021-04-10 03:50:02,207 INFO] Validation accuracy: 53.3896\n","[2021-04-10 03:50:02,376 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-10 03:51:51,354 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:51:54,890 INFO] number of examples: 77471\n","[2021-04-10 03:54:02,135 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:54:05,225 INFO] number of examples: 77471\n","[2021-04-10 03:56:12,266 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:56:15,819 INFO] number of examples: 77471\n","[2021-04-10 03:58:23,089 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:58:26,768 INFO] number of examples: 77471\n","[2021-04-10 03:59:56,363 INFO] Step 20000/30000; acc:  98.53; ppl:  1.13; xent: 0.12; lr: 0.00062; 9962/12524 tok/s;  12201 sec\n","[2021-04-10 03:59:56,364 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:59:56,657 INFO] number of examples: 10362\n","[2021-04-10 04:00:13,373 INFO] Validation perplexity: 34.2002\n","[2021-04-10 04:00:13,373 INFO] Validation accuracy: 53.4992\n","[2021-04-10 04:00:13,546 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-10 04:00:55,026 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:00:58,133 INFO] number of examples: 77471\n","[2021-04-10 04:03:05,439 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:03:09,105 INFO] number of examples: 77471\n","[2021-04-10 04:05:15,896 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:05:19,057 INFO] number of examples: 77471\n","[2021-04-10 04:07:26,317 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:07:29,393 INFO] number of examples: 77471\n","[2021-04-10 04:09:36,152 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:09:39,770 INFO] number of examples: 77471\n","[2021-04-10 04:10:10,872 INFO] Step 21000/30000; acc:  98.66; ppl:  1.13; xent: 0.12; lr: 0.00061; 9911/12449 tok/s;  12816 sec\n","[2021-04-10 04:10:10,873 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:10:11,171 INFO] number of examples: 10362\n","[2021-04-10 04:10:27,882 INFO] Validation perplexity: 34.2376\n","[2021-04-10 04:10:27,882 INFO] Validation accuracy: 53.2666\n","[2021-04-10 04:10:28,060 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-10 04:12:08,874 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:12:12,598 INFO] number of examples: 77471\n","[2021-04-10 04:14:19,349 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:14:22,606 INFO] number of examples: 77471\n","[2021-04-10 04:16:29,838 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:16:33,067 INFO] number of examples: 77471\n","[2021-04-10 04:18:39,824 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:18:43,019 INFO] number of examples: 77471\n","[2021-04-10 04:20:21,611 INFO] Step 22000/30000; acc:  98.76; ppl:  1.12; xent: 0.11; lr: 0.00060; 9962/12525 tok/s;  13426 sec\n","[2021-04-10 04:20:21,612 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:20:21,902 INFO] number of examples: 10362\n","[2021-04-10 04:20:38,611 INFO] Validation perplexity: 35.6151\n","[2021-04-10 04:20:38,611 INFO] Validation accuracy: 53.265\n","[2021-04-10 04:20:38,783 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-10 04:21:11,903 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:21:15,649 INFO] number of examples: 77471\n","[2021-04-10 04:23:22,351 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:23:25,721 INFO] number of examples: 77471\n","[2021-04-10 04:25:32,970 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:25:36,175 INFO] number of examples: 77471\n","[2021-04-10 04:27:42,921 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:27:46,140 INFO] number of examples: 77471\n","[2021-04-10 04:29:53,467 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:29:56,581 INFO] number of examples: 77471\n","[2021-04-10 04:30:35,967 INFO] Step 23000/30000; acc:  98.87; ppl:  1.11; xent: 0.11; lr: 0.00058; 9900/12438 tok/s;  14041 sec\n","[2021-04-10 04:30:35,968 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:30:36,256 INFO] number of examples: 10362\n","[2021-04-10 04:30:52,968 INFO] Validation perplexity: 35.4283\n","[2021-04-10 04:30:52,968 INFO] Validation accuracy: 53.3555\n","[2021-04-10 04:30:53,138 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-10 04:32:24,322 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:32:27,906 INFO] number of examples: 77471\n","[2021-04-10 04:34:35,154 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:34:38,245 INFO] number of examples: 77471\n","[2021-04-10 04:36:44,975 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:36:48,620 INFO] number of examples: 77471\n","[2021-04-10 04:38:55,897 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:38:59,059 INFO] number of examples: 77471\n","[2021-04-10 04:40:46,336 INFO] Step 24000/30000; acc:  98.94; ppl:  1.11; xent: 0.10; lr: 0.00057; 9991/12551 tok/s;  14651 sec\n","[2021-04-10 04:40:46,337 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:40:46,628 INFO] number of examples: 10362\n","[2021-04-10 04:41:03,336 INFO] Validation perplexity: 35.5226\n","[2021-04-10 04:41:03,336 INFO] Validation accuracy: 53.6312\n","[2021-04-10 04:41:03,506 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-10 04:41:27,185 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:41:30,941 INFO] number of examples: 77471\n","[2021-04-10 04:43:38,643 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:43:41,764 INFO] number of examples: 77471\n","[2021-04-10 04:45:48,568 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:45:52,206 INFO] number of examples: 77471\n","[2021-04-10 04:47:59,451 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:48:02,584 INFO] number of examples: 77471\n","[2021-04-10 04:50:09,358 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:50:12,438 INFO] number of examples: 77471\n","[2021-04-10 04:51:01,101 INFO] Step 25000/30000; acc:  99.00; ppl:  1.10; xent: 0.10; lr: 0.00056; 9899/12431 tok/s;  15266 sec\n","[2021-04-10 04:51:01,102 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:51:02,044 INFO] number of examples: 10362\n","[2021-04-10 04:51:18,781 INFO] Validation perplexity: 35.8832\n","[2021-04-10 04:51:18,781 INFO] Validation accuracy: 53.6844\n","[2021-04-10 04:51:18,953 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-10 04:52:41,646 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:52:45,075 INFO] number of examples: 77471\n","[2021-04-10 04:54:51,900 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:54:55,581 INFO] number of examples: 77471\n","[2021-04-10 04:57:02,901 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:57:06,065 INFO] number of examples: 77471\n","[2021-04-10 04:59:12,914 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:59:16,024 INFO] number of examples: 77471\n","[2021-04-10 05:01:12,614 INFO] Step 26000/30000; acc:  99.06; ppl:  1.10; xent: 0.09; lr: 0.00055; 9966/12528 tok/s;  15877 sec\n","[2021-04-10 05:01:12,615 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:01:13,541 INFO] number of examples: 10362\n","[2021-04-10 05:01:30,286 INFO] Validation perplexity: 36.585\n","[2021-04-10 05:01:30,286 INFO] Validation accuracy: 53.4933\n","[2021-04-10 05:01:30,457 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-10 05:01:45,316 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:01:49,085 INFO] number of examples: 77471\n","[2021-04-10 05:03:56,086 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:03:59,761 INFO] number of examples: 77471\n","[2021-04-10 05:06:07,134 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:06:10,337 INFO] number of examples: 77471\n","[2021-04-10 05:08:17,206 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:08:20,318 INFO] number of examples: 77471\n","[2021-04-10 05:10:27,663 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:10:31,353 INFO] number of examples: 77471\n","[2021-04-10 05:11:28,788 INFO] Step 27000/30000; acc:  99.13; ppl:  1.09; xent: 0.09; lr: 0.00054; 9873/12403 tok/s;  16494 sec\n","[2021-04-10 05:11:28,790 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:11:29,090 INFO] number of examples: 10362\n","[2021-04-10 05:11:45,831 INFO] Validation perplexity: 35.3744\n","[2021-04-10 05:11:45,832 INFO] Validation accuracy: 53.5063\n","[2021-04-10 05:11:46,006 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-10 05:12:59,763 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:13:02,911 INFO] number of examples: 77471\n","[2021-04-10 05:15:10,387 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:15:14,050 INFO] number of examples: 77471\n","[2021-04-10 05:17:20,999 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:17:24,117 INFO] number of examples: 77471\n","[2021-04-10 05:19:31,586 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:19:35,193 INFO] number of examples: 77471\n","[2021-04-10 05:21:40,397 INFO] Step 28000/30000; acc:  99.17; ppl:  1.09; xent: 0.09; lr: 0.00053; 9960/12522 tok/s;  17105 sec\n","[2021-04-10 05:21:40,398 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:21:40,694 INFO] number of examples: 10362\n","[2021-04-10 05:21:57,451 INFO] Validation perplexity: 36.5707\n","[2021-04-10 05:21:57,451 INFO] Validation accuracy: 53.5979\n","[2021-04-10 05:21:57,623 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-10 05:22:03,291 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:22:06,999 INFO] number of examples: 77471\n","[2021-04-10 05:24:14,530 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:24:17,695 INFO] number of examples: 77471\n","[2021-04-10 05:26:24,581 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:26:27,680 INFO] number of examples: 77471\n","[2021-04-10 05:28:35,006 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:28:38,561 INFO] number of examples: 77471\n","[2021-04-10 05:30:45,425 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:30:49,227 INFO] number of examples: 77471\n","[2021-04-10 05:31:55,716 INFO] Step 29000/30000; acc:  99.21; ppl:  1.09; xent: 0.08; lr: 0.00052; 9889/12419 tok/s;  17720 sec\n","[2021-04-10 05:31:55,717 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:31:56,010 INFO] number of examples: 10362\n","[2021-04-10 05:32:12,729 INFO] Validation perplexity: 37.4306\n","[2021-04-10 05:32:12,729 INFO] Validation accuracy: 53.5274\n","[2021-04-10 05:32:12,910 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-10 05:33:19,059 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:33:22,187 INFO] number of examples: 77471\n","[2021-04-10 05:35:28,961 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:35:32,624 INFO] number of examples: 77471\n","[2021-04-10 05:37:39,878 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:37:43,041 INFO] number of examples: 77471\n","[2021-04-10 05:39:49,828 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:39:52,942 INFO] number of examples: 77471\n","[2021-04-10 05:42:00,185 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:42:03,855 INFO] number of examples: 77471\n","[2021-04-10 05:42:11,419 INFO] Step 30000/30000; acc:  99.25; ppl:  1.08; xent: 0.08; lr: 0.00051; 9892/12437 tok/s;  18336 sec\n","[2021-04-10 05:42:11,420 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:42:11,737 INFO] number of examples: 10362\n","[2021-04-10 05:42:28,455 INFO] Validation perplexity: 37.1203\n","[2021-04-10 05:42:28,455 INFO] Validation accuracy: 53.5971\n","[2021-04-10 05:42:28,625 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618033354272,"user_tz":-420,"elapsed":18424990,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"81e4d10b-adbe-4569-bd9b-fdb19d3aa6e4"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 29911725\n","-rw------- 1 root root 1020986879 Apr 10 02:18 en-vi_step_10000.pt\n","-rw------- 1 root root 1020986815 Apr 10 00:46 en-vi_step_1000.pt\n","-rw------- 1 root root 1020986879 Apr 10 02:28 en-vi_step_11000.pt\n","-rw------- 1 root root 1020986879 Apr 10 02:38 en-vi_step_12000.pt\n","-rw------- 1 root root 1020986879 Apr 10 02:48 en-vi_step_13000.pt\n","-rw------- 1 root root 1020986815 Apr 10 02:59 en-vi_step_14000.pt\n","-rw------- 1 root root 1020986815 Apr 10 03:09 en-vi_step_15000.pt\n","-rw------- 1 root root 1020986815 Apr 10 03:19 en-vi_step_16000.pt\n","-rw------- 1 root root 1020986879 Apr 10 03:29 en-vi_step_17000.pt\n","-rw------- 1 root root 1020986879 Apr 10 03:39 en-vi_step_18000.pt\n","-rw------- 1 root root 1020986879 Apr 10 03:50 en-vi_step_19000.pt\n","-rw------- 1 root root 1020986879 Apr 10 04:00 en-vi_step_20000.pt\n","-rw------- 1 root root 1020986879 Apr 10 00:57 en-vi_step_2000.pt\n","-rw------- 1 root root 1020986879 Apr 10 04:10 en-vi_step_21000.pt\n","-rw------- 1 root root 1020986879 Apr 10 04:20 en-vi_step_22000.pt\n","-rw------- 1 root root 1020986879 Apr 10 04:30 en-vi_step_23000.pt\n","-rw------- 1 root root 1020986815 Apr 10 04:41 en-vi_step_24000.pt\n","-rw------- 1 root root 1020986815 Apr 10 04:51 en-vi_step_25000.pt\n","-rw------- 1 root root 1020986879 Apr 10 05:01 en-vi_step_26000.pt\n","-rw------- 1 root root 1020986815 Apr 10 05:11 en-vi_step_27000.pt\n","-rw------- 1 root root 1020986815 Apr 10 05:22 en-vi_step_28000.pt\n","-rw------- 1 root root 1020986879 Apr 10 05:32 en-vi_step_29000.pt\n","-rw------- 1 root root 1020986879 Apr 10 05:42 en-vi_step_30000.pt\n","-rw------- 1 root root 1020986879 Apr 10 01:07 en-vi_step_3000.pt\n","-rw------- 1 root root 1020986815 Apr 10 01:17 en-vi_step_4000.pt\n","-rw------- 1 root root 1020986815 Apr 10 01:27 en-vi_step_5000.pt\n","-rw------- 1 root root 1020986879 Apr 10 01:37 en-vi_step_6000.pt\n","-rw------- 1 root root 1020986815 Apr 10 01:47 en-vi_step_7000.pt\n","-rw------- 1 root root 1020986879 Apr 10 01:58 en-vi_step_8000.pt\n","-rw------- 1 root root 1020986879 Apr 10 02:08 en-vi_step_9000.pt\n","\n","model/:\n","total 29911725\n","-rw------- 1 root root 1020986879 Apr 10 02:18 en-vi_step_10000.pt\n","-rw------- 1 root root 1020986815 Apr 10 00:46 en-vi_step_1000.pt\n","-rw------- 1 root root 1020986879 Apr 10 02:28 en-vi_step_11000.pt\n","-rw------- 1 root root 1020986879 Apr 10 02:38 en-vi_step_12000.pt\n","-rw------- 1 root root 1020986879 Apr 10 02:48 en-vi_step_13000.pt\n","-rw------- 1 root root 1020986815 Apr 10 02:59 en-vi_step_14000.pt\n","-rw------- 1 root root 1020986815 Apr 10 03:09 en-vi_step_15000.pt\n","-rw------- 1 root root 1020986815 Apr 10 03:19 en-vi_step_16000.pt\n","-rw------- 1 root root 1020986879 Apr 10 03:29 en-vi_step_17000.pt\n","-rw------- 1 root root 1020986879 Apr 10 03:39 en-vi_step_18000.pt\n","-rw------- 1 root root 1020986879 Apr 10 03:50 en-vi_step_19000.pt\n","-rw------- 1 root root 1020986879 Apr 10 04:00 en-vi_step_20000.pt\n","-rw------- 1 root root 1020986879 Apr 10 00:57 en-vi_step_2000.pt\n","-rw------- 1 root root 1020986879 Apr 10 04:10 en-vi_step_21000.pt\n","-rw------- 1 root root 1020986879 Apr 10 04:20 en-vi_step_22000.pt\n","-rw------- 1 root root 1020986879 Apr 10 04:30 en-vi_step_23000.pt\n","-rw------- 1 root root 1020986815 Apr 10 04:41 en-vi_step_24000.pt\n","-rw------- 1 root root 1020986815 Apr 10 04:51 en-vi_step_25000.pt\n","-rw------- 1 root root 1020986879 Apr 10 05:01 en-vi_step_26000.pt\n","-rw------- 1 root root 1020986815 Apr 10 05:11 en-vi_step_27000.pt\n","-rw------- 1 root root 1020986815 Apr 10 05:22 en-vi_step_28000.pt\n","-rw------- 1 root root 1020986879 Apr 10 05:32 en-vi_step_29000.pt\n","-rw------- 1 root root 1020986879 Apr 10 05:42 en-vi_step_30000.pt\n","-rw------- 1 root root 1020986879 Apr 10 01:07 en-vi_step_3000.pt\n","-rw------- 1 root root 1020986815 Apr 10 01:17 en-vi_step_4000.pt\n","-rw------- 1 root root 1020986815 Apr 10 01:27 en-vi_step_5000.pt\n","-rw------- 1 root root 1020986879 Apr 10 01:37 en-vi_step_6000.pt\n","-rw------- 1 root root 1020986815 Apr 10 01:47 en-vi_step_7000.pt\n","-rw------- 1 root root 1020986879 Apr 10 01:58 en-vi_step_8000.pt\n","-rw------- 1 root root 1020986879 Apr 10 02:08 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618035605902,"user_tz":-420,"elapsed":20676618,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"7f93e6f2-381c-41a2-d584-47bc0599bab8"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-10 05:42:40,742 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 06:18:48,807 INFO] PRED AVG SCORE: -0.4377, PRED PPL: 1.5491\n","[2021-04-10 06:18:48,808 INFO] GOLD AVG SCORE: -3.6305, GOLD PPL: 37.7301\n","[2021-04-10 06:18:48,834 INFO] Translating shard 1.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 06:20:05,036 INFO] PRED AVG SCORE: -0.4408, PRED PPL: 1.5540\n","[2021-04-10 06:20:05,036 INFO] GOLD AVG SCORE: -3.6384, GOLD PPL: 38.0326\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618035605903,"user_tz":-420,"elapsed":20676618,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"b8ff587d-5d07-4abb-8e3a-c28f4f2d37ad"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cà vạt thì loè loẹt .\n","và lí do là bởi vì có 2 lí do , theo tôi nghĩ\n","Ông thích nói về thiên tài tâm linh của lứa tuổi .\n","Chúng tôi đều là người Triều Tiên , nhưng đã trở nên rất khác nhau do hậu quả của 67 năm bị chia cắt .\n","Đó là cách bạn xử lý một vấn đề khi bạn nhìn thấy chúng và đó không chỉ là việc than phiền về vấn đề đó .\n","Tham vọng của các bạn được thoã mãn , nó rất đẹp .\n","Không có thứ nào trong những điều trên thực sự hữu ích bởi vì bạn đang điều trị những triệu chứng chứ không phải nguyên nhân của các vấn đề cơ bản ở Phi Châu .\n","Nhưng hiện nay nhiều người sống đến 90 hay 100 tuổi , trừ khi họ bắt tay quá nhiều hay làm những điều đại loại thế .\n","Nhưng quý vị phải có những công cụ đúng .\n","Những điều này là một phần cuộc đời ông và là những gì ông còn nhớ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618035623975,"user_tz":-420,"elapsed":20694689,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"a7aed113-91eb-44e2-8325-f7f46558359b"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 32, done.\u001b[K\n","remote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (27/27), done.\u001b[K\n","remote: Total 17114 (delta 8), reused 11 (delta 4), pack-reused 17082\u001b[K\n","Receiving objects: 100% (17114/17114), 273.03 MiB | 23.99 MiB/s, done.\n","Resolving deltas: 100% (12332/12332), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618035623976,"user_tz":-420,"elapsed":20694688,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"1098e1e9-5abf-4d8a-80ea-436b23b37b86"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 93607\n","drwx------  2 root root     4096 Apr 10 00:36 data_bin\n","-rw-------  1 root root   996149 Apr  9 11:16 en_test\n","-rw-------  1 root root  8024744 Apr  9 11:16 en_train\n","-rw-------  1 root root  8161362 Apr  9 11:42 en_train_EM_0.8\n","-rw-------  1 root root  8075706 Apr  9 11:42 en_train_EM_0.85\n","-rw-------  1 root root  8040373 Apr  9 11:42 en_train_EM_0.9\n","-rw-------  1 root root  8026272 Apr  9 11:42 en_train_EM_0.95\n","-rw-------  1 root root  3303720 Apr  9 11:42 en_train_EM_factor_0.8\n","-rw-------  1 root root  3268996 Apr  9 11:42 en_train_EM_factor_0.85\n","-rw-------  1 root root  3254332 Apr  9 11:42 en_train_EM_factor_0.9\n","-rw-------  1 root root  3248468 Apr  9 11:42 en_train_EM_factor_0.95\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.8\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.85\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.9\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.95\n","-rw-------  1 root root  1000856 Apr  9 11:16 en_valid\n","-rw-------  1 root root 22435544 Apr 10 00:36 en_vi_iwslt_bert.tar.gz\n","drwx------  2 root root     4096 Apr 10 05:42 model\n","drwx------ 11 root root     4096 Apr 10 06:20 OpenNMT-py\n","drwx------  2 root root     4096 Apr 10 00:36 output\n","-rw-------  1 root root  1226030 Apr 10 06:20 predict.txt\n","-rw-------  1 root root  1327417 Apr  9 11:16 vi_test\n","-rw-------  1 root root 10671354 Apr  9 11:16 vi_train\n","-rw-------  1 root root  1330789 Apr  9 11:16 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618035626040,"user_tz":-420,"elapsed":20696751,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"068f9d2c-8116-4358-f461-2af6c2359226"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 23.79, 58.6/32.7/19.2/11.6 (BP=0.930, ratio=0.933, hyp_len=227751, ref_len=244219)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1618035626677,"user_tz":-420,"elapsed":20697387,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}