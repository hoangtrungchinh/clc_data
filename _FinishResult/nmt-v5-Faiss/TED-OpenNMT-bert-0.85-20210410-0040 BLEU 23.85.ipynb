{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TED-OpenNMT-bert-0.85-20210410-0040 BLEU 23.85.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618015225240,"user_tz":-420,"elapsed":20491,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"d377ce06-8112-468f-e90d-0fafb69d23cc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618015226078,"user_tz":-420,"elapsed":21321,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"34eae759-9ae2-49b7-b8c5-942f31635620"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"TED-OpenNMT-bert-0.85-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v3/OpenNMT-TED-EM-bert-ratio-8-2-2-20210128-0637'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/TED-OpenNMT-bert-0.85-20210410-0040\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618015226079,"user_tz":-420,"elapsed":21317,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"82cc4add-66fd-4f2a-c363-9921e56c9249"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Sat Apr 10 00:40:25 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618015242600,"user_tz":-420,"elapsed":37835,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"8217b7a1-a22b-4380-cc36-dbaa5da889ea"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 5.4MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 7.9MB/s \n","\u001b[?25hCollecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Collecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Collecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=162a2a1193f58f9fab5e4cc260ea4fbe347fbeb4e47f276dc10d8bdc28b097d2\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: pyonmttok, configargparse, waitress, torchtext, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618015244471,"user_tz":-420,"elapsed":39704,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"8a4d6cc4-9b09-424d-ea14-a2948de476da"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'en_vi_iwslt_bert.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-10 00:40:42--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22435544 (21M) [application/octet-stream]\n","Saving to: ‘en_vi_iwslt_bert.tar.gz’\n","\n","en_vi_iwslt_bert.ta 100%[===================>]  21.40M  58.0MB/s    in 0.4s    \n","\n","2021-04-10 00:40:42 (58.0 MB/s) - ‘en_vi_iwslt_bert.tar.gz’ saved [22435544/22435544]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618015258482,"user_tz":-420,"elapsed":53712,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"266793f5-13ce-4e09-f782-af8a03d94a0c"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.85' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-10 00:40:47,680 INFO] Extracting features...\n","[2021-04-10 00:40:47,684 INFO]  * number of source features: 0.\n","[2021-04-10 00:40:47,684 INFO]  * number of target features: 0.\n","[2021-04-10 00:40:47,684 INFO] Building `Fields` object...\n","[2021-04-10 00:40:47,684 INFO] Building & saving training data...\n","[2021-04-10 00:40:47,868 INFO] Building shard 0.\n","[2021-04-10 00:40:52,038 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-10 00:40:55,559 INFO]  * tgt vocab size: 18250.\n","[2021-04-10 00:40:55,616 INFO]  * src vocab size: 40278.\n","[2021-04-10 00:40:55,814 INFO] Building & saving validation data...\n","[2021-04-10 00:40:55,932 INFO] Building shard 0.\n","[2021-04-10 00:40:56,206 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618034227647,"user_tz":-420,"elapsed":19022875,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"98bedc26-aa40-4d96-b5b2-eeee880ff8d3"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-10 00:40:59,026 INFO]  * src vocab size = 40278\n","[2021-04-10 00:40:59,026 INFO]  * tgt vocab size = 18250\n","[2021-04-10 00:40:59,026 INFO] Building model...\n","[2021-04-10 00:41:06,691 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(40278, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(18250, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=18250, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-10 00:41:06,775 INFO] encoder: 39537664\n","[2021-04-10 00:41:06,775 INFO] decoder: 43931466\n","[2021-04-10 00:41:06,775 INFO] * number of parameters: 83469130\n","[2021-04-10 00:41:06,780 INFO] Starting training on GPU: [0]\n","[2021-04-10 00:41:06,780 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-10 00:41:06,780 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:41:09,906 INFO] number of examples: 77471\n","[2021-04-10 00:43:20,946 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:43:24,689 INFO] number of examples: 77471\n","[2021-04-10 00:45:35,707 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:45:38,918 INFO] number of examples: 77471\n","[2021-04-10 00:47:49,925 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:47:53,585 INFO] number of examples: 77471\n","[2021-04-10 00:50:04,651 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:50:08,427 INFO] number of examples: 77471\n","[2021-04-10 00:51:15,138 INFO] Step 1000/30000; acc:  13.45; ppl: 256.56; xent: 5.55; lr: 0.00012; 10033/12509 tok/s;    608 sec\n","[2021-04-10 00:51:15,139 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 00:51:15,475 INFO] number of examples: 10362\n","[2021-04-10 00:51:32,258 INFO] Validation perplexity: 103.168\n","[2021-04-10 00:51:32,258 INFO] Validation accuracy: 26.2859\n","[2021-04-10 00:51:32,455 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-10 00:52:41,278 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:52:45,287 INFO] number of examples: 77471\n","[2021-04-10 00:54:56,296 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:54:59,729 INFO] number of examples: 77471\n","[2021-04-10 00:57:10,838 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:57:14,809 INFO] number of examples: 77471\n","[2021-04-10 00:59:25,704 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 00:59:29,179 INFO] number of examples: 77471\n","[2021-04-10 01:01:40,206 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:01:44,216 INFO] number of examples: 77471\n","[2021-04-10 01:01:46,188 INFO] Step 2000/30000; acc:  40.31; ppl: 21.12; xent: 3.05; lr: 0.00025; 9642/12025 tok/s;   1239 sec\n","[2021-04-10 01:01:46,189 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:01:46,536 INFO] number of examples: 10362\n","[2021-04-10 01:02:03,350 INFO] Validation perplexity: 20.6841\n","[2021-04-10 01:02:03,350 INFO] Validation accuracy: 46.6782\n","[2021-04-10 01:02:03,553 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-10 01:04:17,369 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:04:21,472 INFO] number of examples: 77471\n","[2021-04-10 01:06:32,569 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:06:36,130 INFO] number of examples: 77471\n","[2021-04-10 01:08:47,198 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:08:51,319 INFO] number of examples: 77471\n","[2021-04-10 01:11:02,402 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:11:05,956 INFO] number of examples: 77471\n","[2021-04-10 01:12:13,890 INFO] Step 3000/30000; acc:  56.92; ppl:  6.87; xent: 1.93; lr: 0.00037; 9724/12123 tok/s;   1867 sec\n","[2021-04-10 01:12:13,891 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:12:14,751 INFO] number of examples: 10362\n","[2021-04-10 01:12:31,572 INFO] Validation perplexity: 15.758\n","[2021-04-10 01:12:31,573 INFO] Validation accuracy: 51.1417\n","[2021-04-10 01:12:31,778 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-10 01:13:39,756 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:13:43,267 INFO] number of examples: 77471\n","[2021-04-10 01:15:54,352 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:15:58,362 INFO] number of examples: 77471\n","[2021-04-10 01:18:09,522 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:18:13,799 INFO] number of examples: 77471\n","[2021-04-10 01:20:24,880 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:20:28,598 INFO] number of examples: 77471\n","[2021-04-10 01:22:39,720 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:22:43,381 INFO] number of examples: 77471\n","[2021-04-10 01:22:46,347 INFO] Step 4000/30000; acc:  65.25; ppl:  4.18; xent: 1.43; lr: 0.00049; 9614/11994 tok/s;   2500 sec\n","[2021-04-10 01:22:46,348 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:22:46,704 INFO] number of examples: 10362\n","[2021-04-10 01:23:03,528 INFO] Validation perplexity: 16.485\n","[2021-04-10 01:23:03,529 INFO] Validation accuracy: 50.8864\n","[2021-04-10 01:23:03,730 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-10 01:25:16,538 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:25:20,645 INFO] number of examples: 77471\n","[2021-04-10 01:27:31,814 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:27:36,069 INFO] number of examples: 77471\n","[2021-04-10 01:29:47,191 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:29:50,877 INFO] number of examples: 77471\n","[2021-04-10 01:32:01,976 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:32:05,605 INFO] number of examples: 77471\n","[2021-04-10 01:33:14,759 INFO] Step 5000/30000; acc:  71.63; ppl:  3.06; xent: 1.12; lr: 0.00062; 9720/12115 tok/s;   3128 sec\n","[2021-04-10 01:33:14,761 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:33:15,101 INFO] number of examples: 10362\n","[2021-04-10 01:33:31,941 INFO] Validation perplexity: 18.2777\n","[2021-04-10 01:33:31,941 INFO] Validation accuracy: 51.4527\n","[2021-04-10 01:33:32,139 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-10 01:34:38,913 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:34:43,016 INFO] number of examples: 77471\n","[2021-04-10 01:36:54,131 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:36:58,355 INFO] number of examples: 77471\n","[2021-04-10 01:39:09,506 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:39:13,284 INFO] number of examples: 77471\n","[2021-04-10 01:41:24,671 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:41:28,266 INFO] number of examples: 77471\n","[2021-04-10 01:43:39,343 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:43:43,487 INFO] number of examples: 77471\n","[2021-04-10 01:43:47,591 INFO] Step 6000/30000; acc:  77.01; ppl:  2.42; xent: 0.88; lr: 0.00074; 9604/11982 tok/s;   3761 sec\n","[2021-04-10 01:43:47,592 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:43:47,942 INFO] number of examples: 10362\n","[2021-04-10 01:44:04,768 INFO] Validation perplexity: 20.7172\n","[2021-04-10 01:44:04,769 INFO] Validation accuracy: 51.4468\n","[2021-04-10 01:44:04,960 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-10 01:46:16,801 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:46:21,059 INFO] number of examples: 77471\n","[2021-04-10 01:48:32,075 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:48:35,761 INFO] number of examples: 77471\n","[2021-04-10 01:50:46,759 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:50:50,336 INFO] number of examples: 77471\n","[2021-04-10 01:53:01,322 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:53:05,424 INFO] number of examples: 77471\n","[2021-04-10 01:54:15,674 INFO] Step 7000/30000; acc:  81.10; ppl:  2.06; xent: 0.72; lr: 0.00086; 9723/12121 tok/s;   4389 sec\n","[2021-04-10 01:54:15,675 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 01:54:16,022 INFO] number of examples: 10362\n","[2021-04-10 01:54:32,846 INFO] Validation perplexity: 23.2359\n","[2021-04-10 01:54:32,847 INFO] Validation accuracy: 51.7468\n","[2021-04-10 01:54:33,041 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-10 01:55:38,639 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:55:42,848 INFO] number of examples: 77471\n","[2021-04-10 01:57:53,860 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 01:57:57,463 INFO] number of examples: 77471\n","[2021-04-10 02:00:08,510 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:00:12,670 INFO] number of examples: 77471\n","[2021-04-10 02:02:23,693 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:02:27,265 INFO] number of examples: 77471\n","[2021-04-10 02:04:38,319 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:04:42,426 INFO] number of examples: 77471\n","[2021-04-10 02:04:47,751 INFO] Step 8000/30000; acc:  84.23; ppl:  1.84; xent: 0.61; lr: 0.00099; 9622/12001 tok/s;   5021 sec\n","[2021-04-10 02:04:47,752 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:04:48,086 INFO] number of examples: 10362\n","[2021-04-10 02:05:04,902 INFO] Validation perplexity: 25.4762\n","[2021-04-10 02:05:04,902 INFO] Validation accuracy: 51.9242\n","[2021-04-10 02:05:05,096 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-10 02:07:15,389 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:07:19,594 INFO] number of examples: 77471\n","[2021-04-10 02:09:30,479 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:09:34,064 INFO] number of examples: 77471\n","[2021-04-10 02:11:44,948 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:11:48,435 INFO] number of examples: 77471\n","[2021-04-10 02:13:59,294 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:14:03,288 INFO] number of examples: 77471\n","[2021-04-10 02:15:14,521 INFO] Step 9000/30000; acc:  87.44; ppl:  1.65; xent: 0.50; lr: 0.00093; 9738/12141 tok/s;   5648 sec\n","[2021-04-10 02:15:14,522 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:15:14,882 INFO] number of examples: 10362\n","[2021-04-10 02:15:31,685 INFO] Validation perplexity: 27.0841\n","[2021-04-10 02:15:31,685 INFO] Validation accuracy: 52.109\n","[2021-04-10 02:15:31,881 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-10 02:16:36,034 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:16:40,035 INFO] number of examples: 77471\n","[2021-04-10 02:18:50,909 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:18:55,034 INFO] number of examples: 77471\n","[2021-04-10 02:21:06,176 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:21:09,852 INFO] number of examples: 77471\n","[2021-04-10 02:23:20,832 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:23:24,421 INFO] number of examples: 77471\n","[2021-04-10 02:25:35,720 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:25:39,877 INFO] number of examples: 77471\n","[2021-04-10 02:25:46,384 INFO] Step 10000/30000; acc:  91.18; ppl:  1.47; xent: 0.38; lr: 0.00088; 9628/12011 tok/s;   6280 sec\n","[2021-04-10 02:25:46,385 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:25:46,727 INFO] number of examples: 10362\n","[2021-04-10 02:26:03,549 INFO] Validation perplexity: 28.1248\n","[2021-04-10 02:26:03,550 INFO] Validation accuracy: 52.1454\n","[2021-04-10 02:26:03,747 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-10 02:28:13,083 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:28:17,377 INFO] number of examples: 77471\n","[2021-04-10 02:30:28,483 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:30:32,139 INFO] number of examples: 77471\n","[2021-04-10 02:32:43,333 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:32:46,916 INFO] number of examples: 77471\n","[2021-04-10 02:34:58,067 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:35:02,232 INFO] number of examples: 77471\n","[2021-04-10 02:36:14,800 INFO] Step 11000/30000; acc:  93.40; ppl:  1.37; xent: 0.32; lr: 0.00084; 9711/12106 tok/s;   6908 sec\n","[2021-04-10 02:36:14,801 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:36:15,161 INFO] number of examples: 10362\n","[2021-04-10 02:36:31,987 INFO] Validation perplexity: 29.9812\n","[2021-04-10 02:36:31,987 INFO] Validation accuracy: 52.2633\n","[2021-04-10 02:36:32,186 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-10 02:37:35,197 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:37:39,423 INFO] number of examples: 77471\n","[2021-04-10 02:39:50,591 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:39:54,230 INFO] number of examples: 77471\n","[2021-04-10 02:42:05,418 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:42:09,764 INFO] number of examples: 77471\n","[2021-04-10 02:44:20,978 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:44:24,842 INFO] number of examples: 77471\n","[2021-04-10 02:46:36,099 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:46:39,905 INFO] number of examples: 77471\n","[2021-04-10 02:46:47,587 INFO] Step 12000/30000; acc:  94.87; ppl:  1.31; xent: 0.27; lr: 0.00081; 9617/11995 tok/s;   7541 sec\n","[2021-04-10 02:46:47,588 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:46:47,941 INFO] number of examples: 10362\n","[2021-04-10 02:47:04,765 INFO] Validation perplexity: 29.8939\n","[2021-04-10 02:47:04,765 INFO] Validation accuracy: 52.7137\n","[2021-04-10 02:47:04,965 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-10 02:49:12,973 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:49:16,639 INFO] number of examples: 77471\n","[2021-04-10 02:51:27,823 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:51:32,121 INFO] number of examples: 77471\n","[2021-04-10 02:53:43,250 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:53:47,348 INFO] number of examples: 77471\n","[2021-04-10 02:55:58,550 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:56:02,174 INFO] number of examples: 77471\n","[2021-04-10 02:57:15,831 INFO] Step 13000/30000; acc:  95.92; ppl:  1.26; xent: 0.23; lr: 0.00078; 9713/12110 tok/s;   8169 sec\n","[2021-04-10 02:57:15,833 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 02:57:16,189 INFO] number of examples: 10362\n","[2021-04-10 02:57:33,016 INFO] Validation perplexity: 31.8733\n","[2021-04-10 02:57:33,016 INFO] Validation accuracy: 52.8284\n","[2021-04-10 02:57:33,217 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-10 02:58:35,587 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 02:58:39,781 INFO] number of examples: 77471\n","[2021-04-10 03:00:51,157 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:00:55,470 INFO] number of examples: 77471\n","[2021-04-10 03:03:06,634 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:03:10,330 INFO] number of examples: 77471\n","[2021-04-10 03:05:21,355 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:05:24,935 INFO] number of examples: 77471\n","[2021-04-10 03:07:35,976 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:07:40,104 INFO] number of examples: 77471\n","[2021-04-10 03:07:48,957 INFO] Step 14000/30000; acc:  96.65; ppl:  1.23; xent: 0.21; lr: 0.00075; 9613/11988 tok/s;   8802 sec\n","[2021-04-10 03:07:48,958 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:07:49,315 INFO] number of examples: 10362\n","[2021-04-10 03:08:06,127 INFO] Validation perplexity: 33.1887\n","[2021-04-10 03:08:06,128 INFO] Validation accuracy: 52.7348\n","[2021-04-10 03:08:06,330 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-10 03:10:13,903 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:10:18,171 INFO] number of examples: 77471\n","[2021-04-10 03:12:29,196 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:12:32,887 INFO] number of examples: 77471\n","[2021-04-10 03:14:44,021 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:14:47,596 INFO] number of examples: 77471\n","[2021-04-10 03:16:58,902 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:17:03,156 INFO] number of examples: 77471\n","[2021-04-10 03:18:18,254 INFO] Step 15000/30000; acc:  97.20; ppl:  1.20; xent: 0.19; lr: 0.00072; 9696/12091 tok/s;   9431 sec\n","[2021-04-10 03:18:18,255 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:18:18,611 INFO] number of examples: 10362\n","[2021-04-10 03:18:35,436 INFO] Validation perplexity: 31.7872\n","[2021-04-10 03:18:35,436 INFO] Validation accuracy: 53.041\n","[2021-04-10 03:18:35,635 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-10 03:19:36,559 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:19:40,824 INFO] number of examples: 77471\n","[2021-04-10 03:21:51,915 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:21:55,519 INFO] number of examples: 77471\n","[2021-04-10 03:24:06,586 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:24:11,314 INFO] number of examples: 77471\n","[2021-04-10 03:26:22,438 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:26:26,260 INFO] number of examples: 77471\n","[2021-04-10 03:28:37,556 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:28:41,430 INFO] number of examples: 77471\n","[2021-04-10 03:28:51,519 INFO] Step 16000/30000; acc:  97.63; ppl:  1.18; xent: 0.17; lr: 0.00070; 9610/11984 tok/s;  10065 sec\n","[2021-04-10 03:28:51,520 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:28:51,883 INFO] number of examples: 10362\n","[2021-04-10 03:29:08,855 INFO] Validation perplexity: 32.5822\n","[2021-04-10 03:29:08,855 INFO] Validation accuracy: 53.1389\n","[2021-04-10 03:29:09,079 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-10 03:31:15,600 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:31:19,431 INFO] number of examples: 77471\n","[2021-04-10 03:33:31,329 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:33:35,618 INFO] number of examples: 77471\n","[2021-04-10 03:35:47,642 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:35:51,535 INFO] number of examples: 77471\n","[2021-04-10 03:38:03,877 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:38:07,772 INFO] number of examples: 77471\n","[2021-04-10 03:39:24,539 INFO] Step 17000/30000; acc:  97.93; ppl:  1.17; xent: 0.16; lr: 0.00068; 9638/12020 tok/s;  10698 sec\n","[2021-04-10 03:39:24,541 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:39:24,909 INFO] number of examples: 10362\n","[2021-04-10 03:39:42,005 INFO] Validation perplexity: 33.7526\n","[2021-04-10 03:39:42,005 INFO] Validation accuracy: 52.8233\n","[2021-04-10 03:39:42,230 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-10 03:40:42,462 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:40:46,887 INFO] number of examples: 77471\n","[2021-04-10 03:42:59,154 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:43:03,751 INFO] number of examples: 77471\n","[2021-04-10 03:45:15,953 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:45:19,835 INFO] number of examples: 77471\n","[2021-04-10 03:47:32,102 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:47:36,056 INFO] number of examples: 77471\n","[2021-04-10 03:49:48,345 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:49:52,848 INFO] number of examples: 77471\n","[2021-04-10 03:50:04,249 INFO] Step 18000/30000; acc:  98.19; ppl:  1.15; xent: 0.14; lr: 0.00066; 9514/11864 tok/s;  11337 sec\n","[2021-04-10 03:50:04,251 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 03:50:04,628 INFO] number of examples: 10362\n","[2021-04-10 03:50:21,727 INFO] Validation perplexity: 34.1529\n","[2021-04-10 03:50:21,727 INFO] Validation accuracy: 52.951\n","[2021-04-10 03:50:21,952 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-10 03:52:27,700 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:52:32,300 INFO] number of examples: 77471\n","[2021-04-10 03:54:44,680 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:54:48,684 INFO] number of examples: 77471\n","[2021-04-10 03:57:01,075 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:57:04,928 INFO] number of examples: 77471\n","[2021-04-10 03:59:17,275 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 03:59:21,776 INFO] number of examples: 77471\n","[2021-04-10 04:00:39,671 INFO] Step 19000/30000; acc:  98.35; ppl:  1.14; xent: 0.13; lr: 0.00064; 9601/11975 tok/s;  11973 sec\n","[2021-04-10 04:00:39,673 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:00:40,052 INFO] number of examples: 10362\n","[2021-04-10 04:00:57,119 INFO] Validation perplexity: 34.7875\n","[2021-04-10 04:00:57,119 INFO] Validation accuracy: 52.9521\n","[2021-04-10 04:00:57,346 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-10 04:01:56,693 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:02:01,264 INFO] number of examples: 77471\n","[2021-04-10 04:04:13,563 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:04:17,491 INFO] number of examples: 77471\n","[2021-04-10 04:06:29,808 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:06:34,498 INFO] number of examples: 77471\n","[2021-04-10 04:08:46,827 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:08:50,936 INFO] number of examples: 77471\n","[2021-04-10 04:11:03,257 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:11:07,327 INFO] number of examples: 77471\n","[2021-04-10 04:11:19,891 INFO] Step 20000/30000; acc:  98.52; ppl:  1.13; xent: 0.13; lr: 0.00062; 9505/11854 tok/s;  12613 sec\n","[2021-04-10 04:11:19,892 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:11:20,257 INFO] number of examples: 10362\n","[2021-04-10 04:11:37,338 INFO] Validation perplexity: 34.8408\n","[2021-04-10 04:11:37,339 INFO] Validation accuracy: 53.1413\n","[2021-04-10 04:11:37,553 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-10 04:13:42,054 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:13:45,929 INFO] number of examples: 77471\n","[2021-04-10 04:15:58,204 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:16:02,762 INFO] number of examples: 77471\n","[2021-04-10 04:18:14,980 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:18:18,960 INFO] number of examples: 77471\n","[2021-04-10 04:20:31,215 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:20:35,047 INFO] number of examples: 77471\n","[2021-04-10 04:21:54,106 INFO] Step 21000/30000; acc:  98.66; ppl:  1.13; xent: 0.12; lr: 0.00061; 9619/11995 tok/s;  13247 sec\n","[2021-04-10 04:21:54,107 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:21:54,469 INFO] number of examples: 10362\n","[2021-04-10 04:22:11,547 INFO] Validation perplexity: 34.8918\n","[2021-04-10 04:22:11,547 INFO] Validation accuracy: 53.1288\n","[2021-04-10 04:22:11,775 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-10 04:23:09,804 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:23:14,160 INFO] number of examples: 77471\n","[2021-04-10 04:25:26,414 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:25:30,973 INFO] number of examples: 77471\n","[2021-04-10 04:27:42,557 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:27:46,243 INFO] number of examples: 77471\n","[2021-04-10 04:29:57,355 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:30:00,973 INFO] number of examples: 77471\n","[2021-04-10 04:32:12,029 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:32:16,172 INFO] number of examples: 77471\n","[2021-04-10 04:32:29,693 INFO] Step 22000/30000; acc:  98.77; ppl:  1.12; xent: 0.11; lr: 0.00060; 9577/11944 tok/s;  13883 sec\n","[2021-04-10 04:32:29,694 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:32:30,031 INFO] number of examples: 10362\n","[2021-04-10 04:32:46,842 INFO] Validation perplexity: 34.0269\n","[2021-04-10 04:32:46,843 INFO] Validation accuracy: 53.5584\n","[2021-04-10 04:32:47,045 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-10 04:34:49,300 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:34:53,510 INFO] number of examples: 77471\n","[2021-04-10 04:37:04,390 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:37:08,028 INFO] number of examples: 77471\n","[2021-04-10 04:39:18,975 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:39:22,596 INFO] number of examples: 77471\n","[2021-04-10 04:41:33,591 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:41:37,725 INFO] number of examples: 77471\n","[2021-04-10 04:42:57,116 INFO] Step 23000/30000; acc:  98.87; ppl:  1.11; xent: 0.11; lr: 0.00058; 9724/12124 tok/s;  14510 sec\n","[2021-04-10 04:42:57,117 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:42:57,461 INFO] number of examples: 10362\n","[2021-04-10 04:43:14,262 INFO] Validation perplexity: 36.2169\n","[2021-04-10 04:43:14,262 INFO] Validation accuracy: 53.3199\n","[2021-04-10 04:43:14,460 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-10 04:44:10,551 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:44:14,766 INFO] number of examples: 77471\n","[2021-04-10 04:46:26,752 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:46:30,663 INFO] number of examples: 77471\n","[2021-04-10 04:48:43,014 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:48:47,594 INFO] number of examples: 77471\n","[2021-04-10 04:50:59,938 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:51:03,891 INFO] number of examples: 77471\n","[2021-04-10 04:53:16,186 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:53:20,211 INFO] number of examples: 77471\n","[2021-04-10 04:53:35,061 INFO] Step 24000/30000; acc:  98.96; ppl:  1.11; xent: 0.10; lr: 0.00057; 9539/11901 tok/s;  15148 sec\n","[2021-04-10 04:53:35,063 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 04:53:35,432 INFO] number of examples: 10362\n","[2021-04-10 04:53:52,551 INFO] Validation perplexity: 34.917\n","[2021-04-10 04:53:52,551 INFO] Validation accuracy: 53.5106\n","[2021-04-10 04:53:52,774 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-10 04:55:54,876 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:55:58,778 INFO] number of examples: 77471\n","[2021-04-10 04:58:10,375 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 04:58:14,596 INFO] number of examples: 77471\n","[2021-04-10 05:00:25,550 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:00:29,192 INFO] number of examples: 77471\n","[2021-04-10 05:02:40,125 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:02:43,742 INFO] number of examples: 77471\n","[2021-04-10 05:04:04,218 INFO] Step 25000/30000; acc:  99.02; ppl:  1.10; xent: 0.10; lr: 0.00056; 9696/12085 tok/s;  15777 sec\n","[2021-04-10 05:04:04,219 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:04:04,563 INFO] number of examples: 10362\n","[2021-04-10 05:04:21,381 INFO] Validation perplexity: 36.0361\n","[2021-04-10 05:04:21,381 INFO] Validation accuracy: 53.4044\n","[2021-04-10 05:04:21,571 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-10 05:05:16,754 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:05:21,094 INFO] number of examples: 77471\n","[2021-04-10 05:07:32,606 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:07:36,852 INFO] number of examples: 77471\n","[2021-04-10 05:09:48,003 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:09:51,757 INFO] number of examples: 77471\n","[2021-04-10 05:12:02,841 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:12:06,441 INFO] number of examples: 77471\n","[2021-04-10 05:14:17,553 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:14:21,636 INFO] number of examples: 77471\n","[2021-04-10 05:14:37,509 INFO] Step 26000/30000; acc:  99.09; ppl:  1.10; xent: 0.09; lr: 0.00055; 9612/11989 tok/s;  16411 sec\n","[2021-04-10 05:14:37,511 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:14:37,868 INFO] number of examples: 10362\n","[2021-04-10 05:14:54,723 INFO] Validation perplexity: 36.3752\n","[2021-04-10 05:14:54,724 INFO] Validation accuracy: 53.498\n","[2021-04-10 05:14:54,928 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-10 05:16:54,651 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:16:58,839 INFO] number of examples: 77471\n","[2021-04-10 05:19:10,108 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:19:13,834 INFO] number of examples: 77471\n","[2021-04-10 05:21:25,287 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:21:28,967 INFO] number of examples: 77471\n","[2021-04-10 05:23:40,429 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:23:44,597 INFO] number of examples: 77471\n","[2021-04-10 05:25:06,612 INFO] Step 27000/30000; acc:  99.13; ppl:  1.09; xent: 0.09; lr: 0.00054; 9698/12089 tok/s;  17040 sec\n","[2021-04-10 05:25:06,614 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:25:06,966 INFO] number of examples: 10362\n","[2021-04-10 05:25:23,846 INFO] Validation perplexity: 36.9242\n","[2021-04-10 05:25:23,846 INFO] Validation accuracy: 53.5121\n","[2021-04-10 05:25:24,052 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-10 05:26:19,092 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:26:23,337 INFO] number of examples: 77471\n","[2021-04-10 05:28:34,617 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:28:38,291 INFO] number of examples: 77471\n","[2021-04-10 05:30:49,596 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:30:53,937 INFO] number of examples: 77471\n","[2021-04-10 05:33:05,266 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:33:09,085 INFO] number of examples: 77471\n","[2021-04-10 05:35:20,485 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:35:24,288 INFO] number of examples: 77471\n","[2021-04-10 05:35:41,345 INFO] Step 28000/30000; acc:  99.18; ppl:  1.09; xent: 0.09; lr: 0.00053; 9589/11963 tok/s;  17675 sec\n","[2021-04-10 05:35:41,347 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:35:41,696 INFO] number of examples: 10362\n","[2021-04-10 05:35:58,577 INFO] Validation perplexity: 37.9497\n","[2021-04-10 05:35:58,577 INFO] Validation accuracy: 53.4569\n","[2021-04-10 05:35:58,777 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-10 05:37:57,695 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:38:01,361 INFO] number of examples: 77471\n","[2021-04-10 05:40:12,683 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:40:16,970 INFO] number of examples: 77471\n","[2021-04-10 05:42:28,243 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:42:31,941 INFO] number of examples: 77471\n","[2021-04-10 05:44:43,305 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:44:46,996 INFO] number of examples: 77471\n","[2021-04-10 05:46:10,076 INFO] Step 29000/30000; acc:  99.22; ppl:  1.09; xent: 0.08; lr: 0.00052; 9700/12088 tok/s;  18303 sec\n","[2021-04-10 05:46:10,078 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:46:10,434 INFO] number of examples: 10362\n","[2021-04-10 05:46:27,321 INFO] Validation perplexity: 36.9007\n","[2021-04-10 05:46:27,321 INFO] Validation accuracy: 53.5161\n","[2021-04-10 05:46:27,529 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-10 05:47:20,880 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:47:25,046 INFO] number of examples: 77471\n","[2021-04-10 05:49:36,319 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:49:40,579 INFO] number of examples: 77471\n","[2021-04-10 05:51:51,895 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:51:55,628 INFO] number of examples: 77471\n","[2021-04-10 05:54:06,972 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:54:10,635 INFO] number of examples: 77471\n","[2021-04-10 05:56:22,044 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 05:56:26,257 INFO] number of examples: 77471\n","[2021-04-10 05:56:44,554 INFO] Step 30000/30000; acc:  99.26; ppl:  1.08; xent: 0.08; lr: 0.00051; 9598/11975 tok/s;  18938 sec\n","[2021-04-10 05:56:44,555 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 05:56:44,917 INFO] number of examples: 10362\n","[2021-04-10 05:57:01,809 INFO] Validation perplexity: 37.7324\n","[2021-04-10 05:57:01,809 INFO] Validation accuracy: 53.5795\n","[2021-04-10 05:57:02,022 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618034227648,"user_tz":-420,"elapsed":19022874,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"4ad3995c-4349-45c8-88a3-e2dd1ade3d34"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 30009795\n","-rw------- 1 root root 1024334143 Apr 10 02:26 en-vi_step_10000.pt\n","-rw------- 1 root root 1024334143 Apr 10 00:51 en-vi_step_1000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:36 en-vi_step_11000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:47 en-vi_step_12000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:57 en-vi_step_13000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:08 en-vi_step_14000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:18 en-vi_step_15000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:29 en-vi_step_16000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:39 en-vi_step_17000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:50 en-vi_step_18000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:01 en-vi_step_19000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:11 en-vi_step_20000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:02 en-vi_step_2000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:22 en-vi_step_21000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:32 en-vi_step_22000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:43 en-vi_step_23000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:53 en-vi_step_24000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:04 en-vi_step_25000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:14 en-vi_step_26000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:25 en-vi_step_27000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:36 en-vi_step_28000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:46 en-vi_step_29000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:57 en-vi_step_30000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:12 en-vi_step_3000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:23 en-vi_step_4000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:33 en-vi_step_5000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:44 en-vi_step_6000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:54 en-vi_step_7000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:05 en-vi_step_8000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:15 en-vi_step_9000.pt\n","\n","model/:\n","total 30009795\n","-rw------- 1 root root 1024334143 Apr 10 02:26 en-vi_step_10000.pt\n","-rw------- 1 root root 1024334143 Apr 10 00:51 en-vi_step_1000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:36 en-vi_step_11000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:47 en-vi_step_12000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:57 en-vi_step_13000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:08 en-vi_step_14000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:18 en-vi_step_15000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:29 en-vi_step_16000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:39 en-vi_step_17000.pt\n","-rw------- 1 root root 1024334143 Apr 10 03:50 en-vi_step_18000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:01 en-vi_step_19000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:11 en-vi_step_20000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:02 en-vi_step_2000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:22 en-vi_step_21000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:32 en-vi_step_22000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:43 en-vi_step_23000.pt\n","-rw------- 1 root root 1024334143 Apr 10 04:53 en-vi_step_24000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:04 en-vi_step_25000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:14 en-vi_step_26000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:25 en-vi_step_27000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:36 en-vi_step_28000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:46 en-vi_step_29000.pt\n","-rw------- 1 root root 1024334143 Apr 10 05:57 en-vi_step_30000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:12 en-vi_step_3000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:23 en-vi_step_4000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:33 en-vi_step_5000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:44 en-vi_step_6000.pt\n","-rw------- 1 root root 1024334143 Apr 10 01:54 en-vi_step_7000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:05 en-vi_step_8000.pt\n","-rw------- 1 root root 1024334143 Apr 10 02:15 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618037123743,"user_tz":-420,"elapsed":21918967,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"b8af5824-c763-464c-83b7-d531f5781ea2"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-10 05:57:13,789 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 06:43:46,715 INFO] PRED AVG SCORE: -0.4429, PRED PPL: 1.5572\n","[2021-04-10 06:43:46,715 INFO] GOLD AVG SCORE: -3.6337, GOLD PPL: 37.8533\n","[2021-04-10 06:43:46,744 INFO] Translating shard 1.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 06:45:22,982 INFO] PRED AVG SCORE: -0.4493, PRED PPL: 1.5672\n","[2021-04-10 06:45:22,982 INFO] GOLD AVG SCORE: -3.6446, GOLD PPL: 38.2689\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618037123744,"user_tz":-420,"elapsed":21918967,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"25cb2ca1-7981-49e1-e441-ab36545486fe"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cà vạt thì loè loẹt .\n","và lí do là bởi vì có 2 lí do , theo tôi nghĩ\n","Ông thích nói về thiên tài tâm linh của lứa tuổi .\n","Chúng tôi đều là người Triều Tiên , nhưng đã trở nên rất khác nhau do hậu quả của 67 năm bị chia cắt .\n","Đó là cách bạn xử lý một vấn đề khi bạn nhìn thấy chúng và đó không chỉ là việc than phiền về vấn đề đó .\n","Tham vọng của các bạn được thoã mãn , nó rất đẹp .\n","Không có thứ nào trong những điều trên thực sự hữu ích bởi vì bạn đang điều trị những triệu chứng chứ không phải nguyên nhân của các vấn đề cơ bản ở Phi Châu .\n","Nhưng hiện nay nhiều người sống đến 90 hay 100 tuổi , trừ khi họ bắt tay quá nhiều hay làm những điều đại loại thế .\n","Nhưng quý vị phải có những công cụ đúng .\n","Những điều này là một phần cuộc đời ông và là những gì ông còn nhớ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618037145409,"user_tz":-420,"elapsed":21940630,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"270400d7-1008-4427-9e4c-23f7c621f024"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 29, done.\u001b[K\n","remote: Counting objects: 100% (29/29), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 17114 (delta 7), reused 8 (delta 4), pack-reused 17085\u001b[K\n","Receiving objects: 100% (17114/17114), 273.05 MiB | 19.54 MiB/s, done.\n","Resolving deltas: 100% (12323/12323), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618037145410,"user_tz":-420,"elapsed":21940629,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"208ba277-2bf0-4abd-9495-fde3c3de7af9"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 93598\n","drwx------  2 root root     4096 Apr 10 00:40 data_bin\n","-rw-------  1 root root   996149 Apr  9 11:16 en_test\n","-rw-------  1 root root  8024744 Apr  9 11:16 en_train\n","-rw-------  1 root root  8161362 Apr  9 11:42 en_train_EM_0.8\n","-rw-------  1 root root  8075706 Apr  9 11:42 en_train_EM_0.85\n","-rw-------  1 root root  8040373 Apr  9 11:42 en_train_EM_0.9\n","-rw-------  1 root root  8026272 Apr  9 11:42 en_train_EM_0.95\n","-rw-------  1 root root  3303720 Apr  9 11:42 en_train_EM_factor_0.8\n","-rw-------  1 root root  3268996 Apr  9 11:42 en_train_EM_factor_0.85\n","-rw-------  1 root root  3254332 Apr  9 11:42 en_train_EM_factor_0.9\n","-rw-------  1 root root  3248468 Apr  9 11:42 en_train_EM_factor_0.95\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.8\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.85\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.9\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.95\n","-rw-------  1 root root  1000856 Apr  9 11:16 en_valid\n","-rw-------  1 root root 22435544 Apr 10 00:40 en_vi_iwslt_bert.tar.gz\n","drwx------  2 root root     4096 Apr 10 05:57 model\n","drwx------ 11 root root     4096 Apr 10 06:45 OpenNMT-py\n","drwx------  2 root root     4096 Apr 10 00:40 output\n","-rw-------  1 root root  1216970 Apr 10 06:45 predict.txt\n","-rw-------  1 root root  1327417 Apr  9 11:16 vi_test\n","-rw-------  1 root root 10671354 Apr  9 11:16 vi_train\n","-rw-------  1 root root  1330789 Apr  9 11:16 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618037147776,"user_tz":-420,"elapsed":21942995,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"618ccc69-0505-4ffd-bcfd-9aec6f823056"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 23.85, 58.8/33.0/19.5/11.7 (BP=0.925, ratio=0.927, hyp_len=226478, ref_len=244219)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1618037147778,"user_tz":-420,"elapsed":21942994,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}