{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TED-OpenNMT-sent2vec-0.95-20210410-0746 BLEU 23.70.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040802577,"user_tz":-420,"elapsed":17962,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"42606392-5f3b-494f-a3eb-a36c0dd2ea9a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040803392,"user_tz":-420,"elapsed":18770,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"1532fa19-1cca-460b-cbae-0f84d333e860"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"TED-OpenNMT-sent2vec-0.95-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v3/OpenNMT-TED-EM-sent2vec-ratio-8-2-2-20210128-0637'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/TED-OpenNMT-sent2vec-0.95-20210410-0746\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040803393,"user_tz":-420,"elapsed":18768,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"6f7f69b8-b7f5-4a4e-99d9-1a06a19df03b"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Sat Apr 10 07:46:43 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040817886,"user_tz":-420,"elapsed":33257,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"296c0d2c-4b11-4ad2-d7b6-2fa4fa25c93f"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\r\u001b[K     |█▊                              | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 12.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 7.6MB/s \n","\u001b[?25hCollecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Collecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 12.1MB/s \n","\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=2b501d8cfb1d3fc7a207247d2bc3a0bc78f147bb65e3c2c0c26db1ca1794edc3\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: waitress, torchtext, configargparse, pyonmttok, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040819270,"user_tz":-420,"elapsed":34638,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"92c0824e-8189-43a8-95e9-3e0054879b8b"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_sent2vec.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'en_vi_iwslt_sent2vec.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-10 07:46:57--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_sent2vec.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22512408 (21M) [application/octet-stream]\n","Saving to: ‘en_vi_iwslt_sent2vec.tar.gz’\n","\n","en_vi_iwslt_sent2ve 100%[===================>]  21.47M  70.8MB/s    in 0.3s    \n","\n","2021-04-10 07:46:57 (70.8 MB/s) - ‘en_vi_iwslt_sent2vec.tar.gz’ saved [22512408/22512408]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040830864,"user_tz":-420,"elapsed":46229,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"87eaf2d9-2914-4436-dabd-5d1c4351f128"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.95' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-10 07:47:02,107 INFO] Extracting features...\n","[2021-04-10 07:47:02,109 INFO]  * number of source features: 0.\n","[2021-04-10 07:47:02,110 INFO]  * number of target features: 0.\n","[2021-04-10 07:47:02,110 INFO] Building `Fields` object...\n","[2021-04-10 07:47:02,110 INFO] Building & saving training data...\n","[2021-04-10 07:47:02,321 INFO] Building shard 0.\n","[2021-04-10 07:47:05,722 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-10 07:47:08,808 INFO]  * tgt vocab size: 18250.\n","[2021-04-10 07:47:08,858 INFO]  * src vocab size: 39851.\n","[2021-04-10 07:47:09,027 INFO] Building & saving validation data...\n","[2021-04-10 07:47:09,128 INFO] Building shard 0.\n","[2021-04-10 07:47:09,358 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618059246602,"user_tz":-420,"elapsed":18461965,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"febae287-4f5c-448c-b0b4-1deed2426a3d"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-10 07:47:11,882 INFO]  * src vocab size = 39851\n","[2021-04-10 07:47:11,882 INFO]  * tgt vocab size = 18250\n","[2021-04-10 07:47:11,883 INFO] Building model...\n","[2021-04-10 07:47:19,104 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(39851, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(18250, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=18250, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-10 07:47:19,166 INFO] encoder: 39319040\n","[2021-04-10 07:47:19,166 INFO] decoder: 43931466\n","[2021-04-10 07:47:19,166 INFO] * number of parameters: 83250506\n","[2021-04-10 07:47:19,170 INFO] Starting training on GPU: [0]\n","[2021-04-10 07:47:19,170 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-10 07:47:19,170 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:47:21,743 INFO] number of examples: 77471\n","[2021-04-10 07:49:28,388 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:49:31,511 INFO] number of examples: 77471\n","[2021-04-10 07:51:38,119 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:51:40,855 INFO] number of examples: 77471\n","[2021-04-10 07:53:47,472 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:53:50,600 INFO] number of examples: 77471\n","[2021-04-10 07:55:57,233 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:56:00,432 INFO] number of examples: 77471\n","[2021-04-10 07:57:09,890 INFO] Step 1000/30000; acc:  13.70; ppl: 253.72; xent: 5.54; lr: 0.00012; 10342/12984 tok/s;    591 sec\n","[2021-04-10 07:57:09,891 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 07:57:10,177 INFO] number of examples: 10362\n","[2021-04-10 07:57:26,819 INFO] Validation perplexity: 101.497\n","[2021-04-10 07:57:26,819 INFO] Validation accuracy: 26.6133\n","[2021-04-10 07:57:26,997 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-10 07:58:28,713 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:58:32,148 INFO] number of examples: 77471\n","[2021-04-10 08:00:38,807 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:00:41,765 INFO] number of examples: 77471\n","[2021-04-10 08:02:48,556 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:02:51,961 INFO] number of examples: 77471\n","[2021-04-10 08:04:58,670 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:05:02,249 INFO] number of examples: 77471\n","[2021-04-10 08:07:08,964 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:07:12,186 INFO] number of examples: 77471\n","[2021-04-10 08:07:24,354 INFO] Step 2000/30000; acc:  40.54; ppl: 20.93; xent: 3.04; lr: 0.00025; 9941/12480 tok/s;   1205 sec\n","[2021-04-10 08:07:24,355 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:07:24,656 INFO] number of examples: 10362\n","[2021-04-10 08:07:41,322 INFO] Validation perplexity: 20.8024\n","[2021-04-10 08:07:41,322 INFO] Validation accuracy: 46.8356\n","[2021-04-10 08:07:41,492 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-10 08:09:40,818 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:09:44,054 INFO] number of examples: 77471\n","[2021-04-10 08:11:50,855 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:11:53,859 INFO] number of examples: 77471\n","[2021-04-10 08:14:00,560 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:14:04,053 INFO] number of examples: 77471\n","[2021-04-10 08:16:10,722 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:16:13,766 INFO] number of examples: 77471\n","[2021-04-10 08:17:34,674 INFO] Step 3000/30000; acc:  57.06; ppl:  6.82; xent: 1.92; lr: 0.00037; 10004/12560 tok/s;   1816 sec\n","[2021-04-10 08:17:34,675 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:17:35,417 INFO] number of examples: 10362\n","[2021-04-10 08:17:52,089 INFO] Validation perplexity: 15.3663\n","[2021-04-10 08:17:52,089 INFO] Validation accuracy: 51.3959\n","[2021-04-10 08:17:52,266 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-10 08:18:42,803 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:18:46,394 INFO] number of examples: 77471\n","[2021-04-10 08:20:53,084 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:20:56,269 INFO] number of examples: 77471\n","[2021-04-10 08:23:02,984 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:23:06,136 INFO] number of examples: 77471\n","[2021-04-10 08:25:12,866 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:25:15,984 INFO] number of examples: 77471\n","[2021-04-10 08:27:22,715 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:27:26,416 INFO] number of examples: 77471\n","[2021-04-10 08:27:50,010 INFO] Step 4000/30000; acc:  65.48; ppl:  4.15; xent: 1.42; lr: 0.00049; 9934/12470 tok/s;   2431 sec\n","[2021-04-10 08:27:50,011 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:27:50,323 INFO] number of examples: 10362\n","[2021-04-10 08:28:06,993 INFO] Validation perplexity: 15.9675\n","[2021-04-10 08:28:06,993 INFO] Validation accuracy: 51.7648\n","[2021-04-10 08:28:07,164 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-10 08:29:54,930 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:29:58,070 INFO] number of examples: 77471\n","[2021-04-10 08:32:04,804 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:32:07,855 INFO] number of examples: 77471\n","[2021-04-10 08:34:14,573 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:34:18,162 INFO] number of examples: 77471\n","[2021-04-10 08:36:24,899 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:36:27,979 INFO] number of examples: 77471\n","[2021-04-10 08:38:00,209 INFO] Step 5000/30000; acc:  71.74; ppl:  3.04; xent: 1.11; lr: 0.00062; 9998/12557 tok/s;   3041 sec\n","[2021-04-10 08:38:00,210 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:38:01,086 INFO] number of examples: 10362\n","[2021-04-10 08:38:17,741 INFO] Validation perplexity: 19.2437\n","[2021-04-10 08:38:17,741 INFO] Validation accuracy: 51.0638\n","[2021-04-10 08:38:17,911 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-10 08:38:57,399 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:39:00,733 INFO] number of examples: 77471\n","[2021-04-10 08:41:07,317 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:41:10,787 INFO] number of examples: 77471\n","[2021-04-10 08:43:17,351 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:43:20,376 INFO] number of examples: 77471\n","[2021-04-10 08:45:26,958 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:45:30,406 INFO] number of examples: 77471\n","[2021-04-10 08:47:37,010 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:47:40,622 INFO] number of examples: 77471\n","[2021-04-10 08:48:15,705 INFO] Step 6000/30000; acc:  76.86; ppl:  2.43; xent: 0.89; lr: 0.00074; 9934/12470 tok/s;   3657 sec\n","[2021-04-10 08:48:15,706 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:48:16,008 INFO] number of examples: 10362\n","[2021-04-10 08:48:32,658 INFO] Validation perplexity: 20.691\n","[2021-04-10 08:48:32,658 INFO] Validation accuracy: 51.7221\n","[2021-04-10 08:48:32,833 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-10 08:50:09,589 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:50:12,687 INFO] number of examples: 77471\n","[2021-04-10 08:52:19,283 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:52:22,879 INFO] number of examples: 77471\n","[2021-04-10 08:54:29,430 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:54:32,602 INFO] number of examples: 77471\n","[2021-04-10 08:56:39,203 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:56:42,287 INFO] number of examples: 77471\n","[2021-04-10 08:58:25,954 INFO] Step 7000/30000; acc:  81.21; ppl:  2.05; xent: 0.72; lr: 0.00086; 9998/12555 tok/s;   4267 sec\n","[2021-04-10 08:58:25,955 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:58:26,252 INFO] number of examples: 10362\n","[2021-04-10 08:58:42,902 INFO] Validation perplexity: 23.7606\n","[2021-04-10 08:58:42,903 INFO] Validation accuracy: 51.428\n","[2021-04-10 08:58:43,074 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-10 08:59:10,669 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:59:14,133 INFO] number of examples: 77471\n","[2021-04-10 09:01:20,718 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:01:24,331 INFO] number of examples: 77471\n","[2021-04-10 09:03:30,959 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:03:34,128 INFO] number of examples: 77471\n","[2021-04-10 09:05:40,744 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:05:43,864 INFO] number of examples: 77471\n","[2021-04-10 09:07:50,484 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:07:53,552 INFO] number of examples: 77471\n","[2021-04-10 09:08:40,156 INFO] Step 8000/30000; acc:  84.33; ppl:  1.83; xent: 0.61; lr: 0.00099; 9961/12496 tok/s;   4881 sec\n","[2021-04-10 09:08:40,157 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:08:41,016 INFO] number of examples: 10362\n","[2021-04-10 09:08:57,666 INFO] Validation perplexity: 25.8535\n","[2021-04-10 09:08:57,666 INFO] Validation accuracy: 51.0873\n","[2021-04-10 09:08:57,837 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-10 09:10:22,475 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:10:26,607 INFO] number of examples: 77471\n","[2021-04-10 09:12:33,235 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:12:36,426 INFO] number of examples: 77471\n","[2021-04-10 09:14:43,021 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:14:46,168 INFO] number of examples: 77471\n","[2021-04-10 09:16:52,766 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:16:55,870 INFO] number of examples: 77471\n","[2021-04-10 09:18:51,009 INFO] Step 9000/30000; acc:  87.52; ppl:  1.65; xent: 0.50; lr: 0.00093; 9986/12541 tok/s;   5492 sec\n","[2021-04-10 09:18:51,010 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:18:51,333 INFO] number of examples: 10362\n","[2021-04-10 09:19:07,981 INFO] Validation perplexity: 27.7591\n","[2021-04-10 09:19:07,981 INFO] Validation accuracy: 51.7311\n","[2021-04-10 09:19:08,158 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-10 09:19:24,237 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:19:28,405 INFO] number of examples: 77471\n","[2021-04-10 09:21:35,199 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:21:38,922 INFO] number of examples: 77471\n","[2021-04-10 09:23:45,535 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:23:48,766 INFO] number of examples: 77471\n","[2021-04-10 09:25:55,381 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:25:58,577 INFO] number of examples: 77471\n","[2021-04-10 09:28:05,179 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:28:08,393 INFO] number of examples: 77471\n","[2021-04-10 09:29:06,434 INFO] Step 10000/30000; acc:  91.10; ppl:  1.47; xent: 0.39; lr: 0.00088; 9938/12471 tok/s;   6107 sec\n","[2021-04-10 09:29:06,435 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:29:06,739 INFO] number of examples: 10362\n","[2021-04-10 09:29:23,388 INFO] Validation perplexity: 28.4629\n","[2021-04-10 09:29:23,388 INFO] Validation accuracy: 52.1376\n","[2021-04-10 09:29:23,558 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-10 09:30:36,714 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:30:40,391 INFO] number of examples: 77471\n","[2021-04-10 09:32:46,998 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:32:50,197 INFO] number of examples: 77471\n","[2021-04-10 09:34:56,789 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:34:59,932 INFO] number of examples: 77471\n","[2021-04-10 09:37:06,586 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:37:09,678 INFO] number of examples: 77471\n","[2021-04-10 09:39:16,287 INFO] Step 11000/30000; acc:  93.40; ppl:  1.37; xent: 0.32; lr: 0.00084; 10007/12562 tok/s;   6717 sec\n","[2021-04-10 09:39:16,288 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:39:16,592 INFO] number of examples: 10362\n","[2021-04-10 09:39:33,235 INFO] Validation perplexity: 28.4917\n","[2021-04-10 09:39:33,235 INFO] Validation accuracy: 52.5789\n","[2021-04-10 09:39:33,415 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-10 09:39:38,125 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:39:41,653 INFO] number of examples: 77471\n","[2021-04-10 09:41:48,566 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:41:51,585 INFO] number of examples: 77471\n","[2021-04-10 09:43:58,195 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:44:01,681 INFO] number of examples: 77471\n","[2021-04-10 09:46:08,269 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:46:11,890 INFO] number of examples: 77471\n","[2021-04-10 09:48:18,525 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:48:21,700 INFO] number of examples: 77471\n","[2021-04-10 09:49:31,157 INFO] Step 12000/30000; acc:  94.81; ppl:  1.31; xent: 0.27; lr: 0.00081; 9936/12474 tok/s;   7332 sec\n","[2021-04-10 09:49:31,158 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:49:31,457 INFO] number of examples: 10362\n","[2021-04-10 09:49:48,100 INFO] Validation perplexity: 30.2253\n","[2021-04-10 09:49:48,101 INFO] Validation accuracy: 52.9455\n","[2021-04-10 09:49:48,270 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-10 09:50:50,313 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:50:53,990 INFO] number of examples: 77471\n","[2021-04-10 09:53:00,591 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:53:03,823 INFO] number of examples: 77471\n","[2021-04-10 09:55:10,405 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:55:13,622 INFO] number of examples: 77471\n","[2021-04-10 09:57:20,214 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:57:23,383 INFO] number of examples: 77471\n","[2021-04-10 09:59:29,966 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:59:33,069 INFO] number of examples: 77471\n","[2021-04-10 09:59:45,205 INFO] Step 13000/30000; acc:  95.89; ppl:  1.26; xent: 0.23; lr: 0.00078; 9947/12488 tok/s;   7946 sec\n","[2021-04-10 09:59:45,206 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:59:45,503 INFO] number of examples: 10362\n","[2021-04-10 10:00:02,149 INFO] Validation perplexity: 31.7428\n","[2021-04-10 10:00:02,149 INFO] Validation accuracy: 52.7086\n","[2021-04-10 10:00:02,321 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-10 10:02:01,450 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:02:05,009 INFO] number of examples: 77471\n","[2021-04-10 10:04:11,609 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:04:14,689 INFO] number of examples: 77471\n","[2021-04-10 10:06:21,303 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:06:24,899 INFO] number of examples: 77471\n","[2021-04-10 10:08:31,488 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:08:34,652 INFO] number of examples: 77471\n","[2021-04-10 10:09:55,527 INFO] Step 14000/30000; acc:  96.60; ppl:  1.23; xent: 0.21; lr: 0.00075; 10004/12560 tok/s;   8556 sec\n","[2021-04-10 10:09:55,528 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:09:55,836 INFO] number of examples: 10362\n","[2021-04-10 10:10:12,484 INFO] Validation perplexity: 31.2251\n","[2021-04-10 10:10:12,485 INFO] Validation accuracy: 53.0614\n","[2021-04-10 10:10:12,656 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-10 10:11:03,118 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:11:06,761 INFO] number of examples: 77471\n","[2021-04-10 10:13:13,373 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:13:16,562 INFO] number of examples: 77471\n","[2021-04-10 10:15:23,185 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:15:26,330 INFO] number of examples: 77471\n","[2021-04-10 10:17:32,942 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:17:36,028 INFO] number of examples: 77471\n","[2021-04-10 10:19:42,665 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:19:46,265 INFO] number of examples: 77471\n","[2021-04-10 10:20:09,841 INFO] Step 15000/30000; acc:  97.16; ppl:  1.21; xent: 0.19; lr: 0.00072; 9951/12490 tok/s;   9171 sec\n","[2021-04-10 10:20:09,842 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:20:10,147 INFO] number of examples: 10362\n","[2021-04-10 10:20:26,791 INFO] Validation perplexity: 31.5875\n","[2021-04-10 10:20:26,791 INFO] Validation accuracy: 53.1926\n","[2021-04-10 10:20:26,971 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-10 10:22:14,584 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:22:17,683 INFO] number of examples: 77471\n","[2021-04-10 10:24:24,322 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:24:27,904 INFO] number of examples: 77471\n","[2021-04-10 10:26:34,490 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:26:37,649 INFO] number of examples: 77471\n","[2021-04-10 10:28:44,215 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:28:47,240 INFO] number of examples: 77471\n","[2021-04-10 10:30:19,435 INFO] Step 16000/30000; acc:  97.58; ppl:  1.18; xent: 0.17; lr: 0.00070; 10008/12570 tok/s;   9780 sec\n","[2021-04-10 10:30:19,436 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:30:20,297 INFO] number of examples: 10362\n","[2021-04-10 10:30:36,942 INFO] Validation perplexity: 31.9696\n","[2021-04-10 10:30:36,943 INFO] Validation accuracy: 53.1996\n","[2021-04-10 10:30:37,111 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-10 10:31:16,251 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:31:20,391 INFO] number of examples: 77471\n","[2021-04-10 10:33:27,046 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:33:30,231 INFO] number of examples: 77471\n","[2021-04-10 10:35:36,844 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:35:39,985 INFO] number of examples: 77471\n","[2021-04-10 10:37:46,613 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:37:49,705 INFO] number of examples: 77471\n","[2021-04-10 10:39:56,325 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:39:59,978 INFO] number of examples: 77471\n","[2021-04-10 10:40:35,130 INFO] Step 17000/30000; acc:  97.90; ppl:  1.17; xent: 0.16; lr: 0.00068; 9931/12466 tok/s;  10396 sec\n","[2021-04-10 10:40:35,131 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:40:35,435 INFO] number of examples: 10362\n","[2021-04-10 10:40:52,112 INFO] Validation perplexity: 32.8498\n","[2021-04-10 10:40:52,112 INFO] Validation accuracy: 53.2721\n","[2021-04-10 10:40:52,289 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-10 10:42:28,997 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:42:32,099 INFO] number of examples: 77471\n","[2021-04-10 10:44:38,899 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:44:42,465 INFO] number of examples: 77471\n","[2021-04-10 10:46:49,229 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:46:52,298 INFO] number of examples: 77471\n","[2021-04-10 10:48:59,159 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:49:02,743 INFO] number of examples: 77471\n","[2021-04-10 10:50:46,780 INFO] Step 18000/30000; acc:  98.16; ppl:  1.16; xent: 0.14; lr: 0.00066; 9975/12527 tok/s;  11008 sec\n","[2021-04-10 10:50:46,781 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:50:47,083 INFO] number of examples: 10362\n","[2021-04-10 10:51:03,790 INFO] Validation perplexity: 31.9122\n","[2021-04-10 10:51:03,790 INFO] Validation accuracy: 53.5458\n","[2021-04-10 10:51:03,966 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-10 10:51:31,728 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:51:35,504 INFO] number of examples: 77471\n","[2021-04-10 10:53:42,421 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:53:45,574 INFO] number of examples: 77471\n","[2021-04-10 10:55:52,281 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:55:55,363 INFO] number of examples: 77471\n","[2021-04-10 10:58:02,044 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:58:05,594 INFO] number of examples: 77471\n","[2021-04-10 11:00:12,308 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:00:15,400 INFO] number of examples: 77471\n","[2021-04-10 11:01:02,054 INFO] Step 19000/30000; acc:  98.34; ppl:  1.14; xent: 0.13; lr: 0.00064; 9944/12474 tok/s;  11623 sec\n","[2021-04-10 11:01:02,055 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:01:02,933 INFO] number of examples: 10362\n","[2021-04-10 11:01:19,585 INFO] Validation perplexity: 33.0753\n","[2021-04-10 11:01:19,586 INFO] Validation accuracy: 53.4671\n","[2021-04-10 11:01:19,755 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-10 11:02:44,602 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:02:48,000 INFO] number of examples: 77471\n","[2021-04-10 11:04:54,717 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:04:58,259 INFO] number of examples: 77471\n","[2021-04-10 11:07:04,976 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:07:08,048 INFO] number of examples: 77471\n","[2021-04-10 11:09:14,975 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:09:18,472 INFO] number of examples: 77471\n","[2021-04-10 11:11:13,911 INFO] Step 20000/30000; acc:  98.52; ppl:  1.13; xent: 0.13; lr: 0.00062; 9969/12520 tok/s;  12235 sec\n","[2021-04-10 11:11:13,912 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:11:14,216 INFO] number of examples: 10362\n","[2021-04-10 11:11:30,967 INFO] Validation perplexity: 33.385\n","[2021-04-10 11:11:30,967 INFO] Validation accuracy: 53.6449\n","[2021-04-10 11:11:31,149 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-10 11:11:47,317 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:11:51,546 INFO] number of examples: 77471\n","[2021-04-10 11:13:58,419 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:14:01,542 INFO] number of examples: 77471\n","[2021-04-10 11:16:08,213 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:16:11,886 INFO] number of examples: 77471\n","[2021-04-10 11:18:18,782 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:18:22,090 INFO] number of examples: 77471\n","[2021-04-10 11:20:28,842 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:20:31,996 INFO] number of examples: 77471\n","[2021-04-10 11:21:30,069 INFO] Step 21000/30000; acc:  98.65; ppl:  1.13; xent: 0.12; lr: 0.00061; 9926/12457 tok/s;  12851 sec\n","[2021-04-10 11:21:30,070 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:21:30,370 INFO] number of examples: 10362\n","[2021-04-10 11:21:47,021 INFO] Validation perplexity: 34.2029\n","[2021-04-10 11:21:47,021 INFO] Validation accuracy: 53.3876\n","[2021-04-10 11:21:47,200 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-10 11:23:00,514 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:23:04,104 INFO] number of examples: 77471\n","[2021-04-10 11:25:10,981 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:25:14,112 INFO] number of examples: 77471\n","[2021-04-10 11:27:21,025 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:27:24,757 INFO] number of examples: 77471\n","[2021-04-10 11:29:31,765 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:29:35,083 INFO] number of examples: 77471\n","[2021-04-10 11:31:42,078 INFO] Step 22000/30000; acc:  98.77; ppl:  1.12; xent: 0.11; lr: 0.00060; 9971/12517 tok/s;  13463 sec\n","[2021-04-10 11:31:42,079 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:31:42,378 INFO] number of examples: 10362\n","[2021-04-10 11:31:59,100 INFO] Validation perplexity: 35.2636\n","[2021-04-10 11:31:59,100 INFO] Validation accuracy: 53.4213\n","[2021-04-10 11:31:59,281 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-10 11:32:04,286 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:32:07,559 INFO] number of examples: 77471\n","[2021-04-10 11:34:14,710 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:34:17,801 INFO] number of examples: 77471\n","[2021-04-10 11:36:24,670 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:36:28,218 INFO] number of examples: 77471\n","[2021-04-10 11:38:35,127 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:38:38,251 INFO] number of examples: 77471\n","[2021-04-10 11:40:45,354 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:40:48,851 INFO] number of examples: 77471\n","[2021-04-10 11:41:58,318 INFO] Step 23000/30000; acc:  98.86; ppl:  1.11; xent: 0.11; lr: 0.00058; 9914/12446 tok/s;  14079 sec\n","[2021-04-10 11:41:58,318 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:41:58,624 INFO] number of examples: 10362\n","[2021-04-10 11:42:15,270 INFO] Validation perplexity: 34.6156\n","[2021-04-10 11:42:15,270 INFO] Validation accuracy: 53.6637\n","[2021-04-10 11:42:15,439 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-10 11:43:17,391 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:43:20,932 INFO] number of examples: 77471\n","[2021-04-10 11:45:27,803 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:45:31,474 INFO] number of examples: 77471\n","[2021-04-10 11:47:38,338 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:47:41,522 INFO] number of examples: 77471\n","[2021-04-10 11:49:48,379 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:49:51,491 INFO] number of examples: 77471\n","[2021-04-10 11:51:58,383 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:52:01,492 INFO] number of examples: 77471\n","[2021-04-10 11:52:13,705 INFO] Step 24000/30000; acc:  98.94; ppl:  1.11; xent: 0.10; lr: 0.00057; 9926/12461 tok/s;  14695 sec\n","[2021-04-10 11:52:13,706 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:52:14,634 INFO] number of examples: 10362\n","[2021-04-10 11:52:31,395 INFO] Validation perplexity: 34.5834\n","[2021-04-10 11:52:31,396 INFO] Validation accuracy: 53.8231\n","[2021-04-10 11:52:31,572 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-10 11:54:31,310 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:54:35,605 INFO] number of examples: 77471\n","[2021-04-10 11:56:42,489 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:56:45,777 INFO] number of examples: 77471\n","[2021-04-10 11:58:52,643 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:58:55,858 INFO] number of examples: 77471\n","[2021-04-10 12:01:02,695 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:01:05,907 INFO] number of examples: 77471\n","[2021-04-10 12:02:27,053 INFO] Step 25000/30000; acc:  99.02; ppl:  1.10; xent: 0.10; lr: 0.00056; 9955/12498 tok/s;  15308 sec\n","[2021-04-10 12:02:27,055 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:02:27,383 INFO] number of examples: 10362\n","[2021-04-10 12:02:44,112 INFO] Validation perplexity: 36.101\n","[2021-04-10 12:02:44,112 INFO] Validation accuracy: 53.6547\n","[2021-04-10 12:02:44,292 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-10 12:03:35,064 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:03:38,755 INFO] number of examples: 77471\n","[2021-04-10 12:05:45,769 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:05:48,986 INFO] number of examples: 77471\n","[2021-04-10 12:07:56,017 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:07:59,164 INFO] number of examples: 77471\n","[2021-04-10 12:10:06,194 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:10:09,938 INFO] number of examples: 77471\n","[2021-04-10 12:12:17,097 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:12:20,375 INFO] number of examples: 77471\n","[2021-04-10 12:12:44,045 INFO] Step 26000/30000; acc:  99.08; ppl:  1.10; xent: 0.09; lr: 0.00055; 9908/12436 tok/s;  15925 sec\n","[2021-04-10 12:12:44,047 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:12:44,353 INFO] number of examples: 10362\n","[2021-04-10 12:13:01,083 INFO] Validation perplexity: 36.9165\n","[2021-04-10 12:13:01,083 INFO] Validation accuracy: 53.2466\n","[2021-04-10 12:13:01,257 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-10 12:14:49,315 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:14:52,398 INFO] number of examples: 77471\n","[2021-04-10 12:16:59,417 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:17:02,969 INFO] number of examples: 77471\n","[2021-04-10 12:19:09,969 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:19:13,673 INFO] number of examples: 77471\n","[2021-04-10 12:21:20,689 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:21:23,953 INFO] number of examples: 77471\n","[2021-04-10 12:22:56,419 INFO] Step 27000/30000; acc:  99.13; ppl:  1.09; xent: 0.09; lr: 0.00054; 9963/12513 tok/s;  16537 sec\n","[2021-04-10 12:22:56,420 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:22:56,725 INFO] number of examples: 10362\n","[2021-04-10 12:23:13,449 INFO] Validation perplexity: 34.9745\n","[2021-04-10 12:23:13,449 INFO] Validation accuracy: 53.5834\n","[2021-04-10 12:23:13,624 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-10 12:23:53,278 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:23:56,383 INFO] number of examples: 77471\n","[2021-04-10 12:26:03,312 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:26:06,815 INFO] number of examples: 77471\n","[2021-04-10 12:28:13,623 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:28:17,414 INFO] number of examples: 77471\n","[2021-04-10 12:30:24,474 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:30:27,690 INFO] number of examples: 77471\n","[2021-04-10 12:32:34,694 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:32:37,858 INFO] number of examples: 77471\n","[2021-04-10 12:33:13,073 INFO] Step 28000/30000; acc:  99.18; ppl:  1.09; xent: 0.09; lr: 0.00053; 9915/12447 tok/s;  17154 sec\n","[2021-04-10 12:33:13,074 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:33:13,374 INFO] number of examples: 10362\n","[2021-04-10 12:33:30,101 INFO] Validation perplexity: 35.8379\n","[2021-04-10 12:33:30,101 INFO] Validation accuracy: 53.8051\n","[2021-04-10 12:33:30,275 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-10 12:35:07,482 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:35:11,063 INFO] number of examples: 77471\n","[2021-04-10 12:37:18,073 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:37:21,794 INFO] number of examples: 77471\n","[2021-04-10 12:39:28,834 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:39:32,073 INFO] number of examples: 77471\n","[2021-04-10 12:41:39,068 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:41:42,254 INFO] number of examples: 77471\n","[2021-04-10 12:43:26,263 INFO] Step 29000/30000; acc:  99.22; ppl:  1.09; xent: 0.08; lr: 0.00052; 9950/12495 tok/s;  17767 sec\n","[2021-04-10 12:43:26,264 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:43:26,565 INFO] number of examples: 10362\n","[2021-04-10 12:43:43,293 INFO] Validation perplexity: 37.5291\n","[2021-04-10 12:43:43,293 INFO] Validation accuracy: 53.6586\n","[2021-04-10 12:43:43,467 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-10 12:44:11,188 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:44:14,804 INFO] number of examples: 77471\n","[2021-04-10 12:46:21,783 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:46:24,937 INFO] number of examples: 77471\n","[2021-04-10 12:48:31,943 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:48:35,555 INFO] number of examples: 77471\n","[2021-04-10 12:50:42,525 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:50:45,630 INFO] number of examples: 77471\n","[2021-04-10 12:52:52,647 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:52:56,252 INFO] number of examples: 77471\n","[2021-04-10 12:53:43,048 INFO] Step 30000/30000; acc:  99.26; ppl:  1.08; xent: 0.08; lr: 0.00051; 9919/12443 tok/s;  18384 sec\n","[2021-04-10 12:53:43,049 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:53:43,351 INFO] number of examples: 10362\n","[2021-04-10 12:54:00,079 INFO] Validation perplexity: 37.4547\n","[2021-04-10 12:54:00,080 INFO] Validation accuracy: 53.7722\n","[2021-04-10 12:54:00,252 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618059246603,"user_tz":-420,"elapsed":18461963,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"5431052a-6337-47dc-bb5f-cb54a0c39c16"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 29932530\n","-rw------- 1 root root 1021696959 Apr 10 09:29 en-vi_step_10000.pt\n","-rw------- 1 root root 1021696959 Apr 10 07:57 en-vi_step_1000.pt\n","-rw------- 1 root root 1021696959 Apr 10 09:39 en-vi_step_11000.pt\n","-rw------- 1 root root 1021696959 Apr 10 09:49 en-vi_step_12000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:00 en-vi_step_13000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:10 en-vi_step_14000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:20 en-vi_step_15000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:30 en-vi_step_16000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:40 en-vi_step_17000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:51 en-vi_step_18000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:01 en-vi_step_19000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:11 en-vi_step_20000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:07 en-vi_step_2000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:21 en-vi_step_21000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:32 en-vi_step_22000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:42 en-vi_step_23000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:52 en-vi_step_24000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:02 en-vi_step_25000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:13 en-vi_step_26000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:23 en-vi_step_27000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:33 en-vi_step_28000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:43 en-vi_step_29000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:54 en-vi_step_30000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:17 en-vi_step_3000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:28 en-vi_step_4000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:38 en-vi_step_5000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:48 en-vi_step_6000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:58 en-vi_step_7000.pt\n","-rw------- 1 root root 1021696959 Apr 10 09:09 en-vi_step_8000.pt\n","-rw------- 1 root root 1021696959 Apr 10 09:19 en-vi_step_9000.pt\n","\n","model/:\n","total 29932530\n","-rw------- 1 root root 1021696959 Apr 10 09:29 en-vi_step_10000.pt\n","-rw------- 1 root root 1021696959 Apr 10 07:57 en-vi_step_1000.pt\n","-rw------- 1 root root 1021696959 Apr 10 09:39 en-vi_step_11000.pt\n","-rw------- 1 root root 1021696959 Apr 10 09:49 en-vi_step_12000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:00 en-vi_step_13000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:10 en-vi_step_14000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:20 en-vi_step_15000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:30 en-vi_step_16000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:40 en-vi_step_17000.pt\n","-rw------- 1 root root 1021696959 Apr 10 10:51 en-vi_step_18000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:01 en-vi_step_19000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:11 en-vi_step_20000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:07 en-vi_step_2000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:21 en-vi_step_21000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:32 en-vi_step_22000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:42 en-vi_step_23000.pt\n","-rw------- 1 root root 1021696959 Apr 10 11:52 en-vi_step_24000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:02 en-vi_step_25000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:13 en-vi_step_26000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:23 en-vi_step_27000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:33 en-vi_step_28000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:43 en-vi_step_29000.pt\n","-rw------- 1 root root 1021696959 Apr 10 12:54 en-vi_step_30000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:17 en-vi_step_3000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:28 en-vi_step_4000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:38 en-vi_step_5000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:48 en-vi_step_6000.pt\n","-rw------- 1 root root 1021696959 Apr 10 08:58 en-vi_step_7000.pt\n","-rw------- 1 root root 1021696959 Apr 10 09:09 en-vi_step_8000.pt\n","-rw------- 1 root root 1021696959 Apr 10 09:19 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618063440812,"user_tz":-420,"elapsed":22656170,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e89c9e7b-e9b1-4f3f-a282-d0475ae1f066"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-10 12:54:13,772 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 14:01:41,481 INFO] PRED AVG SCORE: -0.4465, PRED PPL: 1.5628\n","[2021-04-10 14:01:41,481 INFO] GOLD AVG SCORE: -3.6336, GOLD PPL: 37.8473\n","[2021-04-10 14:01:41,508 INFO] Translating shard 1.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 14:03:59,670 INFO] PRED AVG SCORE: -0.4570, PRED PPL: 1.5793\n","[2021-04-10 14:03:59,671 INFO] GOLD AVG SCORE: -3.5959, GOLD PPL: 36.4475\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618063440813,"user_tz":-420,"elapsed":22656169,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"07382aec-7faa-44b1-b27f-9cd03ceb0edf"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cà vạt thì loè loẹt .\n","và lí do là bởi vì có 2 lí do , theo tôi nghĩ\n","Ông thích nói về thiên tài tâm linh của lứa tuổi .\n","Chúng tôi đều là người Triều Tiên , nhưng đã trở nên rất khác nhau do hậu quả của 67 năm bị chia cắt .\n","Đó là cách bạn xử lý một vấn đề khi bạn nhìn thấy chúng và đó không chỉ là việc than phiền về vấn đề đó .\n","Tham vọng của các bạn được thoã mãn , nó rất đẹp .\n","Không có thứ nào trong những điều trên thực sự hữu ích bởi vì bạn đang điều trị những triệu chứng chứ không phải nguyên nhân của các vấn đề cơ bản ở Phi Châu .\n","Nhưng hiện nay nhiều người sống đến 90 hay 100 tuổi , trừ khi họ bắt tay quá nhiều hay làm những điều đại loại thế .\n","Nhưng quý vị phải có những công cụ đúng .\n","Những điều này là một phần cuộc đời ông và là những gì ông còn nhớ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618063461071,"user_tz":-420,"elapsed":22676425,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"d2aad2e6-635e-4669-da91-292d94e869a3"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 32, done.\u001b[K\n","remote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (27/27), done.\u001b[K\n","remote: Total 17114 (delta 8), reused 11 (delta 4), pack-reused 17082\u001b[K\n","Receiving objects: 100% (17114/17114), 273.03 MiB | 19.79 MiB/s, done.\n","Resolving deltas: 100% (12332/12332), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618063461373,"user_tz":-420,"elapsed":22676725,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"ddf204ed-dd77-41ee-aa4f-61380cfb90bf"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 93791\n","drwx------  2 root root     4096 Apr 10 07:46 data_bin\n","-rw-------  1 root root   996149 Apr 10 07:32 en_test\n","-rw-------  1 root root  8024744 Apr 10 07:32 en_train\n","-rw-------  1 root root  8204550 Apr 10 07:32 en_train_EM_0.8\n","-rw-------  1 root root  8103017 Apr 10 07:32 en_train_EM_0.85\n","-rw-------  1 root root  8053185 Apr 10 07:32 en_train_EM_0.9\n","-rw-------  1 root root  8031617 Apr 10 07:32 en_train_EM_0.95\n","-rw-------  1 root root  3323998 Apr 10 07:32 en_train_EM_factor_0.8\n","-rw-------  1 root root  3281394 Apr 10 07:32 en_train_EM_factor_0.85\n","-rw-------  1 root root  3260286 Apr 10 07:32 en_train_EM_factor_0.9\n","-rw-------  1 root root  3250950 Apr 10 07:32 en_train_EM_factor_0.95\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.8\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.85\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.9\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.95\n","-rw-------  1 root root  1000856 Apr 10 07:32 en_valid\n","-rw-------  1 root root 22512408 Apr 10 07:46 en_vi_iwslt_sent2vec.tar.gz\n","drwx------  2 root root     4096 Apr 10 12:54 model\n","drwx------ 11 root root     4096 Apr 10 14:04 OpenNMT-py\n","drwx------  2 root root     4096 Apr 10 07:47 output\n","-rw-------  1 root root  1205938 Apr 10 14:03 predict.txt\n","-rw-------  1 root root  1327417 Apr 10 07:32 vi_test\n","-rw-------  1 root root 10671354 Apr 10 07:32 vi_train\n","-rw-------  1 root root  1330789 Apr 10 07:32 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618063463516,"user_tz":-420,"elapsed":22678866,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"4ae2600d-7437-4c93-f31b-f8faf3dba050"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 23.70, 59.1/33.2/19.5/11.8 (BP=0.914, ratio=0.917, hyp_len=224008, ref_len=244219)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1618063463517,"user_tz":-420,"elapsed":22678866,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}