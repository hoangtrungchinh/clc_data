{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TED-OpenNMT-sent2vec-0.85-20210410-0741 BLEU 23.54.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040506115,"user_tz":-420,"elapsed":23944,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"642e5c5e-f8f2-43fc-fe33-878a9cb11b34"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040506845,"user_tz":-420,"elapsed":24667,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"0fdde4f4-b1fb-4571-c237-6202264522ff"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"TED-OpenNMT-sent2vec-0.85-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v3/OpenNMT-TED-EM-bert-ratio-8-2-2-20210128-0637'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/TED-OpenNMT-sent2vec-0.85-20210410-0741\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040507540,"user_tz":-420,"elapsed":25359,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"da8cf058-057b-4ea8-b960-818ec0e82981"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Sat Apr 10 07:41:46 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040521465,"user_tz":-420,"elapsed":39281,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"ad7faadb-1f04-4aba-f4cb-624440a52b84"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 7.0MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Collecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 11.7MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Collecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=e6ee2eb21e310af63da80ab9b07376a43345066d818cd70b9dbfccf2759cb18a\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: waitress, pyonmttok, configargparse, torchtext, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040523158,"user_tz":-420,"elapsed":40971,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"f1f26338-a456-406f-b7af-807c56f234d1"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_sent2vec.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'en_vi_iwslt_sent2vec.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-10 07:42:00--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_sent2vec.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22512408 (21M) [application/octet-stream]\n","Saving to: ‘en_vi_iwslt_sent2vec.tar.gz’\n","\n","en_vi_iwslt_sent2ve 100%[===================>]  21.47M  49.6MB/s    in 0.4s    \n","\n","2021-04-10 07:42:01 (49.6 MB/s) - ‘en_vi_iwslt_sent2vec.tar.gz’ saved [22512408/22512408]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040535748,"user_tz":-420,"elapsed":53559,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"b99a75eb-1de4-465e-f6da-347e5ffde503"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.85' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-10 07:42:06,246 INFO] Extracting features...\n","[2021-04-10 07:42:06,249 INFO]  * number of source features: 0.\n","[2021-04-10 07:42:06,249 INFO]  * number of target features: 0.\n","[2021-04-10 07:42:06,249 INFO] Building `Fields` object...\n","[2021-04-10 07:42:06,249 INFO] Building & saving training data...\n","[2021-04-10 07:42:06,423 INFO] Building shard 0.\n","[2021-04-10 07:42:10,154 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-10 07:42:13,522 INFO]  * tgt vocab size: 18250.\n","[2021-04-10 07:42:13,595 INFO]  * src vocab size: 40623.\n","[2021-04-10 07:42:13,800 INFO] Building & saving validation data...\n","[2021-04-10 07:42:13,917 INFO] Building shard 0.\n","[2021-04-10 07:42:14,180 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618059041144,"user_tz":-420,"elapsed":18558953,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"dd77acf2-1713-4c1b-aeda-a924881ecf0e"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-10 07:42:17,052 INFO]  * src vocab size = 40623\n","[2021-04-10 07:42:17,052 INFO]  * tgt vocab size = 18250\n","[2021-04-10 07:42:17,052 INFO] Building model...\n","[2021-04-10 07:42:24,272 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(40623, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(18250, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=18250, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-10 07:42:24,339 INFO] encoder: 39714304\n","[2021-04-10 07:42:24,339 INFO] decoder: 43931466\n","[2021-04-10 07:42:24,339 INFO] * number of parameters: 83645770\n","[2021-04-10 07:42:24,343 INFO] Starting training on GPU: [0]\n","[2021-04-10 07:42:24,343 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-10 07:42:24,343 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:42:27,083 INFO] number of examples: 77471\n","[2021-04-10 07:44:35,890 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:44:39,322 INFO] number of examples: 77471\n","[2021-04-10 07:46:48,831 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:46:51,752 INFO] number of examples: 77471\n","[2021-04-10 07:49:00,799 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:49:04,173 INFO] number of examples: 77471\n","[2021-04-10 07:51:13,760 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:51:17,265 INFO] number of examples: 77471\n","[2021-04-10 07:52:21,661 INFO] Step 1000/30000; acc:  13.58; ppl: 257.17; xent: 5.55; lr: 0.00012; 10227/12698 tok/s;    597 sec\n","[2021-04-10 07:52:21,662 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 07:52:21,964 INFO] number of examples: 10362\n","[2021-04-10 07:52:38,864 INFO] Validation perplexity: 107.941\n","[2021-04-10 07:52:38,864 INFO] Validation accuracy: 25.8047\n","[2021-04-10 07:52:39,066 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-10 07:53:48,203 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:53:51,980 INFO] number of examples: 77471\n","[2021-04-10 07:56:01,757 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:56:05,066 INFO] number of examples: 77471\n","[2021-04-10 07:58:14,195 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:58:17,410 INFO] number of examples: 77471\n","[2021-04-10 08:00:26,987 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:00:30,752 INFO] number of examples: 77471\n","[2021-04-10 08:02:38,699 INFO] Step 2000/30000; acc:  39.85; ppl: 21.81; xent: 3.08; lr: 0.00025; 9900/12286 tok/s;   1214 sec\n","[2021-04-10 08:02:38,700 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:02:39,011 INFO] number of examples: 10362\n","[2021-04-10 08:02:55,914 INFO] Validation perplexity: 21.5586\n","[2021-04-10 08:02:55,914 INFO] Validation accuracy: 46.2137\n","[2021-04-10 08:02:56,116 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-10 08:03:01,425 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:03:05,283 INFO] number of examples: 77471\n","[2021-04-10 08:05:15,185 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:05:18,440 INFO] number of examples: 77471\n","[2021-04-10 08:07:27,347 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:07:30,963 INFO] number of examples: 77471\n","[2021-04-10 08:09:40,245 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:09:43,434 INFO] number of examples: 77471\n","[2021-04-10 08:11:52,128 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:11:55,902 INFO] number of examples: 77471\n","[2021-04-10 08:12:58,813 INFO] Step 3000/30000; acc:  56.63; ppl:  6.98; xent: 1.94; lr: 0.00037; 9850/12229 tok/s;   1834 sec\n","[2021-04-10 08:12:58,815 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:12:59,123 INFO] number of examples: 10362\n","[2021-04-10 08:13:15,938 INFO] Validation perplexity: 16.1756\n","[2021-04-10 08:13:15,938 INFO] Validation accuracy: 50.9514\n","[2021-04-10 08:13:16,124 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-10 08:14:26,405 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:14:29,618 INFO] number of examples: 77471\n","[2021-04-10 08:16:37,980 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:16:41,135 INFO] number of examples: 77471\n","[2021-04-10 08:18:50,144 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:18:53,805 INFO] number of examples: 77471\n","[2021-04-10 08:21:02,236 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:21:05,487 INFO] number of examples: 77471\n","[2021-04-10 08:23:11,964 INFO] Step 4000/30000; acc:  65.19; ppl:  4.20; xent: 1.43; lr: 0.00049; 9963/12363 tok/s;   2448 sec\n","[2021-04-10 08:23:11,965 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:23:12,784 INFO] number of examples: 10362\n","[2021-04-10 08:23:29,626 INFO] Validation perplexity: 15.657\n","[2021-04-10 08:23:29,626 INFO] Validation accuracy: 52.0984\n","[2021-04-10 08:23:29,818 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-10 08:23:36,838 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:23:40,067 INFO] number of examples: 77471\n","[2021-04-10 08:25:49,042 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:25:52,668 INFO] number of examples: 77471\n","[2021-04-10 08:28:01,662 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:28:05,553 INFO] number of examples: 77471\n","[2021-04-10 08:30:14,594 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:30:18,070 INFO] number of examples: 77471\n","[2021-04-10 08:32:27,589 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:32:30,868 INFO] number of examples: 77471\n","[2021-04-10 08:33:32,195 INFO] Step 5000/30000; acc:  71.40; ppl:  3.08; xent: 1.12; lr: 0.00062; 9847/12224 tok/s;   3068 sec\n","[2021-04-10 08:33:32,197 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:33:32,529 INFO] number of examples: 10362\n","[2021-04-10 08:33:49,469 INFO] Validation perplexity: 18.1996\n","[2021-04-10 08:33:49,469 INFO] Validation accuracy: 51.645\n","[2021-04-10 08:33:49,673 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-10 08:35:01,620 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:35:05,548 INFO] number of examples: 77471\n","[2021-04-10 08:37:14,924 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:37:18,270 INFO] number of examples: 77471\n","[2021-04-10 08:39:27,042 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:39:30,932 INFO] number of examples: 77471\n","[2021-04-10 08:41:39,945 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:41:43,184 INFO] number of examples: 77471\n","[2021-04-10 08:43:47,484 INFO] Step 6000/30000; acc:  76.44; ppl:  2.47; xent: 0.90; lr: 0.00074; 9926/12320 tok/s;   3683 sec\n","[2021-04-10 08:43:47,485 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:43:47,789 INFO] number of examples: 10362\n","[2021-04-10 08:44:04,562 INFO] Validation perplexity: 21.0417\n","[2021-04-10 08:44:04,562 INFO] Validation accuracy: 51.4292\n","[2021-04-10 08:44:04,743 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-10 08:44:12,792 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:44:16,131 INFO] number of examples: 77471\n","[2021-04-10 08:46:25,238 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:46:28,856 INFO] number of examples: 77471\n","[2021-04-10 08:48:37,188 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:48:41,002 INFO] number of examples: 77471\n","[2021-04-10 08:50:50,003 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:50:53,306 INFO] number of examples: 77471\n","[2021-04-10 08:53:01,561 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:53:04,899 INFO] number of examples: 77471\n","[2021-04-10 08:54:04,932 INFO] Step 7000/30000; acc:  80.77; ppl:  2.08; xent: 0.73; lr: 0.00086; 9897/12288 tok/s;   4301 sec\n","[2021-04-10 08:54:04,933 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:54:05,239 INFO] number of examples: 10362\n","[2021-04-10 08:54:22,010 INFO] Validation perplexity: 23.2428\n","[2021-04-10 08:54:22,010 INFO] Validation accuracy: 51.5114\n","[2021-04-10 08:54:22,202 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-10 08:55:35,585 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:55:38,823 INFO] number of examples: 77471\n","[2021-04-10 08:57:47,191 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:57:50,860 INFO] number of examples: 77471\n","[2021-04-10 08:59:59,808 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:00:02,961 INFO] number of examples: 77471\n","[2021-04-10 09:02:11,257 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:02:14,891 INFO] number of examples: 77471\n","[2021-04-10 09:04:18,021 INFO] Step 8000/30000; acc:  83.94; ppl:  1.86; xent: 0.62; lr: 0.00099; 9958/12355 tok/s;   4914 sec\n","[2021-04-10 09:04:18,022 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:04:18,329 INFO] number of examples: 10362\n","[2021-04-10 09:04:35,095 INFO] Validation perplexity: 25.5055\n","[2021-04-10 09:04:35,095 INFO] Validation accuracy: 51.2032\n","[2021-04-10 09:04:35,281 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-10 09:04:44,971 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:04:48,492 INFO] number of examples: 77471\n","[2021-04-10 09:06:56,880 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:07:00,476 INFO] number of examples: 77471\n","[2021-04-10 09:09:09,580 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:09:13,377 INFO] number of examples: 77471\n","[2021-04-10 09:11:21,802 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:11:25,143 INFO] number of examples: 77471\n","[2021-04-10 09:13:34,250 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:13:37,556 INFO] number of examples: 77471\n","[2021-04-10 09:14:36,006 INFO] Step 9000/30000; acc:  87.21; ppl:  1.66; xent: 0.51; lr: 0.00093; 9890/12279 tok/s;   5532 sec\n","[2021-04-10 09:14:36,007 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:14:36,314 INFO] number of examples: 10362\n","[2021-04-10 09:14:53,168 INFO] Validation perplexity: 26.6833\n","[2021-04-10 09:14:53,168 INFO] Validation accuracy: 51.7945\n","[2021-04-10 09:14:53,357 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-10 09:16:07,623 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:16:11,334 INFO] number of examples: 77471\n","[2021-04-10 09:18:20,284 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:18:23,441 INFO] number of examples: 77471\n","[2021-04-10 09:20:31,922 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:20:35,627 INFO] number of examples: 77471\n","[2021-04-10 09:22:44,618 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:22:47,845 INFO] number of examples: 77471\n","[2021-04-10 09:24:49,492 INFO] Step 10000/30000; acc:  91.00; ppl:  1.48; xent: 0.39; lr: 0.00088; 9952/12351 tok/s;   6145 sec\n","[2021-04-10 09:24:49,493 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:24:50,451 INFO] number of examples: 10362\n","[2021-04-10 09:25:07,245 INFO] Validation perplexity: 29.7841\n","[2021-04-10 09:25:07,245 INFO] Validation accuracy: 52.0581\n","[2021-04-10 09:25:07,424 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-10 09:25:18,078 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:25:21,761 INFO] number of examples: 77471\n","[2021-04-10 09:27:30,999 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:27:34,631 INFO] number of examples: 77471\n","[2021-04-10 09:29:43,053 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:29:46,206 INFO] number of examples: 77471\n","[2021-04-10 09:31:55,173 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:31:58,849 INFO] number of examples: 77471\n","[2021-04-10 09:34:07,153 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:34:10,243 INFO] number of examples: 77471\n","[2021-04-10 09:35:07,432 INFO] Step 11000/30000; acc:  93.19; ppl:  1.38; xent: 0.32; lr: 0.00084; 9888/12276 tok/s;   6763 sec\n","[2021-04-10 09:35:07,433 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:35:08,334 INFO] number of examples: 10362\n","[2021-04-10 09:35:25,139 INFO] Validation perplexity: 29.9615\n","[2021-04-10 09:35:25,139 INFO] Validation accuracy: 52.2484\n","[2021-04-10 09:35:25,316 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-10 09:36:41,299 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:36:45,591 INFO] number of examples: 77471\n","[2021-04-10 09:38:53,875 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:38:57,200 INFO] number of examples: 77471\n","[2021-04-10 09:41:06,127 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:41:09,487 INFO] number of examples: 77471\n","[2021-04-10 09:43:17,894 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:43:21,234 INFO] number of examples: 77471\n","[2021-04-10 09:45:21,671 INFO] Step 12000/30000; acc:  94.75; ppl:  1.31; xent: 0.27; lr: 0.00081; 9938/12336 tok/s;   7377 sec\n","[2021-04-10 09:45:21,672 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:45:21,975 INFO] number of examples: 10362\n","[2021-04-10 09:45:38,767 INFO] Validation perplexity: 31.2118\n","[2021-04-10 09:45:38,768 INFO] Validation accuracy: 52.4681\n","[2021-04-10 09:45:38,956 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-10 09:45:51,906 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:45:55,267 INFO] number of examples: 77471\n","[2021-04-10 09:48:04,029 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:48:07,689 INFO] number of examples: 77471\n","[2021-04-10 09:50:16,753 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:50:20,521 INFO] number of examples: 77471\n","[2021-04-10 09:52:28,989 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:52:32,315 INFO] number of examples: 77471\n","[2021-04-10 09:54:41,360 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:54:44,641 INFO] number of examples: 77471\n","[2021-04-10 09:55:40,186 INFO] Step 13000/30000; acc:  95.81; ppl:  1.27; xent: 0.24; lr: 0.00078; 9882/12264 tok/s;   7996 sec\n","[2021-04-10 09:55:40,187 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:55:40,498 INFO] number of examples: 10362\n","[2021-04-10 09:55:57,292 INFO] Validation perplexity: 31.4045\n","[2021-04-10 09:55:57,293 INFO] Validation accuracy: 52.7775\n","[2021-04-10 09:55:57,470 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-10 09:57:14,378 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:57:17,911 INFO] number of examples: 77471\n","[2021-04-10 09:59:26,769 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:59:30,544 INFO] number of examples: 77471\n","[2021-04-10 10:01:38,781 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:01:42,102 INFO] number of examples: 77471\n","[2021-04-10 10:03:51,035 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:03:54,274 INFO] number of examples: 77471\n","[2021-04-10 10:05:52,796 INFO] Step 14000/30000; acc:  96.60; ppl:  1.23; xent: 0.21; lr: 0.00075; 9962/12369 tok/s;   8608 sec\n","[2021-04-10 10:05:52,797 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:05:53,102 INFO] number of examples: 10362\n","[2021-04-10 10:06:09,896 INFO] Validation perplexity: 31.9454\n","[2021-04-10 10:06:09,896 INFO] Validation accuracy: 53.0242\n","[2021-04-10 10:06:10,078 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-10 10:06:24,211 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:06:28,516 INFO] number of examples: 77471\n","[2021-04-10 10:08:37,535 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:08:40,666 INFO] number of examples: 77471\n","[2021-04-10 10:10:49,092 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:10:52,883 INFO] number of examples: 77471\n","[2021-04-10 10:13:02,007 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:13:05,252 INFO] number of examples: 77471\n","[2021-04-10 10:15:13,554 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:15:16,728 INFO] number of examples: 77471\n","[2021-04-10 10:16:11,114 INFO] Step 15000/30000; acc:  97.12; ppl:  1.21; xent: 0.19; lr: 0.00072; 9886/12267 tok/s;   9227 sec\n","[2021-04-10 10:16:11,115 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:16:12,050 INFO] number of examples: 10362\n","[2021-04-10 10:16:28,816 INFO] Validation perplexity: 33.1999\n","[2021-04-10 10:16:28,816 INFO] Validation accuracy: 52.8519\n","[2021-04-10 10:16:29,000 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-10 10:17:47,757 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:17:52,194 INFO] number of examples: 77471\n","[2021-04-10 10:20:00,693 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:20:03,964 INFO] number of examples: 77471\n","[2021-04-10 10:22:12,695 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:22:15,987 INFO] number of examples: 77471\n","[2021-04-10 10:24:24,206 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:24:27,357 INFO] number of examples: 77471\n","[2021-04-10 10:26:24,573 INFO] Step 16000/30000; acc:  97.56; ppl:  1.19; xent: 0.17; lr: 0.00070; 9946/12353 tok/s;   9840 sec\n","[2021-04-10 10:26:24,574 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:26:24,877 INFO] number of examples: 10362\n","[2021-04-10 10:26:41,678 INFO] Validation perplexity: 33.7177\n","[2021-04-10 10:26:41,678 INFO] Validation accuracy: 52.8969\n","[2021-04-10 10:26:41,876 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-10 10:26:57,734 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:27:02,185 INFO] number of examples: 77471\n","[2021-04-10 10:29:10,528 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:29:13,741 INFO] number of examples: 77471\n","[2021-04-10 10:31:22,731 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:31:26,346 INFO] number of examples: 77471\n","[2021-04-10 10:33:34,755 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:33:37,961 INFO] number of examples: 77471\n","[2021-04-10 10:35:47,279 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:35:51,133 INFO] number of examples: 77471\n","[2021-04-10 10:36:43,804 INFO] Step 17000/30000; acc:  97.90; ppl:  1.17; xent: 0.16; lr: 0.00068; 9871/12251 tok/s;  10459 sec\n","[2021-04-10 10:36:43,805 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:36:44,117 INFO] number of examples: 10362\n","[2021-04-10 10:37:00,894 INFO] Validation perplexity: 33.9158\n","[2021-04-10 10:37:00,894 INFO] Validation accuracy: 52.9259\n","[2021-04-10 10:37:01,077 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-10 10:38:21,088 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:38:24,782 INFO] number of examples: 77471\n","[2021-04-10 10:40:33,529 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:40:36,726 INFO] number of examples: 77471\n","[2021-04-10 10:42:45,015 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:42:48,828 INFO] number of examples: 77471\n","[2021-04-10 10:44:57,834 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:45:01,132 INFO] number of examples: 77471\n","[2021-04-10 10:46:56,716 INFO] Step 18000/30000; acc:  98.16; ppl:  1.15; xent: 0.14; lr: 0.00066; 9957/12362 tok/s;  11072 sec\n","[2021-04-10 10:46:56,717 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:46:57,029 INFO] number of examples: 10362\n","[2021-04-10 10:47:13,774 INFO] Validation perplexity: 33.2985\n","[2021-04-10 10:47:13,774 INFO] Validation accuracy: 53.1201\n","[2021-04-10 10:47:13,954 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-10 10:47:30,923 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:47:34,683 INFO] number of examples: 77471\n","[2021-04-10 10:49:43,490 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:49:47,237 INFO] number of examples: 77471\n","[2021-04-10 10:51:55,450 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:51:58,751 INFO] number of examples: 77471\n","[2021-04-10 10:54:07,573 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:54:10,802 INFO] number of examples: 77471\n","[2021-04-10 10:56:19,072 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:56:22,861 INFO] number of examples: 77471\n","[2021-04-10 10:57:14,328 INFO] Step 19000/30000; acc:  98.36; ppl:  1.14; xent: 0.13; lr: 0.00064; 9896/12283 tok/s;  11690 sec\n","[2021-04-10 10:57:14,329 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:57:14,633 INFO] number of examples: 10362\n","[2021-04-10 10:57:31,386 INFO] Validation perplexity: 34.1143\n","[2021-04-10 10:57:31,386 INFO] Validation accuracy: 53.3543\n","[2021-04-10 10:57:31,571 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-10 10:58:53,438 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:58:56,746 INFO] number of examples: 77471\n","[2021-04-10 11:01:05,081 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:01:08,286 INFO] number of examples: 77471\n","[2021-04-10 11:03:17,401 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:03:21,127 INFO] number of examples: 77471\n","[2021-04-10 11:05:29,453 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:05:32,563 INFO] number of examples: 77471\n","[2021-04-10 11:07:26,982 INFO] Step 20000/30000; acc:  98.51; ppl:  1.13; xent: 0.13; lr: 0.00062; 9961/12367 tok/s;  12303 sec\n","[2021-04-10 11:07:26,983 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:07:27,946 INFO] number of examples: 10362\n","[2021-04-10 11:07:44,745 INFO] Validation perplexity: 33.9966\n","[2021-04-10 11:07:44,745 INFO] Validation accuracy: 53.2337\n","[2021-04-10 11:07:44,927 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-10 11:08:03,736 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:08:07,406 INFO] number of examples: 77471\n","[2021-04-10 11:10:15,818 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:10:19,549 INFO] number of examples: 77471\n","[2021-04-10 11:12:28,889 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:12:32,138 INFO] number of examples: 77471\n","[2021-04-10 11:14:40,893 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:14:44,658 INFO] number of examples: 77471\n","[2021-04-10 11:16:53,756 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:16:56,915 INFO] number of examples: 77471\n","[2021-04-10 11:17:46,585 INFO] Step 21000/30000; acc:  98.65; ppl:  1.13; xent: 0.12; lr: 0.00061; 9870/12249 tok/s;  12922 sec\n","[2021-04-10 11:17:46,586 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:17:47,494 INFO] number of examples: 10362\n","[2021-04-10 11:18:04,264 INFO] Validation perplexity: 34.7803\n","[2021-04-10 11:18:04,264 INFO] Validation accuracy: 53.1828\n","[2021-04-10 11:18:04,441 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-10 11:19:28,382 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:19:32,705 INFO] number of examples: 77471\n","[2021-04-10 11:21:41,705 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:21:45,087 INFO] number of examples: 77471\n","[2021-04-10 11:23:53,531 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:23:56,864 INFO] number of examples: 77471\n","[2021-04-10 11:26:05,866 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:26:09,200 INFO] number of examples: 77471\n","[2021-04-10 11:28:01,940 INFO] Step 22000/30000; acc:  98.77; ppl:  1.12; xent: 0.11; lr: 0.00060; 9913/12308 tok/s;  13538 sec\n","[2021-04-10 11:28:01,941 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:28:02,250 INFO] number of examples: 10362\n","[2021-04-10 11:28:19,075 INFO] Validation perplexity: 35.7955\n","[2021-04-10 11:28:19,075 INFO] Validation accuracy: 53.4256\n","[2021-04-10 11:28:19,260 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-10 11:28:39,069 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:28:42,975 INFO] number of examples: 77471\n","[2021-04-10 11:30:52,024 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:30:55,402 INFO] number of examples: 77471\n","[2021-04-10 11:33:03,872 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:33:07,223 INFO] number of examples: 77471\n","[2021-04-10 11:35:16,318 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:35:19,517 INFO] number of examples: 77471\n","[2021-04-10 11:37:27,873 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:37:31,748 INFO] number of examples: 77471\n","[2021-04-10 11:38:20,379 INFO] Step 23000/30000; acc:  98.86; ppl:  1.11; xent: 0.11; lr: 0.00058; 9887/12273 tok/s;  14156 sec\n","[2021-04-10 11:38:20,380 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:38:20,695 INFO] number of examples: 10362\n","[2021-04-10 11:38:37,526 INFO] Validation perplexity: 34.7975\n","[2021-04-10 11:38:37,527 INFO] Validation accuracy: 53.4033\n","[2021-04-10 11:38:37,720 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-10 11:40:02,317 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:40:05,605 INFO] number of examples: 77471\n","[2021-04-10 11:42:14,089 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:42:17,271 INFO] number of examples: 77471\n","[2021-04-10 11:44:26,405 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:44:30,159 INFO] number of examples: 77471\n","[2021-04-10 11:46:38,742 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:46:41,916 INFO] number of examples: 77471\n","[2021-04-10 11:48:33,560 INFO] Step 24000/30000; acc:  98.94; ppl:  1.11; xent: 0.10; lr: 0.00057; 9951/12352 tok/s;  14769 sec\n","[2021-04-10 11:48:33,561 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:48:34,500 INFO] number of examples: 10362\n","[2021-04-10 11:48:51,317 INFO] Validation perplexity: 34.5952\n","[2021-04-10 11:48:51,317 INFO] Validation accuracy: 53.4456\n","[2021-04-10 11:48:51,506 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-10 11:49:13,055 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:49:16,993 INFO] number of examples: 77471\n","[2021-04-10 11:51:25,502 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:51:29,215 INFO] number of examples: 77471\n","[2021-04-10 11:53:38,191 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:53:41,457 INFO] number of examples: 77471\n","[2021-04-10 11:55:50,018 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:55:53,742 INFO] number of examples: 77471\n","[2021-04-10 11:58:02,801 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:58:05,985 INFO] number of examples: 77471\n","[2021-04-10 11:58:52,822 INFO] Step 25000/30000; acc:  99.01; ppl:  1.10; xent: 0.10; lr: 0.00056; 9870/12255 tok/s;  15388 sec\n","[2021-04-10 11:58:52,823 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:58:53,135 INFO] number of examples: 10362\n","[2021-04-10 11:59:09,923 INFO] Validation perplexity: 36.9989\n","[2021-04-10 11:59:09,923 INFO] Validation accuracy: 53.2631\n","[2021-04-10 11:59:10,104 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-10 12:00:37,556 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:00:41,011 INFO] number of examples: 77471\n","[2021-04-10 12:02:50,082 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:02:53,942 INFO] number of examples: 77471\n","[2021-04-10 12:05:02,582 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:05:05,896 INFO] number of examples: 77471\n","[2021-04-10 12:07:15,092 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:07:18,294 INFO] number of examples: 77471\n","[2021-04-10 12:09:08,294 INFO] Step 26000/30000; acc:  99.07; ppl:  1.10; xent: 0.09; lr: 0.00055; 9919/12306 tok/s;  16004 sec\n","[2021-04-10 12:09:08,295 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:09:09,234 INFO] number of examples: 10362\n","[2021-04-10 12:09:26,049 INFO] Validation perplexity: 36.3432\n","[2021-04-10 12:09:26,049 INFO] Validation accuracy: 53.2243\n","[2021-04-10 12:09:26,238 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-10 12:09:49,030 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:09:53,302 INFO] number of examples: 77471\n","[2021-04-10 12:12:02,326 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:12:05,651 INFO] number of examples: 77471\n","[2021-04-10 12:14:14,117 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:14:17,506 INFO] number of examples: 77471\n","[2021-04-10 12:16:26,595 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:16:29,806 INFO] number of examples: 77471\n","[2021-04-10 12:18:38,317 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:18:42,073 INFO] number of examples: 77471\n","[2021-04-10 12:19:27,818 INFO] Step 27000/30000; acc:  99.13; ppl:  1.09; xent: 0.09; lr: 0.00054; 9863/12250 tok/s;  16623 sec\n","[2021-04-10 12:19:27,819 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:19:28,140 INFO] number of examples: 10362\n","[2021-04-10 12:19:44,999 INFO] Validation perplexity: 36.7334\n","[2021-04-10 12:19:44,999 INFO] Validation accuracy: 53.4182\n","[2021-04-10 12:19:45,188 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-10 12:21:13,011 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:21:16,723 INFO] number of examples: 77471\n","[2021-04-10 12:23:25,370 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:23:28,671 INFO] number of examples: 77471\n","[2021-04-10 12:25:37,990 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:25:41,781 INFO] number of examples: 77471\n","[2021-04-10 12:27:50,302 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:27:53,499 INFO] number of examples: 77471\n","[2021-04-10 12:29:42,304 INFO] Step 28000/30000; acc:  99.17; ppl:  1.09; xent: 0.09; lr: 0.00053; 9934/12327 tok/s;  17238 sec\n","[2021-04-10 12:29:42,305 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:29:43,292 INFO] number of examples: 10362\n","[2021-04-10 12:30:00,131 INFO] Validation perplexity: 37.312\n","[2021-04-10 12:30:00,131 INFO] Validation accuracy: 53.2486\n","[2021-04-10 12:30:00,309 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-10 12:30:24,826 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:30:28,504 INFO] number of examples: 77471\n","[2021-04-10 12:32:37,250 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:32:41,065 INFO] number of examples: 77471\n","[2021-04-10 12:34:50,238 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:34:53,542 INFO] number of examples: 77471\n","[2021-04-10 12:37:02,124 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:37:05,932 INFO] number of examples: 77471\n","[2021-04-10 12:39:15,043 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:39:18,273 INFO] number of examples: 77471\n","[2021-04-10 12:40:02,237 INFO] Step 29000/30000; acc:  99.21; ppl:  1.09; xent: 0.08; lr: 0.00052; 9857/12240 tok/s;  17858 sec\n","[2021-04-10 12:40:02,239 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:40:02,571 INFO] number of examples: 10362\n","[2021-04-10 12:40:19,465 INFO] Validation perplexity: 37.0714\n","[2021-04-10 12:40:19,465 INFO] Validation accuracy: 53.4146\n","[2021-04-10 12:40:19,661 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-10 12:41:49,603 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:41:53,212 INFO] number of examples: 77471\n","[2021-04-10 12:44:02,534 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:44:06,386 INFO] number of examples: 77471\n","[2021-04-10 12:46:14,918 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:46:18,206 INFO] number of examples: 77471\n","[2021-04-10 12:48:27,334 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:48:30,519 INFO] number of examples: 77471\n","[2021-04-10 12:50:17,706 INFO] Step 30000/30000; acc:  99.25; ppl:  1.08; xent: 0.08; lr: 0.00051; 9921/12314 tok/s;  18473 sec\n","[2021-04-10 12:50:17,708 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:50:18,660 INFO] number of examples: 10362\n","[2021-04-10 12:50:35,539 INFO] Validation perplexity: 37.3706\n","[2021-04-10 12:50:35,539 INFO] Validation accuracy: 53.5008\n","[2021-04-10 12:50:35,725 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618059041145,"user_tz":-420,"elapsed":18558952,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"9087f04a-7359-4b4c-8f65-90dee62f631c"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 30072225\n","-rw------- 1 root root 1026464831 Apr 10 09:25 en-vi_step_10000.pt\n","-rw------- 1 root root 1026464831 Apr 10 07:52 en-vi_step_1000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:35 en-vi_step_11000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:45 en-vi_step_12000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:56 en-vi_step_13000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:06 en-vi_step_14000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:16 en-vi_step_15000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:26 en-vi_step_16000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:37 en-vi_step_17000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:47 en-vi_step_18000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:57 en-vi_step_19000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:07 en-vi_step_20000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:03 en-vi_step_2000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:18 en-vi_step_21000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:28 en-vi_step_22000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:38 en-vi_step_23000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:48 en-vi_step_24000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:59 en-vi_step_25000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:09 en-vi_step_26000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:19 en-vi_step_27000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:30 en-vi_step_28000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:40 en-vi_step_29000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:50 en-vi_step_30000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:13 en-vi_step_3000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:23 en-vi_step_4000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:33 en-vi_step_5000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:44 en-vi_step_6000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:54 en-vi_step_7000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:04 en-vi_step_8000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:14 en-vi_step_9000.pt\n","\n","model/:\n","total 30072225\n","-rw------- 1 root root 1026464831 Apr 10 09:25 en-vi_step_10000.pt\n","-rw------- 1 root root 1026464831 Apr 10 07:52 en-vi_step_1000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:35 en-vi_step_11000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:45 en-vi_step_12000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:56 en-vi_step_13000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:06 en-vi_step_14000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:16 en-vi_step_15000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:26 en-vi_step_16000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:37 en-vi_step_17000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:47 en-vi_step_18000.pt\n","-rw------- 1 root root 1026464831 Apr 10 10:57 en-vi_step_19000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:07 en-vi_step_20000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:03 en-vi_step_2000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:18 en-vi_step_21000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:28 en-vi_step_22000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:38 en-vi_step_23000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:48 en-vi_step_24000.pt\n","-rw------- 1 root root 1026464831 Apr 10 11:59 en-vi_step_25000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:09 en-vi_step_26000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:19 en-vi_step_27000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:30 en-vi_step_28000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:40 en-vi_step_29000.pt\n","-rw------- 1 root root 1026464831 Apr 10 12:50 en-vi_step_30000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:13 en-vi_step_3000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:23 en-vi_step_4000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:33 en-vi_step_5000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:44 en-vi_step_6000.pt\n","-rw------- 1 root root 1026464831 Apr 10 08:54 en-vi_step_7000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:04 en-vi_step_8000.pt\n","-rw------- 1 root root 1026464831 Apr 10 09:14 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618061701189,"user_tz":-420,"elapsed":21218994,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"63dcb825-0928-40cb-f75a-aef7ed538c20"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-10 12:50:47,784 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 13:33:31,079 INFO] PRED AVG SCORE: -0.4458, PRED PPL: 1.5618\n","[2021-04-10 13:33:31,080 INFO] GOLD AVG SCORE: -3.6422, GOLD PPL: 38.1756\n","[2021-04-10 13:33:31,109 INFO] Translating shard 1.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 13:35:00,529 INFO] PRED AVG SCORE: -0.4489, PRED PPL: 1.5666\n","[2021-04-10 13:35:00,529 INFO] GOLD AVG SCORE: -3.6215, GOLD PPL: 37.3918\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618061701190,"user_tz":-420,"elapsed":21218993,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"0fa7cad3-02eb-4f70-9388-b3c05186969c"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cà vạt thì loè loẹt .\n","và lí do là bởi vì có 2 lí do , theo tôi nghĩ\n","Ông thích nói về thiên tài tâm linh của lứa tuổi .\n","Chúng tôi đều là người Triều Tiên , nhưng đã trở nên rất khác nhau do hậu quả của 67 năm bị chia cắt .\n","Đó là cách bạn xử lý một vấn đề khi bạn nhìn thấy chúng và đó không chỉ là việc than phiền về vấn đề đó .\n","Tham vọng của các bạn được thoã mãn , nó rất đẹp .\n","Không có thứ nào trong những điều trên thực sự hữu ích bởi vì bạn đang điều trị những triệu chứng chứ không phải nguyên nhân của các vấn đề cơ bản ở Phi Châu .\n","Nhưng hiện nay nhiều người sống đến 90 hay 100 tuổi , trừ khi họ bắt tay quá nhiều hay làm những điều đại loại thế .\n","Nhưng quý vị phải có những công cụ đúng .\n","Những điều này là một phần cuộc đời ông và là những gì ông còn nhớ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618061721016,"user_tz":-420,"elapsed":21238817,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"2b5e482d-18d2-4b82-cb46-73b5d8ec5707"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 29, done.\u001b[K\n","remote: Counting objects: 100% (29/29), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 17114 (delta 7), reused 8 (delta 4), pack-reused 17085\u001b[K\n","Receiving objects: 100% (17114/17114), 273.05 MiB | 21.95 MiB/s, done.\n","Resolving deltas: 100% (12323/12323), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618061721017,"user_tz":-420,"elapsed":21238816,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"468cd5f5-990c-4ff6-f16f-2ecee9044d77"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 93789\n","drwx------  2 root root     4096 Apr 10 07:42 data_bin\n","-rw-------  1 root root   996149 Apr 10 07:32 en_test\n","-rw-------  1 root root  8024744 Apr 10 07:32 en_train\n","-rw-------  1 root root  8204550 Apr 10 07:32 en_train_EM_0.8\n","-rw-------  1 root root  8103017 Apr 10 07:32 en_train_EM_0.85\n","-rw-------  1 root root  8053185 Apr 10 07:32 en_train_EM_0.9\n","-rw-------  1 root root  8031617 Apr 10 07:32 en_train_EM_0.95\n","-rw-------  1 root root  3323998 Apr 10 07:32 en_train_EM_factor_0.8\n","-rw-------  1 root root  3281394 Apr 10 07:32 en_train_EM_factor_0.85\n","-rw-------  1 root root  3260286 Apr 10 07:32 en_train_EM_factor_0.9\n","-rw-------  1 root root  3250950 Apr 10 07:32 en_train_EM_factor_0.95\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.8\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.85\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.9\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.95\n","-rw-------  1 root root  1000856 Apr 10 07:32 en_valid\n","-rw-------  1 root root 22512408 Apr 10 07:42 en_vi_iwslt_sent2vec.tar.gz\n","drwx------  2 root root     4096 Apr 10 12:50 model\n","drwx------ 11 root root     4096 Apr 10 13:35 OpenNMT-py\n","drwx------  2 root root     4096 Apr 10 07:42 output\n","-rw-------  1 root root  1204414 Apr 10 13:35 predict.txt\n","-rw-------  1 root root  1327417 Apr 10 07:32 vi_test\n","-rw-------  1 root root 10671354 Apr 10 07:32 vi_train\n","-rw-------  1 root root  1330789 Apr 10 07:32 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618061723392,"user_tz":-420,"elapsed":21241190,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"dee480df-70bb-469f-a3d2-5cdb3648cf52"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 23.54, 58.8/33.0/19.3/11.7 (BP=0.916, ratio=0.919, hyp_len=224408, ref_len=244219)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1618061723393,"user_tz":-420,"elapsed":21241189,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}