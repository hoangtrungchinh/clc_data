{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TED-OpenNMT-bert-0.9-20210409-1055 BLEU 23.84.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968904740,"user_tz":-420,"elapsed":18713,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e3b33a29-a37a-4022-c8e2-aabb7854ea37"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968905589,"user_tz":-420,"elapsed":19559,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"0d895331-78a0-4b18-d5c5-3b83e765d767"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"TED-OpenNMT-bert-0.9-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v3/OpenNMT-TED-EM-bert-ratio-8-2-2-20210128-0637'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/TED-OpenNMT-bert-0.9-20210409-1148\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968905589,"user_tz":-420,"elapsed":19557,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"7bb7a706-69e4-49b8-a841-42ad6537709f"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Fri Apr  9 11:48:25 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968918748,"user_tz":-420,"elapsed":32715,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"b7d042ab-7abf-4d2c-d7f0-c242eb6ff84d"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\r\u001b[K     |█▊                              | 10kB 22.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 8.9MB/s \n","\u001b[?25hCollecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\r\u001b[K     |██████▏                         | 10kB 28.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 36.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 31.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 14.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Collecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=cdec71f50c7af60b17e3b06362d0d456aef2b2a1bfda92aace21a479048db37c\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: torchtext, pyonmttok, waitress, configargparse, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968920573,"user_tz":-420,"elapsed":34538,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"4b9b727b-ab36-4cd3-eef3-41c53d09f5de"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'en_vi_iwslt_bert.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-09 11:48:38--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22435544 (21M) [application/octet-stream]\n","Saving to: ‘en_vi_iwslt_bert.tar.gz’\n","\n","en_vi_iwslt_bert.ta 100%[===================>]  21.40M  86.8MB/s    in 0.2s    \n","\n","2021-04-09 11:48:39 (86.8 MB/s) - ‘en_vi_iwslt_bert.tar.gz’ saved [22435544/22435544]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968932294,"user_tz":-420,"elapsed":46258,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"cf7bc5c7-0c3f-4a2c-c061-726af0b4d6e9"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.9' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-09 11:48:43,487 INFO] Extracting features...\n","[2021-04-09 11:48:43,490 INFO]  * number of source features: 0.\n","[2021-04-09 11:48:43,490 INFO]  * number of target features: 0.\n","[2021-04-09 11:48:43,490 INFO] Building `Fields` object...\n","[2021-04-09 11:48:43,490 INFO] Building & saving training data...\n","[2021-04-09 11:48:43,640 INFO] Building shard 0.\n","[2021-04-09 11:48:46,975 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-09 11:48:49,958 INFO]  * tgt vocab size: 18250.\n","[2021-04-09 11:48:50,017 INFO]  * src vocab size: 39966.\n","[2021-04-09 11:48:50,213 INFO] Building & saving validation data...\n","[2021-04-09 11:48:50,320 INFO] Building shard 0.\n","[2021-04-09 11:48:50,554 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617987288117,"user_tz":-420,"elapsed":18402079,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"68e183f9-3d22-4aa3-cc99-e9e8311d2114"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-09 11:48:53,087 INFO]  * src vocab size = 39966\n","[2021-04-09 11:48:53,087 INFO]  * tgt vocab size = 18250\n","[2021-04-09 11:48:53,087 INFO] Building model...\n","[2021-04-09 11:48:59,978 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(39966, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(18250, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=18250, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-09 11:49:00,011 INFO] encoder: 39377920\n","[2021-04-09 11:49:00,012 INFO] decoder: 43931466\n","[2021-04-09 11:49:00,012 INFO] * number of parameters: 83309386\n","[2021-04-09 11:49:00,015 INFO] Starting training on GPU: [0]\n","[2021-04-09 11:49:00,015 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-09 11:49:00,016 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:49:02,529 INFO] number of examples: 77471\n","[2021-04-09 11:51:08,909 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:51:11,960 INFO] number of examples: 77471\n","[2021-04-09 11:53:18,333 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:53:21,029 INFO] number of examples: 77471\n","[2021-04-09 11:55:27,406 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:55:30,440 INFO] number of examples: 77471\n","[2021-04-09 11:57:36,820 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:57:39,948 INFO] number of examples: 77471\n","[2021-04-09 11:58:48,950 INFO] Step 1000/30000; acc:  13.62; ppl: 254.01; xent: 5.54; lr: 0.00012; 10377/13027 tok/s;    589 sec\n","[2021-04-09 11:58:48,951 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 11:58:49,227 INFO] number of examples: 10362\n","[2021-04-09 11:59:05,842 INFO] Validation perplexity: 103.397\n","[2021-04-09 11:59:05,842 INFO] Validation accuracy: 26.0952\n","[2021-04-09 11:59:06,009 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-09 12:00:07,224 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:00:10,499 INFO] number of examples: 77471\n","[2021-04-09 12:02:16,970 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:02:19,851 INFO] number of examples: 77471\n","[2021-04-09 12:04:26,340 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:04:29,609 INFO] number of examples: 77471\n","[2021-04-09 12:06:36,111 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:06:39,564 INFO] number of examples: 77471\n","[2021-04-09 12:08:46,077 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:08:49,155 INFO] number of examples: 77471\n","[2021-04-09 12:09:01,271 INFO] Step 2000/30000; acc:  40.45; ppl: 20.93; xent: 3.04; lr: 0.00025; 9996/12515 tok/s;   1201 sec\n","[2021-04-09 12:09:01,272 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:09:01,559 INFO] number of examples: 10362\n","[2021-04-09 12:09:18,197 INFO] Validation perplexity: 21.2421\n","[2021-04-09 12:09:18,197 INFO] Validation accuracy: 46.3469\n","[2021-04-09 12:09:18,366 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-09 12:11:16,962 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:11:19,878 INFO] number of examples: 77471\n","[2021-04-09 12:13:26,301 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:13:29,622 INFO] number of examples: 77471\n","[2021-04-09 12:15:36,081 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:15:39,588 INFO] number of examples: 77471\n","[2021-04-09 12:17:46,046 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:17:49,101 INFO] number of examples: 77471\n","[2021-04-09 12:19:09,677 INFO] Step 3000/30000; acc:  56.90; ppl:  6.87; xent: 1.93; lr: 0.00037; 10046/12609 tok/s;   1810 sec\n","[2021-04-09 12:19:09,678 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:19:09,965 INFO] number of examples: 10362\n","[2021-04-09 12:19:26,603 INFO] Validation perplexity: 16.3752\n","[2021-04-09 12:19:26,604 INFO] Validation accuracy: 50.8613\n","[2021-04-09 12:19:26,770 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-09 12:20:16,851 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:20:19,796 INFO] number of examples: 77471\n","[2021-04-09 12:22:26,246 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:22:29,635 INFO] number of examples: 77471\n","[2021-04-09 12:24:36,143 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:24:39,680 INFO] number of examples: 77471\n","[2021-04-09 12:26:46,209 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:26:49,275 INFO] number of examples: 77471\n","[2021-04-09 12:28:55,749 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:28:58,759 INFO] number of examples: 77471\n","[2021-04-09 12:29:22,258 INFO] Step 4000/30000; acc:  65.27; ppl:  4.18; xent: 1.43; lr: 0.00049; 9985/12510 tok/s;   2422 sec\n","[2021-04-09 12:29:22,259 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:29:22,550 INFO] number of examples: 10362\n","[2021-04-09 12:29:39,183 INFO] Validation perplexity: 16.4842\n","[2021-04-09 12:29:39,183 INFO] Validation accuracy: 51.4049\n","[2021-04-09 12:29:39,358 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-09 12:31:26,119 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:31:29,539 INFO] number of examples: 77471\n","[2021-04-09 12:33:36,079 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:33:39,101 INFO] number of examples: 77471\n","[2021-04-09 12:35:45,847 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:35:49,277 INFO] number of examples: 77471\n","[2021-04-09 12:37:55,787 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:37:58,751 INFO] number of examples: 77471\n","[2021-04-09 12:39:30,753 INFO] Step 5000/30000; acc:  71.71; ppl:  3.04; xent: 1.11; lr: 0.00062; 10049/12607 tok/s;   3031 sec\n","[2021-04-09 12:39:30,754 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:39:31,499 INFO] number of examples: 10362\n","[2021-04-09 12:39:48,167 INFO] Validation perplexity: 17.9736\n","[2021-04-09 12:39:48,167 INFO] Validation accuracy: 51.7299\n","[2021-04-09 12:39:48,338 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-09 12:40:26,967 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:40:29,871 INFO] number of examples: 77471\n","[2021-04-09 12:42:36,477 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:42:39,869 INFO] number of examples: 77471\n","[2021-04-09 12:44:46,333 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:44:49,903 INFO] number of examples: 77471\n","[2021-04-09 12:46:56,672 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:46:59,781 INFO] number of examples: 77471\n","[2021-04-09 12:49:06,559 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:49:09,634 INFO] number of examples: 77471\n","[2021-04-09 12:49:44,570 INFO] Step 6000/30000; acc:  77.16; ppl:  2.40; xent: 0.88; lr: 0.00074; 9959/12486 tok/s;   3645 sec\n","[2021-04-09 12:49:44,571 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:49:44,860 INFO] number of examples: 10362\n","[2021-04-09 12:50:01,583 INFO] Validation perplexity: 21.5154\n","[2021-04-09 12:50:01,583 INFO] Validation accuracy: 51.4593\n","[2021-04-09 12:50:01,774 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-09 12:51:38,004 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:51:41,518 INFO] number of examples: 77471\n","[2021-04-09 12:53:48,272 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:53:51,852 INFO] number of examples: 77471\n","[2021-04-09 12:55:58,386 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:56:01,482 INFO] number of examples: 77471\n","[2021-04-09 12:58:07,958 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:58:10,947 INFO] number of examples: 77471\n","[2021-04-09 12:59:54,353 INFO] Step 7000/30000; acc:  81.33; ppl:  2.04; xent: 0.71; lr: 0.00086; 10026/12575 tok/s;   4254 sec\n","[2021-04-09 12:59:54,354 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:59:54,641 INFO] number of examples: 10362\n","[2021-04-09 13:00:11,286 INFO] Validation perplexity: 24.6438\n","[2021-04-09 13:00:11,286 INFO] Validation accuracy: 51.298\n","[2021-04-09 13:00:11,454 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-09 13:00:38,892 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:00:42,274 INFO] number of examples: 77471\n","[2021-04-09 13:02:48,808 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:02:52,303 INFO] number of examples: 77471\n","[2021-04-09 13:04:58,923 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:05:01,967 INFO] number of examples: 77471\n","[2021-04-09 13:07:08,523 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:07:11,536 INFO] number of examples: 77471\n","[2021-04-09 13:09:18,170 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:09:21,674 INFO] number of examples: 77471\n","[2021-04-09 13:10:07,880 INFO] Step 8000/30000; acc:  84.47; ppl:  1.82; xent: 0.60; lr: 0.00099; 9970/12504 tok/s;   4868 sec\n","[2021-04-09 13:10:07,881 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:10:08,170 INFO] number of examples: 10362\n","[2021-04-09 13:10:24,806 INFO] Validation perplexity: 26.544\n","[2021-04-09 13:10:24,806 INFO] Validation accuracy: 51.446\n","[2021-04-09 13:10:24,972 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-09 13:11:49,505 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:11:52,480 INFO] number of examples: 77471\n","[2021-04-09 13:13:58,951 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:14:02,394 INFO] number of examples: 77471\n","[2021-04-09 13:16:08,922 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:16:11,928 INFO] number of examples: 77471\n","[2021-04-09 13:18:18,622 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:18:22,089 INFO] number of examples: 77471\n","[2021-04-09 13:20:17,209 INFO] Step 9000/30000; acc:  87.76; ppl:  1.63; xent: 0.49; lr: 0.00093; 10044/12582 tok/s;   5477 sec\n","[2021-04-09 13:20:17,210 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:20:17,500 INFO] number of examples: 10362\n","[2021-04-09 13:20:34,177 INFO] Validation perplexity: 28.0781\n","[2021-04-09 13:20:34,177 INFO] Validation accuracy: 51.5443\n","[2021-04-09 13:20:34,343 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-09 13:20:49,786 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:20:53,687 INFO] number of examples: 77471\n","[2021-04-09 13:23:00,308 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:23:03,345 INFO] number of examples: 77471\n","[2021-04-09 13:25:09,833 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:25:13,393 INFO] number of examples: 77471\n","[2021-04-09 13:27:19,919 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:27:23,055 INFO] number of examples: 77471\n","[2021-04-09 13:29:29,752 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:29:32,830 INFO] number of examples: 77471\n","[2021-04-09 13:30:30,595 INFO] Step 10000/30000; acc:  91.08; ppl:  1.47; xent: 0.39; lr: 0.00088; 9963/12504 tok/s;   6091 sec\n","[2021-04-09 13:30:30,596 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:30:30,884 INFO] number of examples: 10362\n","[2021-04-09 13:30:47,537 INFO] Validation perplexity: 29.9676\n","[2021-04-09 13:30:47,537 INFO] Validation accuracy: 51.7617\n","[2021-04-09 13:30:47,705 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-09 13:32:00,905 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:32:04,406 INFO] number of examples: 77471\n","[2021-04-09 13:34:10,980 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:34:14,056 INFO] number of examples: 77471\n","[2021-04-09 13:36:20,771 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:36:24,359 INFO] number of examples: 77471\n","[2021-04-09 13:38:30,989 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:38:34,093 INFO] number of examples: 77471\n","[2021-04-09 13:40:40,730 INFO] Step 11000/30000; acc:  93.35; ppl:  1.37; xent: 0.32; lr: 0.00084; 10035/12565 tok/s;   6701 sec\n","[2021-04-09 13:40:40,731 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:40:41,025 INFO] number of examples: 10362\n","[2021-04-09 13:40:57,751 INFO] Validation perplexity: 29.4018\n","[2021-04-09 13:40:57,751 INFO] Validation accuracy: 52.8374\n","[2021-04-09 13:40:57,924 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-09 13:41:01,632 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:41:04,723 INFO] number of examples: 77471\n","[2021-04-09 13:43:11,595 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:43:15,040 INFO] number of examples: 77471\n","[2021-04-09 13:45:21,643 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:45:24,612 INFO] number of examples: 77471\n","[2021-04-09 13:47:31,158 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:47:34,571 INFO] number of examples: 77471\n","[2021-04-09 13:49:41,097 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:49:44,074 INFO] number of examples: 77471\n","[2021-04-09 13:50:53,240 INFO] Step 12000/30000; acc:  94.91; ppl:  1.31; xent: 0.27; lr: 0.00081; 9978/12525 tok/s;   7313 sec\n","[2021-04-09 13:50:53,241 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:50:54,094 INFO] number of examples: 10362\n","[2021-04-09 13:51:10,741 INFO] Validation perplexity: 31.0135\n","[2021-04-09 13:51:10,741 INFO] Validation accuracy: 52.6467\n","[2021-04-09 13:51:10,907 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-09 13:52:12,643 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:52:16,746 INFO] number of examples: 77471\n","[2021-04-09 13:54:23,530 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:54:26,759 INFO] number of examples: 77471\n","[2021-04-09 13:56:33,526 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:56:36,577 INFO] number of examples: 77471\n","[2021-04-09 13:58:43,061 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:58:46,065 INFO] number of examples: 77471\n","[2021-04-09 14:00:52,605 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:00:56,118 INFO] number of examples: 77471\n","[2021-04-09 14:01:08,264 INFO] Step 13000/30000; acc:  95.93; ppl:  1.26; xent: 0.23; lr: 0.00078; 9952/12460 tok/s;   7928 sec\n","[2021-04-09 14:01:08,265 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:01:08,556 INFO] number of examples: 10362\n","[2021-04-09 14:01:25,206 INFO] Validation perplexity: 30.7382\n","[2021-04-09 14:01:25,206 INFO] Validation accuracy: 52.6706\n","[2021-04-09 14:01:25,374 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-09 14:03:23,663 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:03:26,650 INFO] number of examples: 77471\n","[2021-04-09 14:05:33,295 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:05:36,800 INFO] number of examples: 77471\n","[2021-04-09 14:07:43,357 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:07:46,486 INFO] number of examples: 77471\n","[2021-04-09 14:09:53,027 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:09:56,590 INFO] number of examples: 77471\n","[2021-04-09 14:11:17,230 INFO] Step 14000/30000; acc:  96.67; ppl:  1.23; xent: 0.21; lr: 0.00075; 10037/12598 tok/s;   8537 sec\n","[2021-04-09 14:11:17,231 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:11:17,518 INFO] number of examples: 10362\n","[2021-04-09 14:11:34,165 INFO] Validation perplexity: 32.0909\n","[2021-04-09 14:11:34,165 INFO] Validation accuracy: 52.8131\n","[2021-04-09 14:11:34,331 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-09 14:12:25,300 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:12:28,309 INFO] number of examples: 77471\n","[2021-04-09 14:14:34,838 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:14:38,368 INFO] number of examples: 77471\n","[2021-04-09 14:16:44,904 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:16:47,991 INFO] number of examples: 77471\n","[2021-04-09 14:18:54,549 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:18:57,606 INFO] number of examples: 77471\n","[2021-04-09 14:21:04,151 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:21:07,101 INFO] number of examples: 77471\n","[2021-04-09 14:21:30,604 INFO] Step 15000/30000; acc:  97.19; ppl:  1.20; xent: 0.19; lr: 0.00072; 9972/12494 tok/s;   9151 sec\n","[2021-04-09 14:21:30,605 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:21:31,462 INFO] number of examples: 10362\n","[2021-04-09 14:21:48,131 INFO] Validation perplexity: 30.8327\n","[2021-04-09 14:21:48,131 INFO] Validation accuracy: 53.5043\n","[2021-04-09 14:21:48,300 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-09 14:23:35,502 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:23:39,608 INFO] number of examples: 77471\n","[2021-04-09 14:25:46,186 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:25:49,351 INFO] number of examples: 77471\n","[2021-04-09 14:27:55,951 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:27:59,083 INFO] number of examples: 77471\n","[2021-04-09 14:30:05,725 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:30:08,810 INFO] number of examples: 77471\n","[2021-04-09 14:31:40,843 INFO] Step 16000/30000; acc:  97.59; ppl:  1.18; xent: 0.17; lr: 0.00070; 10020/12571 tok/s;   9761 sec\n","[2021-04-09 14:31:40,844 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:31:41,133 INFO] number of examples: 10362\n","[2021-04-09 14:31:57,785 INFO] Validation perplexity: 33.2009\n","[2021-04-09 14:31:57,785 INFO] Validation accuracy: 52.8867\n","[2021-04-09 14:31:57,953 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-09 14:32:36,352 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:32:39,362 INFO] number of examples: 77471\n","[2021-04-09 14:34:45,924 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:34:49,302 INFO] number of examples: 77471\n","[2021-04-09 14:36:55,868 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:36:59,435 INFO] number of examples: 77471\n","[2021-04-09 14:39:06,131 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:39:09,228 INFO] number of examples: 77471\n","[2021-04-09 14:41:15,836 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:41:18,876 INFO] number of examples: 77471\n","[2021-04-09 14:41:53,712 INFO] Step 17000/30000; acc:  97.94; ppl:  1.17; xent: 0.15; lr: 0.00068; 9975/12505 tok/s;  10374 sec\n","[2021-04-09 14:41:53,713 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:41:54,009 INFO] number of examples: 10362\n","[2021-04-09 14:42:10,669 INFO] Validation perplexity: 33.53\n","[2021-04-09 14:42:10,669 INFO] Validation accuracy: 53.0865\n","[2021-04-09 14:42:10,836 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-09 14:43:46,521 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:43:49,964 INFO] number of examples: 77471\n","[2021-04-09 14:45:56,787 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:46:00,398 INFO] number of examples: 77471\n","[2021-04-09 14:48:07,161 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:48:10,256 INFO] number of examples: 77471\n","[2021-04-09 14:50:17,018 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:50:20,050 INFO] number of examples: 77471\n","[2021-04-09 14:52:03,511 INFO] Step 18000/30000; acc:  98.19; ppl:  1.15; xent: 0.14; lr: 0.00066; 10026/12575 tok/s;  10983 sec\n","[2021-04-09 14:52:03,512 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:52:03,801 INFO] number of examples: 10362\n","[2021-04-09 14:52:20,456 INFO] Validation perplexity: 32.8751\n","[2021-04-09 14:52:20,456 INFO] Validation accuracy: 53.5161\n","[2021-04-09 14:52:20,632 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-09 14:52:47,792 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:52:51,201 INFO] number of examples: 77471\n","[2021-04-09 14:54:57,900 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:55:01,511 INFO] number of examples: 77471\n","[2021-04-09 14:57:08,136 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:57:11,217 INFO] number of examples: 77471\n","[2021-04-09 14:59:17,805 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:59:20,827 INFO] number of examples: 77471\n","[2021-04-09 15:01:27,438 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:01:30,973 INFO] number of examples: 77471\n","[2021-04-09 15:02:17,317 INFO] Step 19000/30000; acc:  98.39; ppl:  1.14; xent: 0.13; lr: 0.00064; 9966/12498 tok/s;  11597 sec\n","[2021-04-09 15:02:17,318 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:02:17,608 INFO] number of examples: 10362\n","[2021-04-09 15:02:34,311 INFO] Validation perplexity: 33.1824\n","[2021-04-09 15:02:34,311 INFO] Validation accuracy: 53.4843\n","[2021-04-09 15:02:34,481 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-09 15:03:59,000 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:04:02,526 INFO] number of examples: 77471\n","[2021-04-09 15:06:09,035 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:06:12,115 INFO] number of examples: 77471\n","[2021-04-09 15:08:18,644 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:08:21,648 INFO] number of examples: 77471\n","[2021-04-09 15:10:28,234 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:10:31,655 INFO] number of examples: 77471\n","[2021-04-09 15:12:26,716 INFO] Step 20000/30000; acc:  98.54; ppl:  1.13; xent: 0.13; lr: 0.00062; 10043/12581 tok/s;  12207 sec\n","[2021-04-09 15:12:26,717 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:12:27,001 INFO] number of examples: 10362\n","[2021-04-09 15:12:43,648 INFO] Validation perplexity: 35.5302\n","[2021-04-09 15:12:43,648 INFO] Validation accuracy: 53.0109\n","[2021-04-09 15:12:43,816 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-09 15:12:59,400 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:13:03,349 INFO] number of examples: 77471\n","[2021-04-09 15:15:09,962 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:15:12,995 INFO] number of examples: 77471\n","[2021-04-09 15:17:19,493 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:17:23,028 INFO] number of examples: 77471\n","[2021-04-09 15:19:29,510 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:19:32,639 INFO] number of examples: 77471\n","[2021-04-09 15:21:39,402 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:21:42,507 INFO] number of examples: 77471\n","[2021-04-09 15:22:40,251 INFO] Step 21000/30000; acc:  98.67; ppl:  1.13; xent: 0.12; lr: 0.00061; 9960/12501 tok/s;  12820 sec\n","[2021-04-09 15:22:40,252 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:22:40,541 INFO] number of examples: 10362\n","[2021-04-09 15:22:57,233 INFO] Validation perplexity: 35.3146\n","[2021-04-09 15:22:57,233 INFO] Validation accuracy: 53.1891\n","[2021-04-09 15:22:57,405 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-09 15:24:11,520 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:24:15,105 INFO] number of examples: 77471\n","[2021-04-09 15:26:21,798 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:26:24,932 INFO] number of examples: 77471\n","[2021-04-09 15:28:31,416 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:28:34,375 INFO] number of examples: 77471\n","[2021-04-09 15:30:41,020 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:30:44,415 INFO] number of examples: 77471\n","[2021-04-09 15:32:50,888 INFO] Step 22000/30000; acc:  98.78; ppl:  1.12; xent: 0.11; lr: 0.00060; 10026/12555 tok/s;  13431 sec\n","[2021-04-09 15:32:50,889 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:32:51,177 INFO] number of examples: 10362\n","[2021-04-09 15:33:07,815 INFO] Validation perplexity: 35.4408\n","[2021-04-09 15:33:07,815 INFO] Validation accuracy: 53.502\n","[2021-04-09 15:33:07,985 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-09 15:33:12,198 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:33:15,648 INFO] number of examples: 77471\n","[2021-04-09 15:35:22,289 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:35:25,792 INFO] number of examples: 77471\n","[2021-04-09 15:37:32,310 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:37:35,346 INFO] number of examples: 77471\n","[2021-04-09 15:39:41,800 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:39:44,771 INFO] number of examples: 77471\n","[2021-04-09 15:41:51,333 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:41:54,798 INFO] number of examples: 77471\n","[2021-04-09 15:43:03,979 INFO] Step 23000/30000; acc:  98.87; ppl:  1.11; xent: 0.11; lr: 0.00058; 9968/12513 tok/s;  14044 sec\n","[2021-04-09 15:43:03,980 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:43:04,273 INFO] number of examples: 10362\n","[2021-04-09 15:43:20,975 INFO] Validation perplexity: 34.5303\n","[2021-04-09 15:43:20,975 INFO] Validation accuracy: 53.5799\n","[2021-04-09 15:43:21,143 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-09 15:44:22,559 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:44:26,072 INFO] number of examples: 77471\n","[2021-04-09 15:46:32,604 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:46:35,692 INFO] number of examples: 77471\n","[2021-04-09 15:48:42,262 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:48:45,229 INFO] number of examples: 77471\n","[2021-04-09 15:50:52,042 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:50:55,482 INFO] number of examples: 77471\n","[2021-04-09 15:53:02,027 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:53:04,996 INFO] number of examples: 77471\n","[2021-04-09 15:53:17,125 INFO] Step 24000/30000; acc:  98.95; ppl:  1.11; xent: 0.10; lr: 0.00057; 9982/12498 tok/s;  14657 sec\n","[2021-04-09 15:53:17,126 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:53:17,971 INFO] number of examples: 10362\n","[2021-04-09 15:53:34,622 INFO] Validation perplexity: 35.9349\n","[2021-04-09 15:53:34,622 INFO] Validation accuracy: 53.3089\n","[2021-04-09 15:53:34,788 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-09 15:55:33,179 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:55:37,242 INFO] number of examples: 77471\n","[2021-04-09 15:57:43,817 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:57:46,983 INFO] number of examples: 77471\n","[2021-04-09 15:59:53,516 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:59:56,673 INFO] number of examples: 77471\n","[2021-04-09 16:02:03,495 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:02:06,716 INFO] number of examples: 77471\n","[2021-04-09 16:03:27,670 INFO] Step 25000/30000; acc:  99.02; ppl:  1.10; xent: 0.10; lr: 0.00056; 10011/12565 tok/s;  15268 sec\n","[2021-04-09 16:03:27,671 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 16:03:27,965 INFO] number of examples: 10362\n","[2021-04-09 16:03:44,737 INFO] Validation perplexity: 36.4785\n","[2021-04-09 16:03:44,738 INFO] Validation accuracy: 53.6175\n","[2021-04-09 16:03:44,910 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-09 16:04:35,166 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:04:38,213 INFO] number of examples: 77471\n","[2021-04-09 16:06:45,112 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:06:48,577 INFO] number of examples: 77471\n","[2021-04-09 16:08:55,137 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:08:58,683 INFO] number of examples: 77471\n","[2021-04-09 16:11:05,176 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:11:08,264 INFO] number of examples: 77471\n","[2021-04-09 16:13:14,765 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:13:17,764 INFO] number of examples: 77471\n","[2021-04-09 16:13:41,229 INFO] Step 26000/30000; acc:  99.08; ppl:  1.10; xent: 0.09; lr: 0.00055; 9969/12490 tok/s;  15881 sec\n","[2021-04-09 16:13:41,231 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 16:13:41,527 INFO] number of examples: 10362\n","[2021-04-09 16:13:58,161 INFO] Validation perplexity: 36.0436\n","[2021-04-09 16:13:58,162 INFO] Validation accuracy: 53.7385\n","[2021-04-09 16:13:58,329 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-09 16:15:45,141 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:15:48,519 INFO] number of examples: 77471\n","[2021-04-09 16:17:55,012 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:17:58,513 INFO] number of examples: 77471\n","[2021-04-09 16:20:05,012 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:20:08,111 INFO] number of examples: 77471\n","[2021-04-09 16:22:14,682 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:22:17,687 INFO] number of examples: 77471\n","[2021-04-09 16:23:49,689 INFO] Step 27000/30000; acc:  99.13; ppl:  1.09; xent: 0.09; lr: 0.00054; 10050/12608 tok/s;  16490 sec\n","[2021-04-09 16:23:49,690 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 16:23:49,979 INFO] number of examples: 10362\n","[2021-04-09 16:24:06,610 INFO] Validation perplexity: 35.8659\n","[2021-04-09 16:24:06,610 INFO] Validation accuracy: 53.4988\n","[2021-04-09 16:24:06,778 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-09 16:24:45,115 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:24:48,481 INFO] number of examples: 77471\n","[2021-04-09 16:26:54,915 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:26:58,451 INFO] number of examples: 77471\n","[2021-04-09 16:29:04,942 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:29:08,031 INFO] number of examples: 77471\n","[2021-04-09 16:31:14,557 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:31:17,567 INFO] number of examples: 77471\n","[2021-04-09 16:33:24,267 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:33:27,751 INFO] number of examples: 77471\n","[2021-04-09 16:34:02,586 INFO] Step 28000/30000; acc:  99.19; ppl:  1.09; xent: 0.09; lr: 0.00053; 9974/12504 tok/s;  17103 sec\n","[2021-04-09 16:34:02,587 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 16:34:02,881 INFO] number of examples: 10362\n","[2021-04-09 16:34:19,521 INFO] Validation perplexity: 35.8221\n","[2021-04-09 16:34:19,521 INFO] Validation accuracy: 53.6077\n","[2021-04-09 16:34:19,688 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-09 16:35:55,611 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:35:59,139 INFO] number of examples: 77471\n","[2021-04-09 16:38:05,699 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:38:08,795 INFO] number of examples: 77471\n","[2021-04-09 16:40:15,340 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:40:18,310 INFO] number of examples: 77471\n","[2021-04-09 16:42:24,844 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:42:28,268 INFO] number of examples: 77471\n","[2021-04-09 16:44:11,632 INFO] Step 29000/30000; acc:  99.22; ppl:  1.09; xent: 0.08; lr: 0.00052; 10039/12590 tok/s;  17712 sec\n","[2021-04-09 16:44:11,633 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 16:44:11,921 INFO] number of examples: 10362\n","[2021-04-09 16:44:28,558 INFO] Validation perplexity: 37.2913\n","[2021-04-09 16:44:28,558 INFO] Validation accuracy: 53.5654\n","[2021-04-09 16:44:28,728 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-09 16:44:56,918 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:45:00,413 INFO] number of examples: 77471\n","[2021-04-09 16:47:06,923 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:47:09,932 INFO] number of examples: 77471\n","[2021-04-09 16:49:16,447 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:49:19,999 INFO] number of examples: 77471\n","[2021-04-09 16:51:26,445 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:51:29,552 INFO] number of examples: 77471\n","[2021-04-09 16:53:36,075 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:53:39,119 INFO] number of examples: 77471\n","[2021-04-09 16:54:25,332 INFO] Step 30000/30000; acc:  99.25; ppl:  1.09; xent: 0.08; lr: 0.00051; 9967/12500 tok/s;  18325 sec\n","[2021-04-09 16:54:25,333 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 16:54:25,643 INFO] number of examples: 10362\n","[2021-04-09 16:54:42,282 INFO] Validation perplexity: 37.1696\n","[2021-04-09 16:54:42,282 INFO] Validation accuracy: 53.6782\n","[2021-04-09 16:54:42,459 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617987288118,"user_tz":-420,"elapsed":18402079,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"86636de3-1281-421b-e830-90d2fbaff80d"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 29953350\n","-rw------- 1 root root 1022407295 Apr  9 13:30 en-vi_step_10000.pt\n","-rw------- 1 root root 1022407295 Apr  9 11:59 en-vi_step_1000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:41 en-vi_step_11000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:51 en-vi_step_12000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:01 en-vi_step_13000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:11 en-vi_step_14000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:21 en-vi_step_15000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:32 en-vi_step_16000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:42 en-vi_step_17000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:52 en-vi_step_18000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:02 en-vi_step_19000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:12 en-vi_step_20000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:09 en-vi_step_2000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:23 en-vi_step_21000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:33 en-vi_step_22000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:43 en-vi_step_23000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:53 en-vi_step_24000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:03 en-vi_step_25000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:14 en-vi_step_26000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:24 en-vi_step_27000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:34 en-vi_step_28000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:44 en-vi_step_29000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:54 en-vi_step_30000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:19 en-vi_step_3000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:29 en-vi_step_4000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:39 en-vi_step_5000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:50 en-vi_step_6000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:00 en-vi_step_7000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:10 en-vi_step_8000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:20 en-vi_step_9000.pt\n","\n","model/:\n","total 29953350\n","-rw------- 1 root root 1022407295 Apr  9 13:30 en-vi_step_10000.pt\n","-rw------- 1 root root 1022407295 Apr  9 11:59 en-vi_step_1000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:41 en-vi_step_11000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:51 en-vi_step_12000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:01 en-vi_step_13000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:11 en-vi_step_14000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:21 en-vi_step_15000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:32 en-vi_step_16000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:42 en-vi_step_17000.pt\n","-rw------- 1 root root 1022407295 Apr  9 14:52 en-vi_step_18000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:02 en-vi_step_19000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:12 en-vi_step_20000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:09 en-vi_step_2000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:23 en-vi_step_21000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:33 en-vi_step_22000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:43 en-vi_step_23000.pt\n","-rw------- 1 root root 1022407295 Apr  9 15:53 en-vi_step_24000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:03 en-vi_step_25000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:14 en-vi_step_26000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:24 en-vi_step_27000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:34 en-vi_step_28000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:44 en-vi_step_29000.pt\n","-rw------- 1 root root 1022407295 Apr  9 16:54 en-vi_step_30000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:19 en-vi_step_3000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:29 en-vi_step_4000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:39 en-vi_step_5000.pt\n","-rw------- 1 root root 1022407295 Apr  9 12:50 en-vi_step_6000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:00 en-vi_step_7000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:10 en-vi_step_8000.pt\n","-rw------- 1 root root 1022407295 Apr  9 13:20 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617989691238,"user_tz":-420,"elapsed":20805198,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"1a9dd9e9-f33b-49c3-8bc1-47c9c94e79d0"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-09 16:54:53,948 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-09 17:33:30,142 INFO] PRED AVG SCORE: -0.4503, PRED PPL: 1.5687\n","[2021-04-09 17:33:30,142 INFO] GOLD AVG SCORE: -3.6273, GOLD PPL: 37.6110\n","[2021-04-09 17:33:30,166 INFO] Translating shard 1.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-09 17:34:50,450 INFO] PRED AVG SCORE: -0.4513, PRED PPL: 1.5704\n","[2021-04-09 17:34:50,450 INFO] GOLD AVG SCORE: -3.5739, GOLD PPL: 35.6571\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617989691239,"user_tz":-420,"elapsed":20805197,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"7310ad5f-404a-4b3e-c5ec-f493ffc16ff8"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cà vạt thì loè loẹt .\n","và lí do là bởi vì có 2 lí do , theo tôi nghĩ\n","Ông thích nói về thiên tài tâm linh của lứa tuổi .\n","Chúng tôi đều là người Triều Tiên , nhưng đã trở nên rất khác nhau do hậu quả của 67 năm bị chia cắt .\n","Đó là cách bạn xử lý một vấn đề khi bạn nhìn thấy chúng và đó không chỉ là việc than phiền về vấn đề đó .\n","Tham vọng của các bạn được thoã mãn , nó rất đẹp .\n","Không có thứ nào trong những điều trên thực sự hữu ích bởi vì bạn đang điều trị những triệu chứng chứ không phải nguyên nhân của các vấn đề cơ bản ở Phi Châu .\n","Nhưng hiện nay nhiều người sống đến 90 hay 100 tuổi , trừ khi họ bắt tay quá nhiều hay làm những điều đại loại thế .\n","Nhưng quý vị phải có những công cụ đúng .\n","Những điều này là một phần cuộc đời ông và là những gì ông còn nhớ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617989709550,"user_tz":-420,"elapsed":20823507,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"029cad14-08f3-4c41-c69b-617841a47439"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 32, done.\u001b[K\n","remote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (27/27), done.\u001b[K\n","remote: Total 17114 (delta 8), reused 11 (delta 4), pack-reused 17082\u001b[K\n","Receiving objects: 100% (17114/17114), 273.03 MiB | 23.83 MiB/s, done.\n","Resolving deltas: 100% (12332/12332), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617989710096,"user_tz":-420,"elapsed":20824052,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"cff167ad-ec8b-48b3-f765-13ac4c14c063"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 93602\n","drwx------  2 root root     4096 Apr  9 11:48 data_bin\n","-rw-------  1 root root   996149 Apr  9 11:16 en_test\n","-rw-------  1 root root  8024744 Apr  9 11:16 en_train\n","-rw-------  1 root root  8161362 Apr  9 11:42 en_train_EM_0.8\n","-rw-------  1 root root  8075706 Apr  9 11:42 en_train_EM_0.85\n","-rw-------  1 root root  8040373 Apr  9 11:42 en_train_EM_0.9\n","-rw-------  1 root root  8026272 Apr  9 11:42 en_train_EM_0.95\n","-rw-------  1 root root  3303720 Apr  9 11:42 en_train_EM_factor_0.8\n","-rw-------  1 root root  3268996 Apr  9 11:42 en_train_EM_factor_0.85\n","-rw-------  1 root root  3254332 Apr  9 11:42 en_train_EM_factor_0.9\n","-rw-------  1 root root  3248468 Apr  9 11:42 en_train_EM_factor_0.95\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.8\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.85\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.9\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.95\n","-rw-------  1 root root  1000856 Apr  9 11:16 en_valid\n","-rw-------  1 root root 22435544 Apr  9 11:48 en_vi_iwslt_bert.tar.gz\n","drwx------  2 root root     4096 Apr  9 16:54 model\n","drwx------ 11 root root     4096 Apr  9 17:35 OpenNMT-py\n","drwx------  2 root root     4096 Apr  9 11:48 output\n","-rw-------  1 root root  1221540 Apr  9 17:34 predict.txt\n","-rw-------  1 root root  1327417 Apr  9 11:16 vi_test\n","-rw-------  1 root root 10671354 Apr  9 11:16 vi_train\n","-rw-------  1 root root  1330789 Apr  9 11:16 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617989712029,"user_tz":-420,"elapsed":20825983,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"0ac48612-f085-4705-fe03-b679ec7d1d65"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 23.84, 58.7/32.9/19.3/11.7 (BP=0.928, ratio=0.930, hyp_len=227151, ref_len=244219)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1617989712030,"user_tz":-420,"elapsed":20825983,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}