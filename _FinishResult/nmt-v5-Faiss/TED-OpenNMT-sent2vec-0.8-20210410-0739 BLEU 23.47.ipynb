{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TED-OpenNMT-sent2vec-0.8-20210410-0739 BLEU 23.47.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040364772,"user_tz":-420,"elapsed":24344,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"ce713f7e-2781-44f5-c24b-340ad32eb03e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040366333,"user_tz":-420,"elapsed":25902,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e04dbaff-b8bc-4b77-e89f-a299323c631a"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"TED-OpenNMT-sent2vec-0.8-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v3/OpenNMT-TED-EM-bert-ratio-8-2-2-20210128-0637'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/TED-OpenNMT-sent2vec-0.8-20210410-0739\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040366333,"user_tz":-420,"elapsed":25900,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"c1c611aa-0845-494e-e550-0bd3350be275"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Sat Apr 10 07:39:25 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040382702,"user_tz":-420,"elapsed":42268,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"64eb5cd1-0e1b-43cd-98af-c519501fecec"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 7.9MB/s \n","\u001b[?25hCollecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 13.7MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Collecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Collecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=994f84500cf54e54036a50b0c7bfd0de6689d5455c915405e3f166289feb0704\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: pyonmttok, waitress, torchtext, configargparse, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 6.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040385076,"user_tz":-420,"elapsed":44641,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"76e2e9df-a8dd-4713-f20f-56b6baf44d54"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_sent2vec.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'en_vi_iwslt_sent2vec.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-10 07:39:42--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_sent2vec.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22512408 (21M) [application/octet-stream]\n","Saving to: ‘en_vi_iwslt_sent2vec.tar.gz’\n","\n","en_vi_iwslt_sent2ve 100%[===================>]  21.47M  57.0MB/s    in 0.4s    \n","\n","2021-04-10 07:39:43 (57.0 MB/s) - ‘en_vi_iwslt_sent2vec.tar.gz’ saved [22512408/22512408]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618040399609,"user_tz":-420,"elapsed":59172,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"d183c819-9026-4dbe-ed73-9f4a9dff9864"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.8' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-10 07:39:48,319 INFO] Extracting features...\n","[2021-04-10 07:39:48,322 INFO]  * number of source features: 0.\n","[2021-04-10 07:39:48,323 INFO]  * number of target features: 0.\n","[2021-04-10 07:39:48,323 INFO] Building `Fields` object...\n","[2021-04-10 07:39:48,323 INFO] Building & saving training data...\n","[2021-04-10 07:39:48,513 INFO] Building shard 0.\n","[2021-04-10 07:39:52,798 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-10 07:39:56,516 INFO]  * tgt vocab size: 18250.\n","[2021-04-10 07:39:56,577 INFO]  * src vocab size: 41040.\n","[2021-04-10 07:39:56,805 INFO] Building & saving validation data...\n","[2021-04-10 07:39:56,926 INFO] Building shard 0.\n","[2021-04-10 07:39:57,221 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618059320061,"user_tz":-420,"elapsed":18979623,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"54540bb2-c3fb-4b9a-89d8-9185629448b9"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-10 07:40:00,760 INFO]  * src vocab size = 41040\n","[2021-04-10 07:40:00,760 INFO]  * tgt vocab size = 18250\n","[2021-04-10 07:40:00,760 INFO] Building model...\n","[2021-04-10 07:40:08,377 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(41040, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(18250, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=18250, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-10 07:40:08,422 INFO] encoder: 39927808\n","[2021-04-10 07:40:08,423 INFO] decoder: 43931466\n","[2021-04-10 07:40:08,423 INFO] * number of parameters: 83859274\n","[2021-04-10 07:40:08,428 INFO] Starting training on GPU: [0]\n","[2021-04-10 07:40:08,428 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-10 07:40:08,428 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:40:11,589 INFO] number of examples: 77471\n","[2021-04-10 07:42:24,229 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:42:28,035 INFO] number of examples: 77471\n","[2021-04-10 07:44:41,287 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:44:44,575 INFO] number of examples: 77471\n","[2021-04-10 07:46:56,998 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:47:00,685 INFO] number of examples: 77471\n","[2021-04-10 07:49:13,695 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:49:17,468 INFO] number of examples: 77471\n","[2021-04-10 07:50:18,155 INFO] Step 1000/30000; acc:  13.66; ppl: 252.37; xent: 5.53; lr: 0.00012; 10075/12311 tok/s;    610 sec\n","[2021-04-10 07:50:18,156 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 07:50:18,946 INFO] number of examples: 10362\n","[2021-04-10 07:50:35,823 INFO] Validation perplexity: 99.9851\n","[2021-04-10 07:50:35,823 INFO] Validation accuracy: 26.6012\n","[2021-04-10 07:50:36,034 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-10 07:51:52,549 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:51:56,015 INFO] number of examples: 77471\n","[2021-04-10 07:54:09,130 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:54:13,108 INFO] number of examples: 77471\n","[2021-04-10 07:56:25,682 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:56:29,203 INFO] number of examples: 77471\n","[2021-04-10 07:58:42,315 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 07:58:46,322 INFO] number of examples: 77471\n","[2021-04-10 08:00:47,031 INFO] Step 2000/30000; acc:  40.49; ppl: 20.88; xent: 3.04; lr: 0.00025; 9781/11956 tok/s;   1239 sec\n","[2021-04-10 08:00:47,033 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:00:47,383 INFO] number of examples: 10362\n","[2021-04-10 08:01:04,290 INFO] Validation perplexity: 22.9734\n","[2021-04-10 08:01:04,290 INFO] Validation accuracy: 45.6177\n","[2021-04-10 08:01:04,506 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-10 08:01:20,859 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:01:25,419 INFO] number of examples: 77471\n","[2021-04-10 08:03:38,594 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:03:42,846 INFO] number of examples: 77471\n","[2021-04-10 08:05:55,297 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:05:59,053 INFO] number of examples: 77471\n","[2021-04-10 08:08:12,087 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:08:15,766 INFO] number of examples: 77471\n","[2021-04-10 08:10:28,229 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:10:31,855 INFO] number of examples: 77471\n","[2021-04-10 08:11:20,930 INFO] Step 3000/30000; acc:  57.02; ppl:  6.82; xent: 1.92; lr: 0.00037; 9699/11854 tok/s;   1873 sec\n","[2021-04-10 08:11:20,932 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:11:21,893 INFO] number of examples: 10362\n","[2021-04-10 08:11:38,801 INFO] Validation perplexity: 15.7473\n","[2021-04-10 08:11:38,801 INFO] Validation accuracy: 50.6695\n","[2021-04-10 08:11:39,021 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-10 08:13:07,663 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:13:12,499 INFO] number of examples: 77471\n","[2021-04-10 08:15:24,974 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:15:28,772 INFO] number of examples: 77471\n","[2021-04-10 08:17:41,793 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:17:45,580 INFO] number of examples: 77471\n","[2021-04-10 08:19:57,967 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:20:01,689 INFO] number of examples: 77471\n","[2021-04-10 08:21:50,450 INFO] Step 4000/30000; acc:  65.28; ppl:  4.18; xent: 1.43; lr: 0.00049; 9766/11926 tok/s;   2502 sec\n","[2021-04-10 08:21:50,451 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:21:50,809 INFO] number of examples: 10362\n","[2021-04-10 08:22:07,708 INFO] Validation perplexity: 16.4758\n","[2021-04-10 08:22:07,708 INFO] Validation accuracy: 51.475\n","[2021-04-10 08:22:07,916 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-10 08:22:36,805 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:22:41,019 INFO] number of examples: 77471\n","[2021-04-10 08:24:53,630 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:24:57,343 INFO] number of examples: 77471\n","[2021-04-10 08:27:10,778 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:27:15,057 INFO] number of examples: 77471\n","[2021-04-10 08:29:27,914 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:29:31,582 INFO] number of examples: 77471\n","[2021-04-10 08:31:44,502 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:31:48,659 INFO] number of examples: 77471\n","[2021-04-10 08:32:25,224 INFO] Step 5000/30000; acc:  71.56; ppl:  3.06; xent: 1.12; lr: 0.00062; 9686/11851 tok/s;   3137 sec\n","[2021-04-10 08:32:25,225 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:32:25,580 INFO] number of examples: 10362\n","[2021-04-10 08:32:42,443 INFO] Validation perplexity: 18.2677\n","[2021-04-10 08:32:42,443 INFO] Validation accuracy: 51.4354\n","[2021-04-10 08:32:42,650 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-10 08:34:22,930 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:34:27,217 INFO] number of examples: 77471\n","[2021-04-10 08:36:40,029 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:36:43,639 INFO] number of examples: 77471\n","[2021-04-10 08:38:55,873 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:38:59,478 INFO] number of examples: 77471\n","[2021-04-10 08:41:12,260 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:41:16,350 INFO] number of examples: 77471\n","[2021-04-10 08:42:52,623 INFO] Step 6000/30000; acc:  76.78; ppl:  2.44; xent: 0.89; lr: 0.00074; 9796/11963 tok/s;   3764 sec\n","[2021-04-10 08:42:52,624 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:42:52,972 INFO] number of examples: 10362\n","[2021-04-10 08:43:09,842 INFO] Validation perplexity: 20.881\n","[2021-04-10 08:43:09,842 INFO] Validation accuracy: 51.6117\n","[2021-04-10 08:43:10,048 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-10 08:43:50,683 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:43:54,925 INFO] number of examples: 77471\n","[2021-04-10 08:46:07,695 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:46:11,383 INFO] number of examples: 77471\n","[2021-04-10 08:48:23,653 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:48:27,227 INFO] number of examples: 77471\n","[2021-04-10 08:50:40,056 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:50:44,098 INFO] number of examples: 77471\n","[2021-04-10 08:52:56,298 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:53:00,568 INFO] number of examples: 77471\n","[2021-04-10 08:53:25,428 INFO] Step 7000/30000; acc:  81.19; ppl:  2.06; xent: 0.72; lr: 0.00086; 9725/11888 tok/s;   4397 sec\n","[2021-04-10 08:53:25,429 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 08:53:25,792 INFO] number of examples: 10362\n","[2021-04-10 08:53:42,656 INFO] Validation perplexity: 23.5678\n","[2021-04-10 08:53:42,656 INFO] Validation accuracy: 51.4531\n","[2021-04-10 08:53:42,861 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-10 08:55:35,682 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:55:39,272 INFO] number of examples: 77471\n","[2021-04-10 08:57:51,541 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 08:57:55,663 INFO] number of examples: 77471\n","[2021-04-10 09:00:08,475 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:00:12,105 INFO] number of examples: 77471\n","[2021-04-10 09:02:24,339 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:02:28,492 INFO] number of examples: 77471\n","[2021-04-10 09:03:53,057 INFO] Step 8000/30000; acc:  84.18; ppl:  1.84; xent: 0.61; lr: 0.00099; 9786/11957 tok/s;   5025 sec\n","[2021-04-10 09:03:53,059 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:03:53,413 INFO] number of examples: 10362\n","[2021-04-10 09:04:10,281 INFO] Validation perplexity: 25.3559\n","[2021-04-10 09:04:10,281 INFO] Validation accuracy: 51.1977\n","[2021-04-10 09:04:10,491 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-10 09:05:03,354 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:05:07,624 INFO] number of examples: 77471\n","[2021-04-10 09:07:19,836 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:07:23,564 INFO] number of examples: 77471\n","[2021-04-10 09:09:36,360 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:09:39,978 INFO] number of examples: 77471\n","[2021-04-10 09:11:52,095 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:11:56,283 INFO] number of examples: 77471\n","[2021-04-10 09:14:08,999 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:14:12,658 INFO] number of examples: 77471\n","[2021-04-10 09:14:25,147 INFO] Step 9000/30000; acc:  87.48; ppl:  1.65; xent: 0.50; lr: 0.00093; 9735/11902 tok/s;   5657 sec\n","[2021-04-10 09:14:25,149 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:14:25,516 INFO] number of examples: 10362\n","[2021-04-10 09:14:42,396 INFO] Validation perplexity: 26.1775\n","[2021-04-10 09:14:42,396 INFO] Validation accuracy: 51.9829\n","[2021-04-10 09:14:42,599 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-10 09:16:46,797 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:16:50,963 INFO] number of examples: 77471\n","[2021-04-10 09:19:03,672 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:19:07,291 INFO] number of examples: 77471\n","[2021-04-10 09:21:19,496 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:21:23,706 INFO] number of examples: 77471\n","[2021-04-10 09:23:36,381 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:23:40,032 INFO] number of examples: 77471\n","[2021-04-10 09:24:52,572 INFO] Step 10000/30000; acc:  91.03; ppl:  1.48; xent: 0.39; lr: 0.00088; 9793/11965 tok/s;   6284 sec\n","[2021-04-10 09:24:52,573 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:24:52,934 INFO] number of examples: 10362\n","[2021-04-10 09:25:09,804 INFO] Validation perplexity: 27.5195\n","[2021-04-10 09:25:09,804 INFO] Validation accuracy: 52.3894\n","[2021-04-10 09:25:10,015 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-10 09:26:14,445 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:26:18,645 INFO] number of examples: 77471\n","[2021-04-10 09:28:31,437 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:28:35,023 INFO] number of examples: 77471\n","[2021-04-10 09:30:47,207 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:30:51,401 INFO] number of examples: 77471\n","[2021-04-10 09:33:04,210 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:33:07,920 INFO] number of examples: 77471\n","[2021-04-10 09:35:20,135 INFO] Step 11000/30000; acc:  93.30; ppl:  1.37; xent: 0.32; lr: 0.00084; 9805/11989 tok/s;   6912 sec\n","[2021-04-10 09:35:20,136 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:35:20,492 INFO] number of examples: 10362\n","[2021-04-10 09:35:37,361 INFO] Validation perplexity: 32.0999\n","[2021-04-10 09:35:37,362 INFO] Validation accuracy: 51.7229\n","[2021-04-10 09:35:37,569 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-10 09:35:41,797 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:35:45,950 INFO] number of examples: 77471\n","[2021-04-10 09:37:59,026 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:38:02,732 INFO] number of examples: 77471\n","[2021-04-10 09:40:14,948 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:40:18,534 INFO] number of examples: 77471\n","[2021-04-10 09:42:31,323 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:42:35,384 INFO] number of examples: 77471\n","[2021-04-10 09:44:47,545 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:44:51,795 INFO] number of examples: 77471\n","[2021-04-10 09:45:52,397 INFO] Step 12000/30000; acc:  94.82; ppl:  1.31; xent: 0.27; lr: 0.00081; 9717/11877 tok/s;   7544 sec\n","[2021-04-10 09:45:52,399 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:45:52,760 INFO] number of examples: 10362\n","[2021-04-10 09:46:09,638 INFO] Validation perplexity: 30.555\n","[2021-04-10 09:46:09,638 INFO] Validation accuracy: 52.6533\n","[2021-04-10 09:46:09,845 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-10 09:47:26,725 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:47:30,350 INFO] number of examples: 77471\n","[2021-04-10 09:49:42,548 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:49:46,671 INFO] number of examples: 77471\n","[2021-04-10 09:51:59,433 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:52:03,053 INFO] number of examples: 77471\n","[2021-04-10 09:54:15,278 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:54:19,457 INFO] number of examples: 77471\n","[2021-04-10 09:56:19,840 INFO] Step 13000/30000; acc:  95.80; ppl:  1.27; xent: 0.24; lr: 0.00078; 9802/11979 tok/s;   8171 sec\n","[2021-04-10 09:56:19,841 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 09:56:20,196 INFO] number of examples: 10362\n","[2021-04-10 09:56:37,055 INFO] Validation perplexity: 31.74\n","[2021-04-10 09:56:37,055 INFO] Validation accuracy: 52.8922\n","[2021-04-10 09:56:37,256 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-10 09:56:54,190 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:56:59,152 INFO] number of examples: 77471\n","[2021-04-10 09:59:11,342 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 09:59:15,124 INFO] number of examples: 77471\n","[2021-04-10 10:01:28,012 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:01:31,620 INFO] number of examples: 77471\n","[2021-04-10 10:03:43,799 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:03:48,046 INFO] number of examples: 77471\n","[2021-04-10 10:06:00,859 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:06:04,542 INFO] number of examples: 77471\n","[2021-04-10 10:06:52,884 INFO] Step 14000/30000; acc:  96.58; ppl:  1.23; xent: 0.21; lr: 0.00075; 9711/11870 tok/s;   8804 sec\n","[2021-04-10 10:06:52,886 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:06:53,247 INFO] number of examples: 10362\n","[2021-04-10 10:07:10,110 INFO] Validation perplexity: 30.6954\n","[2021-04-10 10:07:10,111 INFO] Validation accuracy: 53.1217\n","[2021-04-10 10:07:10,321 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-10 10:08:39,205 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:08:43,432 INFO] number of examples: 77471\n","[2021-04-10 10:10:56,183 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:10:59,832 INFO] number of examples: 77471\n","[2021-04-10 10:13:12,006 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:13:16,286 INFO] number of examples: 77471\n","[2021-04-10 10:15:29,036 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:15:32,753 INFO] number of examples: 77471\n","[2021-04-10 10:17:20,682 INFO] Step 15000/30000; acc:  97.13; ppl:  1.21; xent: 0.19; lr: 0.00072; 9792/11960 tok/s;   9432 sec\n","[2021-04-10 10:17:20,683 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:17:21,048 INFO] number of examples: 10362\n","[2021-04-10 10:17:37,941 INFO] Validation perplexity: 31.7085\n","[2021-04-10 10:17:37,941 INFO] Validation accuracy: 53.1213\n","[2021-04-10 10:17:38,148 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-10 10:18:06,846 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:18:10,416 INFO] number of examples: 77471\n","[2021-04-10 10:20:23,202 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:20:27,256 INFO] number of examples: 77471\n","[2021-04-10 10:22:39,475 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:22:43,766 INFO] number of examples: 77471\n","[2021-04-10 10:24:56,657 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:25:00,474 INFO] number of examples: 77471\n","[2021-04-10 10:27:12,780 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:27:16,522 INFO] number of examples: 77471\n","[2021-04-10 10:27:53,146 INFO] Step 16000/30000; acc:  97.52; ppl:  1.19; xent: 0.17; lr: 0.00070; 9723/11893 tok/s;  10065 sec\n","[2021-04-10 10:27:53,147 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:27:53,523 INFO] number of examples: 10362\n","[2021-04-10 10:28:10,389 INFO] Validation perplexity: 31.2741\n","[2021-04-10 10:28:10,389 INFO] Validation accuracy: 53.3794\n","[2021-04-10 10:28:10,597 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-10 10:29:51,643 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:29:55,871 INFO] number of examples: 77471\n","[2021-04-10 10:32:08,163 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:32:11,888 INFO] number of examples: 77471\n","[2021-04-10 10:34:24,868 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:34:29,197 INFO] number of examples: 77471\n","[2021-04-10 10:36:41,514 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:36:45,307 INFO] number of examples: 77471\n","[2021-04-10 10:38:21,677 INFO] Step 17000/30000; acc:  97.86; ppl:  1.17; xent: 0.16; lr: 0.00068; 9777/11941 tok/s;  10693 sec\n","[2021-04-10 10:38:21,678 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:38:22,035 INFO] number of examples: 10362\n","[2021-04-10 10:38:38,904 INFO] Validation perplexity: 32.3977\n","[2021-04-10 10:38:38,904 INFO] Validation accuracy: 53.231\n","[2021-04-10 10:38:39,111 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-10 10:39:20,505 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:39:24,115 INFO] number of examples: 77471\n","[2021-04-10 10:41:36,426 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:41:40,529 INFO] number of examples: 77471\n","[2021-04-10 10:43:53,386 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:43:57,680 INFO] number of examples: 77471\n","[2021-04-10 10:46:10,005 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:46:13,760 INFO] number of examples: 77471\n","[2021-04-10 10:48:26,677 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:48:30,363 INFO] number of examples: 77471\n","[2021-04-10 10:48:54,580 INFO] Step 18000/30000; acc:  98.12; ppl:  1.16; xent: 0.15; lr: 0.00066; 9723/11886 tok/s;  11326 sec\n","[2021-04-10 10:48:54,582 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:48:54,946 INFO] number of examples: 10362\n","[2021-04-10 10:49:11,825 INFO] Validation perplexity: 34.5247\n","[2021-04-10 10:49:11,825 INFO] Validation accuracy: 53.3116\n","[2021-04-10 10:49:12,033 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-10 10:51:04,730 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:51:08,797 INFO] number of examples: 77471\n","[2021-04-10 10:53:21,589 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:53:25,842 INFO] number of examples: 77471\n","[2021-04-10 10:55:38,091 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:55:41,791 INFO] number of examples: 77471\n","[2021-04-10 10:57:54,579 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 10:57:58,239 INFO] number of examples: 77471\n","[2021-04-10 10:59:22,239 INFO] Step 19000/30000; acc:  98.32; ppl:  1.14; xent: 0.14; lr: 0.00064; 9787/11956 tok/s;  11954 sec\n","[2021-04-10 10:59:22,241 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 10:59:23,236 INFO] number of examples: 10362\n","[2021-04-10 10:59:40,109 INFO] Validation perplexity: 34.3605\n","[2021-04-10 10:59:40,110 INFO] Validation accuracy: 53.269\n","[2021-04-10 10:59:40,315 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-10 11:00:33,323 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:00:37,319 INFO] number of examples: 77471\n","[2021-04-10 11:02:50,213 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:02:54,438 INFO] number of examples: 77471\n","[2021-04-10 11:05:06,700 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:05:10,402 INFO] number of examples: 77471\n","[2021-04-10 11:07:23,168 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:07:26,792 INFO] number of examples: 77471\n","[2021-04-10 11:09:39,028 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:09:43,172 INFO] number of examples: 77471\n","[2021-04-10 11:09:55,708 INFO] Step 20000/30000; acc:  98.46; ppl:  1.14; xent: 0.13; lr: 0.00062; 9715/11876 tok/s;  12587 sec\n","[2021-04-10 11:09:55,709 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:09:56,081 INFO] number of examples: 10362\n","[2021-04-10 11:10:12,954 INFO] Validation perplexity: 35.9639\n","[2021-04-10 11:10:12,954 INFO] Validation accuracy: 52.7023\n","[2021-04-10 11:10:13,157 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-10 11:12:18,163 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:12:22,391 INFO] number of examples: 77471\n","[2021-04-10 11:14:34,673 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:14:38,371 INFO] number of examples: 77471\n","[2021-04-10 11:16:51,193 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:16:54,831 INFO] number of examples: 77471\n","[2021-04-10 11:19:06,999 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:19:11,040 INFO] number of examples: 77471\n","[2021-04-10 11:20:23,502 INFO] Step 21000/30000; acc:  98.61; ppl:  1.13; xent: 0.12; lr: 0.00061; 9789/11962 tok/s;  13215 sec\n","[2021-04-10 11:20:23,503 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:20:23,867 INFO] number of examples: 10362\n","[2021-04-10 11:20:40,730 INFO] Validation perplexity: 35.8816\n","[2021-04-10 11:20:40,731 INFO] Validation accuracy: 53.3649\n","[2021-04-10 11:20:40,944 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-10 11:21:46,635 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:21:50,734 INFO] number of examples: 77471\n","[2021-04-10 11:24:02,893 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:24:07,149 INFO] number of examples: 77471\n","[2021-04-10 11:26:19,871 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:26:23,607 INFO] number of examples: 77471\n","[2021-04-10 11:28:35,719 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:28:39,335 INFO] number of examples: 77471\n","[2021-04-10 11:30:51,470 INFO] Step 22000/30000; acc:  98.72; ppl:  1.12; xent: 0.11; lr: 0.00060; 9798/11978 tok/s;  13843 sec\n","[2021-04-10 11:30:51,471 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:30:51,838 INFO] number of examples: 10362\n","[2021-04-10 11:31:08,686 INFO] Validation perplexity: 35.7509\n","[2021-04-10 11:31:08,686 INFO] Validation accuracy: 53.4295\n","[2021-04-10 11:31:08,895 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-10 11:31:13,762 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:31:17,909 INFO] number of examples: 77471\n","[2021-04-10 11:33:30,398 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:33:34,611 INFO] number of examples: 77471\n","[2021-04-10 11:35:47,349 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:35:51,075 INFO] number of examples: 77471\n","[2021-04-10 11:38:03,316 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:38:06,910 INFO] number of examples: 77471\n","[2021-04-10 11:40:19,657 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:40:23,851 INFO] number of examples: 77471\n","[2021-04-10 11:41:23,909 INFO] Step 23000/30000; acc:  98.84; ppl:  1.11; xent: 0.11; lr: 0.00058; 9713/11874 tok/s;  14475 sec\n","[2021-04-10 11:41:23,910 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:41:24,276 INFO] number of examples: 10362\n","[2021-04-10 11:41:41,139 INFO] Validation perplexity: 36.0198\n","[2021-04-10 11:41:41,139 INFO] Validation accuracy: 53.2141\n","[2021-04-10 11:41:41,349 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-10 11:42:58,339 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:43:01,967 INFO] number of examples: 77471\n","[2021-04-10 11:45:14,807 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:45:18,875 INFO] number of examples: 77471\n","[2021-04-10 11:47:31,080 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:47:35,315 INFO] number of examples: 77471\n","[2021-04-10 11:49:48,057 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:49:51,769 INFO] number of examples: 77471\n","[2021-04-10 11:51:51,600 INFO] Step 24000/30000; acc:  98.91; ppl:  1.11; xent: 0.10; lr: 0.00057; 9798/11974 tok/s;  15103 sec\n","[2021-04-10 11:51:51,602 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 11:51:51,970 INFO] number of examples: 10362\n","[2021-04-10 11:52:08,826 INFO] Validation perplexity: 35.9797\n","[2021-04-10 11:52:08,826 INFO] Validation accuracy: 53.3896\n","[2021-04-10 11:52:09,033 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-10 11:52:26,018 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:52:31,269 INFO] number of examples: 77471\n","[2021-04-10 11:54:44,203 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:54:47,987 INFO] number of examples: 77471\n","[2021-04-10 11:57:00,214 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:57:03,883 INFO] number of examples: 77471\n","[2021-04-10 11:59:16,682 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 11:59:20,932 INFO] number of examples: 77471\n","[2021-04-10 12:01:33,247 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:01:36,936 INFO] number of examples: 77471\n","[2021-04-10 12:02:25,363 INFO] Step 25000/30000; acc:  98.99; ppl:  1.10; xent: 0.10; lr: 0.00056; 9702/11861 tok/s;  15737 sec\n","[2021-04-10 12:02:25,364 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:02:25,730 INFO] number of examples: 10362\n","[2021-04-10 12:02:42,605 INFO] Validation perplexity: 35.8301\n","[2021-04-10 12:02:42,605 INFO] Validation accuracy: 53.5685\n","[2021-04-10 12:02:42,821 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-10 12:04:11,963 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:04:16,213 INFO] number of examples: 77471\n","[2021-04-10 12:06:28,514 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:06:32,241 INFO] number of examples: 77471\n","[2021-04-10 12:08:45,195 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:08:48,844 INFO] number of examples: 77471\n","[2021-04-10 12:11:01,093 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:11:05,161 INFO] number of examples: 77471\n","[2021-04-10 12:12:53,149 INFO] Step 26000/30000; acc:  99.05; ppl:  1.10; xent: 0.09; lr: 0.00055; 9789/11957 tok/s;  16365 sec\n","[2021-04-10 12:12:53,151 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:12:53,518 INFO] number of examples: 10362\n","[2021-04-10 12:13:10,380 INFO] Validation perplexity: 37.0382\n","[2021-04-10 12:13:10,380 INFO] Validation accuracy: 53.3347\n","[2021-04-10 12:13:10,589 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-10 12:13:40,189 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:13:44,260 INFO] number of examples: 77471\n","[2021-04-10 12:15:56,380 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:16:00,605 INFO] number of examples: 77471\n","[2021-04-10 12:18:13,389 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:18:17,106 INFO] number of examples: 77471\n","[2021-04-10 12:20:29,343 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:20:32,935 INFO] number of examples: 77471\n","[2021-04-10 12:22:45,721 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:22:49,866 INFO] number of examples: 77471\n","[2021-04-10 12:23:25,839 INFO] Step 27000/30000; acc:  99.11; ppl:  1.10; xent: 0.09; lr: 0.00054; 9720/11889 tok/s;  16997 sec\n","[2021-04-10 12:23:25,840 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:23:26,209 INFO] number of examples: 10362\n","[2021-04-10 12:23:43,074 INFO] Validation perplexity: 37.1115\n","[2021-04-10 12:23:43,074 INFO] Validation accuracy: 53.4601\n","[2021-04-10 12:23:43,284 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-10 12:25:24,068 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:25:28,296 INFO] number of examples: 77471\n","[2021-04-10 12:27:41,020 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:27:44,693 INFO] number of examples: 77471\n","[2021-04-10 12:29:56,885 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:30:01,157 INFO] number of examples: 77471\n","[2021-04-10 12:32:13,981 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:32:17,768 INFO] number of examples: 77471\n","[2021-04-10 12:33:53,447 INFO] Step 28000/30000; acc:  99.17; ppl:  1.09; xent: 0.09; lr: 0.00053; 9793/11958 tok/s;  17625 sec\n","[2021-04-10 12:33:53,448 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:33:53,809 INFO] number of examples: 10362\n","[2021-04-10 12:34:10,670 INFO] Validation perplexity: 36.241\n","[2021-04-10 12:34:10,671 INFO] Validation accuracy: 53.7961\n","[2021-04-10 12:34:10,892 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-10 12:34:52,794 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:34:56,436 INFO] number of examples: 77471\n","[2021-04-10 12:37:09,225 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:37:13,281 INFO] number of examples: 77471\n","[2021-04-10 12:39:25,436 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:39:29,705 INFO] number of examples: 77471\n","[2021-04-10 12:41:42,531 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:41:46,248 INFO] number of examples: 77471\n","[2021-04-10 12:43:58,439 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:44:02,103 INFO] number of examples: 77471\n","[2021-04-10 12:44:26,359 INFO] Step 29000/30000; acc:  99.21; ppl:  1.09; xent: 0.08; lr: 0.00052; 9723/11886 tok/s;  18258 sec\n","[2021-04-10 12:44:26,360 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:44:27,375 INFO] number of examples: 10362\n","[2021-04-10 12:44:44,244 INFO] Validation perplexity: 37.3622\n","[2021-04-10 12:44:44,244 INFO] Validation accuracy: 53.6234\n","[2021-04-10 12:44:44,456 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-10 12:46:38,702 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:46:42,701 INFO] number of examples: 77471\n","[2021-04-10 12:48:55,001 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:48:59,324 INFO] number of examples: 77471\n","[2021-04-10 12:51:12,043 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:51:15,796 INFO] number of examples: 77471\n","[2021-04-10 12:53:28,028 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-10 12:53:31,701 INFO] number of examples: 77471\n","[2021-04-10 12:54:55,707 INFO] Step 30000/30000; acc:  99.25; ppl:  1.09; xent: 0.08; lr: 0.00051; 9759/11924 tok/s;  18887 sec\n","[2021-04-10 12:54:55,708 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-10 12:54:56,699 INFO] number of examples: 10362\n","[2021-04-10 12:55:13,558 INFO] Validation perplexity: 37.7575\n","[2021-04-10 12:55:13,559 INFO] Validation accuracy: 53.6664\n","[2021-04-10 12:55:13,772 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618059320063,"user_tz":-420,"elapsed":18979623,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"4a340a23-d118-452f-ca2f-ea2d2a3c0a3b"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 30147675\n","-rw------- 1 root root 1029040319 Apr 10 09:25 en-vi_step_10000.pt\n","-rw------- 1 root root 1029040319 Apr 10 07:50 en-vi_step_1000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:35 en-vi_step_11000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:46 en-vi_step_12000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:56 en-vi_step_13000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:07 en-vi_step_14000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:17 en-vi_step_15000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:28 en-vi_step_16000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:38 en-vi_step_17000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:49 en-vi_step_18000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:59 en-vi_step_19000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:10 en-vi_step_20000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:01 en-vi_step_2000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:20 en-vi_step_21000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:31 en-vi_step_22000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:41 en-vi_step_23000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:52 en-vi_step_24000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:02 en-vi_step_25000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:13 en-vi_step_26000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:23 en-vi_step_27000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:34 en-vi_step_28000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:44 en-vi_step_29000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:55 en-vi_step_30000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:11 en-vi_step_3000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:22 en-vi_step_4000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:32 en-vi_step_5000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:43 en-vi_step_6000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:53 en-vi_step_7000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:04 en-vi_step_8000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:14 en-vi_step_9000.pt\n","\n","model/:\n","total 30147675\n","-rw------- 1 root root 1029040319 Apr 10 09:25 en-vi_step_10000.pt\n","-rw------- 1 root root 1029040319 Apr 10 07:50 en-vi_step_1000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:35 en-vi_step_11000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:46 en-vi_step_12000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:56 en-vi_step_13000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:07 en-vi_step_14000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:17 en-vi_step_15000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:28 en-vi_step_16000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:38 en-vi_step_17000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:49 en-vi_step_18000.pt\n","-rw------- 1 root root 1029040319 Apr 10 10:59 en-vi_step_19000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:10 en-vi_step_20000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:01 en-vi_step_2000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:20 en-vi_step_21000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:31 en-vi_step_22000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:41 en-vi_step_23000.pt\n","-rw------- 1 root root 1029040319 Apr 10 11:52 en-vi_step_24000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:02 en-vi_step_25000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:13 en-vi_step_26000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:23 en-vi_step_27000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:34 en-vi_step_28000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:44 en-vi_step_29000.pt\n","-rw------- 1 root root 1029040319 Apr 10 12:55 en-vi_step_30000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:11 en-vi_step_3000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:22 en-vi_step_4000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:32 en-vi_step_5000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:43 en-vi_step_6000.pt\n","-rw------- 1 root root 1029040319 Apr 10 08:53 en-vi_step_7000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:04 en-vi_step_8000.pt\n","-rw------- 1 root root 1029040319 Apr 10 09:14 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618062236075,"user_tz":-420,"elapsed":21895634,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"07d7ec80-7c33-416b-9ce5-6aede2d692a6"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-10 12:55:27,255 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 13:42:18,607 INFO] PRED AVG SCORE: -0.4296, PRED PPL: 1.5366\n","[2021-04-10 13:42:18,608 INFO] GOLD AVG SCORE: -3.6377, GOLD PPL: 38.0052\n","[2021-04-10 13:42:18,637 INFO] Translating shard 1.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-10 13:43:55,360 INFO] PRED AVG SCORE: -0.4352, PRED PPL: 1.5452\n","[2021-04-10 13:43:55,360 INFO] GOLD AVG SCORE: -3.6504, GOLD PPL: 38.4906\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618062236076,"user_tz":-420,"elapsed":21895634,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e91f8ff9-5d5c-408c-ada6-0a586023e1c6"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cà vạt thì loè loẹt .\n","và lí do là bởi vì có 2 lí do , theo tôi nghĩ\n","Ông thích nói về thiên tài tâm linh của lứa tuổi .\n","Chúng tôi đều là người Triều Tiên , nhưng đã trở nên rất khác nhau do hậu quả của 67 năm bị chia cắt .\n","Đó là cách bạn xử lý một vấn đề khi bạn nhìn thấy chúng và đó không chỉ là việc than phiền về vấn đề đó .\n","Tham vọng của các bạn được thoã mãn , nó rất đẹp .\n","Không có thứ nào trong những điều trên thực sự hữu ích bởi vì bạn đang điều trị những triệu chứng chứ không phải nguyên nhân của các vấn đề cơ bản ở Phi Châu .\n","Nhưng hiện nay nhiều người sống đến 90 hay 100 tuổi , trừ khi họ bắt tay quá nhiều hay làm những điều đại loại thế .\n","Nhưng quý vị phải có những công cụ đúng .\n","Những điều này là một phần cuộc đời ông và là những gì ông còn nhớ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618062259107,"user_tz":-420,"elapsed":21918663,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"87fb03ee-6b02-4770-df51-2bb71693aa29"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 32, done.\u001b[K\n","remote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (27/27), done.\u001b[K\n","remote: Total 17114 (delta 8), reused 11 (delta 4), pack-reused 17082\u001b[K\n","Receiving objects: 100% (17114/17114), 273.03 MiB | 17.78 MiB/s, done.\n","Resolving deltas: 100% (12332/12332), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618062259596,"user_tz":-420,"elapsed":21919151,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"fe6cf349-d364-444a-dd5d-455af504d2d0"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 93762\n","drwx------  2 root root     4096 Apr 10 07:39 data_bin\n","-rw-------  1 root root   996149 Apr 10 07:32 en_test\n","-rw-------  1 root root  8024744 Apr 10 07:32 en_train\n","-rw-------  1 root root  8204550 Apr 10 07:32 en_train_EM_0.8\n","-rw-------  1 root root  8103017 Apr 10 07:32 en_train_EM_0.85\n","-rw-------  1 root root  8053185 Apr 10 07:32 en_train_EM_0.9\n","-rw-------  1 root root  8031617 Apr 10 07:32 en_train_EM_0.95\n","-rw-------  1 root root  3323998 Apr 10 07:32 en_train_EM_factor_0.8\n","-rw-------  1 root root  3281394 Apr 10 07:32 en_train_EM_factor_0.85\n","-rw-------  1 root root  3260286 Apr 10 07:32 en_train_EM_factor_0.9\n","-rw-------  1 root root  3250950 Apr 10 07:32 en_train_EM_factor_0.95\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.8\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.85\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.9\n","-rw-------  1 root root   860286 Apr 10 07:32 en_train_EM_score_0.95\n","-rw-------  1 root root  1000856 Apr 10 07:32 en_valid\n","-rw-------  1 root root 22512408 Apr 10 07:39 en_vi_iwslt_sent2vec.tar.gz\n","drwx------  2 root root     4096 Apr 10 12:55 model\n","drwx------ 11 root root     4096 Apr 10 13:44 OpenNMT-py\n","drwx------  2 root root     4096 Apr 10 07:39 output\n","-rw-------  1 root root  1176762 Apr 10 13:43 predict.txt\n","-rw-------  1 root root  1327417 Apr 10 07:32 vi_test\n","-rw-------  1 root root 10671354 Apr 10 07:32 vi_train\n","-rw-------  1 root root  1330789 Apr 10 07:32 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618062262374,"user_tz":-420,"elapsed":21921928,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"a9b25225-613d-4d65-8561-8ea70e2a8a5b"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 23.47, 59.5/33.5/19.8/12.0 (BP=0.894, ratio=0.900, hyp_len=219688, ref_len=244219)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1618062262374,"user_tz":-420,"elapsed":21921926,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}