{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TED-OpenNMT-bert-0.8-20210409-1053 BLEU 23.39.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968886855,"user_tz":-420,"elapsed":21922,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"c3248833-1e6f-4d93-831f-dc73bd886b31"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968888512,"user_tz":-420,"elapsed":23576,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"f9cbc6de-2ca8-43e1-cc1c-76f7fa382469"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"TED-OpenNMT-bert-0.8-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v3/OpenNMT-TED-EM-bert-ratio-8-2-2-20210128-0637'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/TED-OpenNMT-bert-0.8-20210409-1148\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968888512,"user_tz":-420,"elapsed":23574,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"3bda6882-8a40-4ac2-dc5f-035cb6d38aec"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Fri Apr  9 11:48:07 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968903201,"user_tz":-420,"elapsed":38262,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e308e245-06fa-4a5c-95ec-7bed74b344c7"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 13.2MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 19.1MB/s \n","\u001b[?25hCollecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[?25hCollecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=7d3141d7dc3741dc5fe9b64cc68fea146baf4693f79380bece7c777e68479906\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: pyonmttok, waitress, configargparse, torchtext, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968905537,"user_tz":-420,"elapsed":40597,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"b49515bd-c5f5-4ea0-97e7-06a5f8a3086f"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'en_vi_iwslt_bert.tar.gz'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2021-04-09 11:48:22--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22435544 (21M) [application/octet-stream]\n","Saving to: ‘en_vi_iwslt_bert.tar.gz’\n","\n","en_vi_iwslt_bert.ta 100%[===================>]  21.40M  84.9MB/s    in 0.3s    \n","\n","2021-04-09 11:48:23 (84.9 MB/s) - ‘en_vi_iwslt_bert.tar.gz’ saved [22435544/22435544]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617968917742,"user_tz":-420,"elapsed":52800,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"9261849e-4131-4ce0-9f47-3f3eff09f85e"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.8' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-09 11:48:28,182 INFO] Extracting features...\n","[2021-04-09 11:48:28,186 INFO]  * number of source features: 0.\n","[2021-04-09 11:48:28,186 INFO]  * number of target features: 0.\n","[2021-04-09 11:48:28,186 INFO] Building `Fields` object...\n","[2021-04-09 11:48:28,186 INFO] Building & saving training data...\n","[2021-04-09 11:48:28,357 INFO] Building shard 0.\n","[2021-04-09 11:48:32,083 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-09 11:48:35,352 INFO]  * tgt vocab size: 18250.\n","[2021-04-09 11:48:35,421 INFO]  * src vocab size: 40744.\n","[2021-04-09 11:48:35,630 INFO] Building & saving validation data...\n","[2021-04-09 11:48:35,742 INFO] Building shard 0.\n","[2021-04-09 11:48:36,009 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617979614294,"user_tz":-420,"elapsed":10749351,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"bf0fb81b-c92e-443b-880d-fd3590a13bad"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[2021-04-09 11:48:38,849 INFO]  * src vocab size = 40744\n","[2021-04-09 11:48:38,849 INFO]  * tgt vocab size = 18250\n","[2021-04-09 11:48:38,849 INFO] Building model...\n","[2021-04-09 11:48:46,937 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(40744, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(18250, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=18250, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-09 11:48:46,987 INFO] encoder: 39776256\n","[2021-04-09 11:48:46,987 INFO] decoder: 43931466\n","[2021-04-09 11:48:46,987 INFO] * number of parameters: 83707722\n","[2021-04-09 11:48:46,991 INFO] Starting training on GPU: [0]\n","[2021-04-09 11:48:46,991 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-09 11:48:46,991 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:48:49,749 INFO] number of examples: 77471\n","[2021-04-09 11:50:02,425 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:50:05,846 INFO] number of examples: 77471\n","[2021-04-09 11:51:18,416 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:51:21,345 INFO] number of examples: 77471\n","[2021-04-09 11:52:34,117 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:52:37,531 INFO] number of examples: 77471\n","[2021-04-09 11:53:50,394 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:53:53,881 INFO] number of examples: 77471\n","[2021-04-09 11:54:29,365 INFO] Step 1000/30000; acc:  13.89; ppl: 251.55; xent: 5.53; lr: 0.00012; 17944/22105 tok/s;    342 sec\n","[2021-04-09 11:54:29,366 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 11:54:29,681 INFO] number of examples: 10362\n","[2021-04-09 11:54:39,123 INFO] Validation perplexity: 103.103\n","[2021-04-09 11:54:39,123 INFO] Validation accuracy: 26.4344\n","[2021-04-09 11:54:39,317 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-09 11:55:21,192 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:55:24,956 INFO] number of examples: 77471\n","[2021-04-09 11:56:37,758 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:56:41,075 INFO] number of examples: 77471\n","[2021-04-09 11:57:54,221 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:57:57,445 INFO] number of examples: 77471\n","[2021-04-09 11:59:10,342 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:59:14,084 INFO] number of examples: 77471\n","[2021-04-09 12:00:24,729 INFO] Step 2000/30000; acc:  40.26; ppl: 21.23; xent: 3.06; lr: 0.00025; 17294/21268 tok/s;    698 sec\n","[2021-04-09 12:00:24,730 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:00:25,040 INFO] number of examples: 10362\n","[2021-04-09 12:00:34,491 INFO] Validation perplexity: 21.1984\n","[2021-04-09 12:00:34,491 INFO] Validation accuracy: 46.6312\n","[2021-04-09 12:00:34,687 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-09 12:00:41,131 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:00:44,944 INFO] number of examples: 77471\n","[2021-04-09 12:01:58,167 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:02:01,494 INFO] number of examples: 77471\n","[2021-04-09 12:03:14,333 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:03:18,275 INFO] number of examples: 77471\n","[2021-04-09 12:04:31,082 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:04:34,457 INFO] number of examples: 77471\n","[2021-04-09 12:05:47,248 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:05:50,455 INFO] number of examples: 77471\n","[2021-04-09 12:06:23,749 INFO] Step 3000/30000; acc:  56.83; ppl:  6.91; xent: 1.93; lr: 0.00037; 17110/21091 tok/s;   1057 sec\n","[2021-04-09 12:06:23,750 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:06:24,566 INFO] number of examples: 10362\n","[2021-04-09 12:06:34,040 INFO] Validation perplexity: 17.0989\n","[2021-04-09 12:06:34,040 INFO] Validation accuracy: 50.001\n","[2021-04-09 12:06:34,235 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-09 12:07:18,159 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:07:22,048 INFO] number of examples: 77471\n","[2021-04-09 12:08:34,817 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:08:38,306 INFO] number of examples: 77471\n","[2021-04-09 12:09:51,051 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:09:54,408 INFO] number of examples: 77471\n","[2021-04-09 12:11:07,193 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:11:10,519 INFO] number of examples: 77471\n","[2021-04-09 12:12:18,725 INFO] Step 4000/30000; acc:  65.13; ppl:  4.21; xent: 1.44; lr: 0.00049; 17307/21289 tok/s;   1412 sec\n","[2021-04-09 12:12:18,726 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:12:19,036 INFO] number of examples: 10362\n","[2021-04-09 12:12:28,491 INFO] Validation perplexity: 16.7478\n","[2021-04-09 12:12:28,491 INFO] Validation accuracy: 51.0058\n","[2021-04-09 12:12:28,696 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-09 12:12:37,477 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:12:41,651 INFO] number of examples: 77471\n","[2021-04-09 12:13:54,747 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:13:58,045 INFO] number of examples: 77471\n","[2021-04-09 12:15:10,732 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:15:14,572 INFO] number of examples: 77471\n","[2021-04-09 12:16:27,292 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:16:30,531 INFO] number of examples: 77471\n","[2021-04-09 12:17:43,400 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:17:47,333 INFO] number of examples: 77471\n","[2021-04-09 12:18:18,516 INFO] Step 5000/30000; acc:  71.36; ppl:  3.09; xent: 1.13; lr: 0.00062; 17082/21050 tok/s;   1772 sec\n","[2021-04-09 12:18:18,517 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:18:18,823 INFO] number of examples: 10362\n","[2021-04-09 12:18:28,263 INFO] Validation perplexity: 18.9341\n","[2021-04-09 12:18:28,263 INFO] Validation accuracy: 51.2655\n","[2021-04-09 12:18:28,455 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-09 12:19:14,701 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:19:18,577 INFO] number of examples: 77471\n","[2021-04-09 12:20:31,314 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:20:34,643 INFO] number of examples: 77471\n","[2021-04-09 12:21:47,380 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:21:51,407 INFO] number of examples: 77471\n","[2021-04-09 12:23:04,099 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:23:07,593 INFO] number of examples: 77471\n","[2021-04-09 12:24:13,505 INFO] Step 6000/30000; acc:  76.69; ppl:  2.45; xent: 0.90; lr: 0.00074; 17304/21280 tok/s;   2127 sec\n","[2021-04-09 12:24:13,506 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:24:13,814 INFO] number of examples: 10362\n","[2021-04-09 12:24:23,258 INFO] Validation perplexity: 22.2974\n","[2021-04-09 12:24:23,258 INFO] Validation accuracy: 50.767\n","[2021-04-09 12:24:23,448 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-09 12:24:34,518 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:24:38,021 INFO] number of examples: 77471\n","[2021-04-09 12:25:50,924 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:25:54,888 INFO] number of examples: 77471\n","[2021-04-09 12:27:07,518 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:27:11,004 INFO] number of examples: 77471\n","[2021-04-09 12:28:23,770 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:28:27,188 INFO] number of examples: 77471\n","[2021-04-09 12:29:40,147 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:29:43,503 INFO] number of examples: 77471\n","[2021-04-09 12:30:12,447 INFO] Step 7000/30000; acc:  80.90; ppl:  2.08; xent: 0.73; lr: 0.00086; 17132/21104 tok/s;   2485 sec\n","[2021-04-09 12:30:12,448 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:30:13,416 INFO] number of examples: 10362\n","[2021-04-09 12:30:22,950 INFO] Validation perplexity: 22.4358\n","[2021-04-09 12:30:22,950 INFO] Validation accuracy: 51.7746\n","[2021-04-09 12:30:23,142 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-09 12:31:11,877 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:31:16,617 INFO] number of examples: 77471\n","[2021-04-09 12:32:29,762 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:32:33,330 INFO] number of examples: 77471\n","[2021-04-09 12:33:46,362 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:33:49,850 INFO] number of examples: 77471\n","[2021-04-09 12:35:02,715 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:35:06,139 INFO] number of examples: 77471\n","[2021-04-09 12:36:09,972 INFO] Step 8000/30000; acc:  84.07; ppl:  1.85; xent: 0.61; lr: 0.00099; 17175/21139 tok/s;   2843 sec\n","[2021-04-09 12:36:09,973 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:36:10,285 INFO] number of examples: 10362\n","[2021-04-09 12:36:19,743 INFO] Validation perplexity: 25.576\n","[2021-04-09 12:36:19,743 INFO] Validation accuracy: 51.6332\n","[2021-04-09 12:36:19,942 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-09 12:36:33,325 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:36:37,675 INFO] number of examples: 77471\n","[2021-04-09 12:37:50,885 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:37:54,218 INFO] number of examples: 77471\n","[2021-04-09 12:39:07,129 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:39:11,063 INFO] number of examples: 77471\n","[2021-04-09 12:40:24,013 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:40:27,390 INFO] number of examples: 77471\n","[2021-04-09 12:41:40,313 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:41:44,168 INFO] number of examples: 77471\n","[2021-04-09 12:42:10,779 INFO] Step 9000/30000; acc:  87.38; ppl:  1.65; xent: 0.50; lr: 0.00093; 17040/20979 tok/s;   3204 sec\n","[2021-04-09 12:42:10,780 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:42:11,111 INFO] number of examples: 10362\n","[2021-04-09 12:42:20,579 INFO] Validation perplexity: 26.9386\n","[2021-04-09 12:42:20,579 INFO] Validation accuracy: 52.1078\n","[2021-04-09 12:42:20,771 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-09 12:43:11,253 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:43:15,304 INFO] number of examples: 77471\n","[2021-04-09 12:44:28,221 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:44:31,695 INFO] number of examples: 77471\n","[2021-04-09 12:45:44,505 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:45:47,974 INFO] number of examples: 77471\n","[2021-04-09 12:47:00,797 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:47:04,174 INFO] number of examples: 77471\n","[2021-04-09 12:48:05,637 INFO] Step 10000/30000; acc:  91.11; ppl:  1.47; xent: 0.39; lr: 0.00088; 17306/21322 tok/s;   3559 sec\n","[2021-04-09 12:48:05,638 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:48:05,952 INFO] number of examples: 10362\n","[2021-04-09 12:48:15,397 INFO] Validation perplexity: 28.0619\n","[2021-04-09 12:48:15,397 INFO] Validation accuracy: 52.5872\n","[2021-04-09 12:48:15,594 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-09 12:48:31,180 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:48:35,291 INFO] number of examples: 77471\n","[2021-04-09 12:49:48,330 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:49:51,671 INFO] number of examples: 77471\n","[2021-04-09 12:51:04,514 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:51:08,404 INFO] number of examples: 77471\n","[2021-04-09 12:52:21,179 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:52:24,516 INFO] number of examples: 77471\n","[2021-04-09 12:53:37,315 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:53:41,204 INFO] number of examples: 77471\n","[2021-04-09 12:54:05,624 INFO] Step 11000/30000; acc:  93.29; ppl:  1.37; xent: 0.32; lr: 0.00084; 17074/21009 tok/s;   3919 sec\n","[2021-04-09 12:54:05,625 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:54:05,947 INFO] number of examples: 10362\n","[2021-04-09 12:54:15,427 INFO] Validation perplexity: 28.9856\n","[2021-04-09 12:54:15,428 INFO] Validation accuracy: 52.4791\n","[2021-04-09 12:54:15,618 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-09 12:55:08,601 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:55:12,574 INFO] number of examples: 77471\n","[2021-04-09 12:56:25,460 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:56:28,842 INFO] number of examples: 77471\n","[2021-04-09 12:57:41,704 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:57:45,741 INFO] number of examples: 77471\n","[2021-04-09 12:58:58,531 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:59:01,983 INFO] number of examples: 77471\n","[2021-04-09 13:00:01,316 INFO] Step 12000/30000; acc:  94.76; ppl:  1.31; xent: 0.27; lr: 0.00081; 17271/21268 tok/s;   4274 sec\n","[2021-04-09 13:00:01,317 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:00:01,633 INFO] number of examples: 10362\n","[2021-04-09 13:00:11,097 INFO] Validation perplexity: 29.8348\n","[2021-04-09 13:00:11,097 INFO] Validation accuracy: 52.5609\n","[2021-04-09 13:00:11,291 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-09 13:00:28,970 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:00:32,640 INFO] number of examples: 77471\n","[2021-04-09 13:01:45,667 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:01:49,662 INFO] number of examples: 77471\n","[2021-04-09 13:03:02,492 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:03:06,084 INFO] number of examples: 77471\n","[2021-04-09 13:04:18,917 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:04:22,309 INFO] number of examples: 77471\n","[2021-04-09 13:05:35,151 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:05:39,197 INFO] number of examples: 77471\n","[2021-04-09 13:06:01,364 INFO] Step 13000/30000; acc:  95.81; ppl:  1.27; xent: 0.24; lr: 0.00078; 17072/21009 tok/s;   4634 sec\n","[2021-04-09 13:06:01,365 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:06:01,679 INFO] number of examples: 10362\n","[2021-04-09 13:06:11,136 INFO] Validation perplexity: 30.0732\n","[2021-04-09 13:06:11,136 INFO] Validation accuracy: 53.0328\n","[2021-04-09 13:06:11,328 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-09 13:07:07,298 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:07:10,748 INFO] number of examples: 77471\n","[2021-04-09 13:08:23,536 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:08:26,884 INFO] number of examples: 77471\n","[2021-04-09 13:09:39,751 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:09:43,695 INFO] number of examples: 77471\n","[2021-04-09 13:10:56,502 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:10:59,807 INFO] number of examples: 77471\n","[2021-04-09 13:11:56,738 INFO] Step 14000/30000; acc:  96.57; ppl:  1.23; xent: 0.21; lr: 0.00075; 17283/21293 tok/s;   4990 sec\n","[2021-04-09 13:11:56,739 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:11:57,739 INFO] number of examples: 10362\n","[2021-04-09 13:12:07,171 INFO] Validation perplexity: 30.8389\n","[2021-04-09 13:12:07,172 INFO] Validation accuracy: 52.9212\n","[2021-04-09 13:12:07,367 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-09 13:12:27,674 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:12:31,568 INFO] number of examples: 77471\n","[2021-04-09 13:13:44,499 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:13:48,387 INFO] number of examples: 77471\n","[2021-04-09 13:15:01,207 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:15:04,513 INFO] number of examples: 77471\n","[2021-04-09 13:16:17,401 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:16:21,415 INFO] number of examples: 77471\n","[2021-04-09 13:17:34,465 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:17:37,893 INFO] number of examples: 77471\n","[2021-04-09 13:17:57,793 INFO] Step 15000/30000; acc:  97.16; ppl:  1.20; xent: 0.19; lr: 0.00072; 17019/20947 tok/s;   5351 sec\n","[2021-04-09 13:17:57,794 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:17:58,124 INFO] number of examples: 10362\n","[2021-04-09 13:18:07,584 INFO] Validation perplexity: 31.8966\n","[2021-04-09 13:18:07,584 INFO] Validation accuracy: 52.8018\n","[2021-04-09 13:18:07,780 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-09 13:19:05,180 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:19:09,073 INFO] number of examples: 77471\n","[2021-04-09 13:20:22,041 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:20:26,107 INFO] number of examples: 77471\n","[2021-04-09 13:21:38,902 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:21:42,372 INFO] number of examples: 77471\n","[2021-04-09 13:22:55,147 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:22:58,593 INFO] number of examples: 77471\n","[2021-04-09 13:23:53,240 INFO] Step 16000/30000; acc:  97.58; ppl:  1.18; xent: 0.17; lr: 0.00070; 17289/21290 tok/s;   5706 sec\n","[2021-04-09 13:23:53,241 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:23:53,556 INFO] number of examples: 10362\n","[2021-04-09 13:24:03,028 INFO] Validation perplexity: 33.1248\n","[2021-04-09 13:24:03,028 INFO] Validation accuracy: 53.2118\n","[2021-04-09 13:24:03,221 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-09 13:24:25,589 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:24:29,225 INFO] number of examples: 77471\n","[2021-04-09 13:25:42,138 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:25:45,928 INFO] number of examples: 77471\n","[2021-04-09 13:26:58,739 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:27:02,794 INFO] number of examples: 77471\n","[2021-04-09 13:28:15,445 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:28:19,045 INFO] number of examples: 77471\n","[2021-04-09 13:29:31,805 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:29:35,337 INFO] number of examples: 77471\n","[2021-04-09 13:29:52,921 INFO] Step 17000/30000; acc:  97.90; ppl:  1.17; xent: 0.15; lr: 0.00068; 17085/21036 tok/s;   6066 sec\n","[2021-04-09 13:29:52,922 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:29:53,237 INFO] number of examples: 10362\n","[2021-04-09 13:30:02,684 INFO] Validation perplexity: 32.6602\n","[2021-04-09 13:30:02,684 INFO] Validation accuracy: 53.4189\n","[2021-04-09 13:30:02,882 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-09 13:31:02,762 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:31:06,107 INFO] number of examples: 77471\n","[2021-04-09 13:32:18,825 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:32:22,673 INFO] number of examples: 77471\n","[2021-04-09 13:33:35,461 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:33:38,766 INFO] number of examples: 77471\n","[2021-04-09 13:34:51,390 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:34:55,287 INFO] number of examples: 77471\n","[2021-04-09 13:35:47,747 INFO] Step 18000/30000; acc:  98.16; ppl:  1.15; xent: 0.14; lr: 0.00066; 17317/21320 tok/s;   6421 sec\n","[2021-04-09 13:35:47,748 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:35:48,053 INFO] number of examples: 10362\n","[2021-04-09 13:35:57,504 INFO] Validation perplexity: 33.4822\n","[2021-04-09 13:35:57,504 INFO] Validation accuracy: 53.1675\n","[2021-04-09 13:35:57,695 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-09 13:36:22,320 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:36:25,941 INFO] number of examples: 77471\n","[2021-04-09 13:37:38,630 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:37:42,429 INFO] number of examples: 77471\n","[2021-04-09 13:38:55,113 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:38:59,103 INFO] number of examples: 77471\n","[2021-04-09 13:40:11,844 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:40:15,326 INFO] number of examples: 77471\n","[2021-04-09 13:41:28,098 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:41:31,601 INFO] number of examples: 77471\n","[2021-04-09 13:41:47,034 INFO] Step 19000/30000; acc:  98.37; ppl:  1.14; xent: 0.13; lr: 0.00064; 17105/21061 tok/s;   6780 sec\n","[2021-04-09 13:41:47,035 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:41:47,356 INFO] number of examples: 10362\n","[2021-04-09 13:41:56,844 INFO] Validation perplexity: 34.5382\n","[2021-04-09 13:41:56,844 INFO] Validation accuracy: 53.5509\n","[2021-04-09 13:41:57,039 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-09 13:42:59,053 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:43:02,413 INFO] number of examples: 77471\n","[2021-04-09 13:44:15,140 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:44:19,092 INFO] number of examples: 77471\n","[2021-04-09 13:45:31,909 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:45:35,159 INFO] number of examples: 77471\n","[2021-04-09 13:46:47,651 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:46:51,377 INFO] number of examples: 77471\n","[2021-04-09 13:47:41,040 INFO] Step 20000/30000; acc:  98.53; ppl:  1.13; xent: 0.12; lr: 0.00062; 17352/21368 tok/s;   7134 sec\n","[2021-04-09 13:47:41,042 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:47:41,349 INFO] number of examples: 10362\n","[2021-04-09 13:47:50,693 INFO] Validation perplexity: 34.1612\n","[2021-04-09 13:47:50,693 INFO] Validation accuracy: 53.173\n","[2021-04-09 13:47:50,870 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-09 13:48:18,566 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:48:22,501 INFO] number of examples: 77471\n","[2021-04-09 13:49:34,647 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:49:37,928 INFO] number of examples: 77471\n","[2021-04-09 13:50:50,080 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:50:53,308 INFO] number of examples: 77471\n","[2021-04-09 13:52:05,536 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:52:08,695 INFO] number of examples: 77471\n","[2021-04-09 13:53:20,919 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:53:24,505 INFO] number of examples: 77471\n","[2021-04-09 13:53:37,461 INFO] Step 21000/30000; acc:  98.67; ppl:  1.13; xent: 0.12; lr: 0.00061; 17238/21221 tok/s;   7490 sec\n","[2021-04-09 13:53:37,462 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:53:37,765 INFO] number of examples: 10362\n","[2021-04-09 13:53:47,124 INFO] Validation perplexity: 34.1006\n","[2021-04-09 13:53:47,125 INFO] Validation accuracy: 53.4432\n","[2021-04-09 13:53:47,307 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-09 13:54:51,020 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:54:54,672 INFO] number of examples: 77471\n","[2021-04-09 13:56:06,818 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:56:09,972 INFO] number of examples: 77471\n","[2021-04-09 13:57:22,097 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:57:25,737 INFO] number of examples: 77471\n","[2021-04-09 13:58:37,905 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:58:41,108 INFO] number of examples: 77471\n","[2021-04-09 13:59:28,576 INFO] Step 22000/30000; acc:  98.78; ppl:  1.12; xent: 0.11; lr: 0.00060; 17495/21541 tok/s;   7842 sec\n","[2021-04-09 13:59:28,577 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:59:29,500 INFO] number of examples: 10362\n","[2021-04-09 13:59:38,838 INFO] Validation perplexity: 34.7612\n","[2021-04-09 13:59:38,838 INFO] Validation accuracy: 53.4585\n","[2021-04-09 13:59:39,022 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-09 14:00:08,153 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:00:11,612 INFO] number of examples: 77471\n","[2021-04-09 14:01:23,756 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:01:27,397 INFO] number of examples: 77471\n","[2021-04-09 14:02:39,406 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:02:42,524 INFO] number of examples: 77471\n","[2021-04-09 14:03:54,646 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:03:58,249 INFO] number of examples: 77471\n","[2021-04-09 14:05:10,378 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:05:13,510 INFO] number of examples: 77471\n","[2021-04-09 14:05:24,264 INFO] Step 23000/30000; acc:  98.88; ppl:  1.11; xent: 0.11; lr: 0.00058; 17277/21269 tok/s;   8197 sec\n","[2021-04-09 14:05:24,265 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:05:25,241 INFO] number of examples: 10362\n","[2021-04-09 14:05:34,596 INFO] Validation perplexity: 35.6031\n","[2021-04-09 14:05:34,596 INFO] Validation accuracy: 53.3849\n","[2021-04-09 14:05:34,777 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-09 14:06:40,690 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:06:44,993 INFO] number of examples: 77471\n","[2021-04-09 14:07:57,535 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:08:00,924 INFO] number of examples: 77471\n","[2021-04-09 14:09:13,119 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:09:16,383 INFO] number of examples: 77471\n","[2021-04-09 14:10:28,684 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:10:31,885 INFO] number of examples: 77471\n","[2021-04-09 14:11:17,090 INFO] Step 24000/30000; acc:  98.96; ppl:  1.11; xent: 0.10; lr: 0.00057; 17410/21433 tok/s;   8550 sec\n","[2021-04-09 14:11:17,092 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:11:17,393 INFO] number of examples: 10362\n","[2021-04-09 14:11:26,737 INFO] Validation perplexity: 34.6381\n","[2021-04-09 14:11:26,737 INFO] Validation accuracy: 53.6034\n","[2021-04-09 14:11:26,918 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-09 14:11:58,237 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:12:01,869 INFO] number of examples: 77471\n","[2021-04-09 14:13:14,115 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:13:17,877 INFO] number of examples: 77471\n","[2021-04-09 14:14:30,078 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:14:33,468 INFO] number of examples: 77471\n","[2021-04-09 14:15:45,712 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:15:48,982 INFO] number of examples: 77471\n","[2021-04-09 14:17:01,240 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:17:04,403 INFO] number of examples: 77471\n","[2021-04-09 14:17:12,897 INFO] Step 25000/30000; acc:  99.03; ppl:  1.10; xent: 0.10; lr: 0.00056; 17269/21262 tok/s;   8906 sec\n","[2021-04-09 14:17:12,898 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:17:13,206 INFO] number of examples: 10362\n","[2021-04-09 14:17:22,536 INFO] Validation perplexity: 36.679\n","[2021-04-09 14:17:22,537 INFO] Validation accuracy: 53.5392\n","[2021-04-09 14:17:22,712 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-09 14:18:30,788 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:18:34,445 INFO] number of examples: 77471\n","[2021-04-09 14:19:46,536 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:19:50,208 INFO] number of examples: 77471\n","[2021-04-09 14:21:02,452 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:21:05,726 INFO] number of examples: 77471\n","[2021-04-09 14:22:17,821 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:22:21,053 INFO] number of examples: 77471\n","[2021-04-09 14:23:04,062 INFO] Step 26000/30000; acc:  99.09; ppl:  1.10; xent: 0.09; lr: 0.00055; 17488/21542 tok/s;   9257 sec\n","[2021-04-09 14:23:04,063 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:23:04,358 INFO] number of examples: 10362\n","[2021-04-09 14:23:13,665 INFO] Validation perplexity: 35.3642\n","[2021-04-09 14:23:13,665 INFO] Validation accuracy: 53.5286\n","[2021-04-09 14:23:13,845 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-09 14:23:47,425 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:23:51,026 INFO] number of examples: 77471\n","[2021-04-09 14:25:03,218 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:25:07,033 INFO] number of examples: 77471\n","[2021-04-09 14:26:19,135 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:26:22,531 INFO] number of examples: 77471\n","[2021-04-09 14:27:34,665 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:27:37,894 INFO] number of examples: 77471\n","[2021-04-09 14:28:50,047 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:28:53,131 INFO] number of examples: 77471\n","[2021-04-09 14:28:59,402 INFO] Step 27000/30000; acc:  99.15; ppl:  1.09; xent: 0.09; lr: 0.00054; 17301/21296 tok/s;   9612 sec\n","[2021-04-09 14:28:59,403 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:29:00,317 INFO] number of examples: 10362\n","[2021-04-09 14:29:09,633 INFO] Validation perplexity: 35.1689\n","[2021-04-09 14:29:09,633 INFO] Validation accuracy: 53.3363\n","[2021-04-09 14:29:09,814 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-09 14:30:20,148 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:30:24,425 INFO] number of examples: 77471\n","[2021-04-09 14:31:36,579 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:31:39,858 INFO] number of examples: 77471\n","[2021-04-09 14:32:52,058 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:32:55,305 INFO] number of examples: 77471\n","[2021-04-09 14:34:07,556 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:34:10,719 INFO] number of examples: 77471\n","[2021-04-09 14:34:51,378 INFO] Step 28000/30000; acc:  99.19; ppl:  1.09; xent: 0.09; lr: 0.00053; 17444/21479 tok/s;   9964 sec\n","[2021-04-09 14:34:51,379 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:34:51,678 INFO] number of examples: 10362\n","[2021-04-09 14:35:01,022 INFO] Validation perplexity: 36.051\n","[2021-04-09 14:35:01,022 INFO] Validation accuracy: 53.7616\n","[2021-04-09 14:35:01,212 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-09 14:35:36,998 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:35:40,599 INFO] number of examples: 77471\n","[2021-04-09 14:36:52,544 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:36:56,280 INFO] number of examples: 77471\n","[2021-04-09 14:38:08,519 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:38:11,784 INFO] number of examples: 77471\n","[2021-04-09 14:39:23,837 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:39:27,120 INFO] number of examples: 77471\n","[2021-04-09 14:40:39,220 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:40:42,396 INFO] number of examples: 77471\n","[2021-04-09 14:40:46,379 INFO] Step 29000/30000; acc:  99.24; ppl:  1.09; xent: 0.08; lr: 0.00052; 17319/21318 tok/s;  10319 sec\n","[2021-04-09 14:40:46,380 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:40:46,684 INFO] number of examples: 10362\n","[2021-04-09 14:40:56,008 INFO] Validation perplexity: 36.4003\n","[2021-04-09 14:40:56,009 INFO] Validation accuracy: 53.3982\n","[2021-04-09 14:40:56,189 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-09 14:42:09,549 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:42:13,107 INFO] number of examples: 77471\n","[2021-04-09 14:43:25,298 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:43:28,986 INFO] number of examples: 77471\n","[2021-04-09 14:44:41,053 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:44:44,240 INFO] number of examples: 77471\n","[2021-04-09 14:45:56,306 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:46:00,105 INFO] number of examples: 77471\n","[2021-04-09 14:46:38,474 INFO] Step 30000/30000; acc:  99.28; ppl:  1.08; xent: 0.08; lr: 0.00051; 17441/21487 tok/s;  10671 sec\n","[2021-04-09 14:46:38,475 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:46:38,772 INFO] number of examples: 10362\n","[2021-04-09 14:46:48,095 INFO] Validation perplexity: 37.462\n","[2021-04-09 14:46:48,095 INFO] Validation accuracy: 53.4554\n","[2021-04-09 14:46:48,278 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617979614296,"user_tz":-420,"elapsed":10749351,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"5c5d8f95-80c6-4a62-e1c1-4c6ec4d16778"},"source":["!ls -al model model/"],"execution_count":8,"outputs":[{"output_type":"stream","text":["model:\n","total 30094110\n","-rw------- 1 root root 1027212159 Apr  9 12:48 en-vi_step_10000.pt\n","-rw------- 1 root root 1027212159 Apr  9 11:54 en-vi_step_1000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:54 en-vi_step_11000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:00 en-vi_step_12000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:06 en-vi_step_13000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:12 en-vi_step_14000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:18 en-vi_step_15000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:24 en-vi_step_16000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:30 en-vi_step_17000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:36 en-vi_step_18000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:42 en-vi_step_19000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:47 en-vi_step_20000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:00 en-vi_step_2000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:53 en-vi_step_21000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:59 en-vi_step_22000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:05 en-vi_step_23000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:11 en-vi_step_24000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:17 en-vi_step_25000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:23 en-vi_step_26000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:29 en-vi_step_27000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:35 en-vi_step_28000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:41 en-vi_step_29000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:46 en-vi_step_30000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:06 en-vi_step_3000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:12 en-vi_step_4000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:18 en-vi_step_5000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:24 en-vi_step_6000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:30 en-vi_step_7000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:36 en-vi_step_8000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:42 en-vi_step_9000.pt\n","\n","model/:\n","total 30094110\n","-rw------- 1 root root 1027212159 Apr  9 12:48 en-vi_step_10000.pt\n","-rw------- 1 root root 1027212159 Apr  9 11:54 en-vi_step_1000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:54 en-vi_step_11000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:00 en-vi_step_12000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:06 en-vi_step_13000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:12 en-vi_step_14000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:18 en-vi_step_15000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:24 en-vi_step_16000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:30 en-vi_step_17000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:36 en-vi_step_18000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:42 en-vi_step_19000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:47 en-vi_step_20000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:00 en-vi_step_2000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:53 en-vi_step_21000.pt\n","-rw------- 1 root root 1027212159 Apr  9 13:59 en-vi_step_22000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:05 en-vi_step_23000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:11 en-vi_step_24000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:17 en-vi_step_25000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:23 en-vi_step_26000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:29 en-vi_step_27000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:35 en-vi_step_28000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:41 en-vi_step_29000.pt\n","-rw------- 1 root root 1027212159 Apr  9 14:46 en-vi_step_30000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:06 en-vi_step_3000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:12 en-vi_step_4000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:18 en-vi_step_5000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:24 en-vi_step_6000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:30 en-vi_step_7000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:36 en-vi_step_8000.pt\n","-rw------- 1 root root 1027212159 Apr  9 12:42 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617981928140,"user_tz":-420,"elapsed":13063194,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"1b7a1558-e12b-4243-a12a-0ef2cd7613f9"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[2021-04-09 14:47:00,241 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-09 15:24:08,054 INFO] PRED AVG SCORE: -0.4499, PRED PPL: 1.5682\n","[2021-04-09 15:24:08,055 INFO] GOLD AVG SCORE: -3.6284, GOLD PPL: 37.6536\n","[2021-04-09 15:24:08,080 INFO] Translating shard 1.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-09 15:25:27,233 INFO] PRED AVG SCORE: -0.4560, PRED PPL: 1.5778\n","[2021-04-09 15:25:27,234 INFO] GOLD AVG SCORE: -3.6243, GOLD PPL: 37.4982\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617981928141,"user_tz":-420,"elapsed":13063194,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"693d2c1c-28b2-45b6-85b5-0a0f9c5837a0"},"source":["!tail vi_test"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cà vạt thì loè loẹt .\n","và lí do là bởi vì có 2 lí do , theo tôi nghĩ\n","Ông thích nói về thiên tài tâm linh của lứa tuổi .\n","Chúng tôi đều là người Triều Tiên , nhưng đã trở nên rất khác nhau do hậu quả của 67 năm bị chia cắt .\n","Đó là cách bạn xử lý một vấn đề khi bạn nhìn thấy chúng và đó không chỉ là việc than phiền về vấn đề đó .\n","Tham vọng của các bạn được thoã mãn , nó rất đẹp .\n","Không có thứ nào trong những điều trên thực sự hữu ích bởi vì bạn đang điều trị những triệu chứng chứ không phải nguyên nhân của các vấn đề cơ bản ở Phi Châu .\n","Nhưng hiện nay nhiều người sống đến 90 hay 100 tuổi , trừ khi họ bắt tay quá nhiều hay làm những điều đại loại thế .\n","Nhưng quý vị phải có những công cụ đúng .\n","Những điều này là một phần cuộc đời ông và là những gì ông còn nhớ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617981946583,"user_tz":-420,"elapsed":13081635,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"7ea67b01-b361-44f6-9634-9c53c04dc966"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 32, done.\u001b[K\n","remote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (27/27), done.\u001b[K\n","remote: Total 17114 (delta 8), reused 11 (delta 4), pack-reused 17082\u001b[K\n","Receiving objects: 100% (17114/17114), 273.03 MiB | 23.73 MiB/s, done.\n","Resolving deltas: 100% (12332/12332), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617981946584,"user_tz":-420,"elapsed":13081634,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"ea50e75d-6f94-4601-b38b-e530739a94ca"},"source":["!ls -al"],"execution_count":12,"outputs":[{"output_type":"stream","text":["total 93572\n","drwx------  2 root root     4096 Apr  9 11:48 data_bin\n","-rw-------  1 root root   996149 Apr  9 11:16 en_test\n","-rw-------  1 root root  8024744 Apr  9 11:16 en_train\n","-rw-------  1 root root  8161362 Apr  9 11:42 en_train_EM_0.8\n","-rw-------  1 root root  8075706 Apr  9 11:42 en_train_EM_0.85\n","-rw-------  1 root root  8040373 Apr  9 11:42 en_train_EM_0.9\n","-rw-------  1 root root  8026272 Apr  9 11:42 en_train_EM_0.95\n","-rw-------  1 root root  3303720 Apr  9 11:42 en_train_EM_factor_0.8\n","-rw-------  1 root root  3268996 Apr  9 11:42 en_train_EM_factor_0.85\n","-rw-------  1 root root  3254332 Apr  9 11:42 en_train_EM_factor_0.9\n","-rw-------  1 root root  3248468 Apr  9 11:42 en_train_EM_factor_0.95\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.8\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.85\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.9\n","-rw-------  1 root root   859759 Apr  9 11:42 en_train_EM_score_0.95\n","-rw-------  1 root root  1000856 Apr  9 11:16 en_valid\n","-rw-------  1 root root 22435544 Apr  9 11:48 en_vi_iwslt_bert.tar.gz\n","drwx------  2 root root     4096 Apr  9 14:46 model\n","drwx------ 11 root root     4096 Apr  9 15:25 OpenNMT-py\n","drwx------  2 root root     4096 Apr  9 11:48 output\n","-rw-------  1 root root  1190865 Apr  9 15:25 predict.txt\n","-rw-------  1 root root  1327417 Apr  9 11:16 vi_test\n","-rw-------  1 root root 10671354 Apr  9 11:16 vi_train\n","-rw-------  1 root root  1330789 Apr  9 11:16 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617981948504,"user_tz":-420,"elapsed":13083553,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"c9310200-a3f7-4cb7-e990-8c2324f8b76e"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":13,"outputs":[{"output_type":"stream","text":["BLEU = 23.39, 59.2/33.2/19.5/11.8 (BP=0.902, ratio=0.906, hyp_len=221362, ref_len=244219)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1617981948505,"user_tz":-420,"elapsed":13083553,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":13,"outputs":[]}]}