{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TED-OpenNMT-20210409-1047 BLEU 23.50.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617965254692,"user_tz":-420,"elapsed":26981,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"2577b24b-dbc0-424e-ee5f-e08301f9fee6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617965255997,"user_tz":-420,"elapsed":28277,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"a7b4bc20-c368-4d24-bd36-4fb09fb91ade"},"source":["import os\n","path = \"\"\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","os.chdir(path)\n","import time\n","FOLDERNAME = \"TED-OpenNMT-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","!mkdir $FOLDERNAME\n","\n","path = path + FOLDERNAME\n","os.chdir(path)\n","!pwd\n","\n","# import os\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v3/OpenNMT-TED-EM-bert-ratio-8-2-2-20210128-0637'\n","# os.chdir(path)\n","# !pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/TED-OpenNMT-20210409-1047\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617965255998,"user_tz":-420,"elapsed":28274,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"53db9140-f579-470f-c698-5543ea9e5ed9"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Fri Apr  9 10:47:35 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617965272700,"user_tz":-420,"elapsed":44973,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e510e38e-92c9-4075-f876-3fa11a6fa654"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 6.2MB/s \n","\u001b[?25hCollecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/63/17c6ac0d8a0cfa5ff7257e52edb6759d12dc266392f6c97f5c65c0c7238c/pyonmttok-1.25.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Collecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n","\u001b[?25hCollecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (54.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.8.1)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=48229f6f8c88bec262d5259cd54d9123440d4d476231f59a24828bbdf0551d1c\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: torchtext, pyonmttok, waitress, configargparse, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.25.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617965483328,"user_tz":-420,"elapsed":2390,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"c32e3196-0f72-46be-a0f2-3c77a7d8ed90"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'en_vi_iwslt_bert.tar.gz'"],"execution_count":20,"outputs":[{"output_type":"stream","text":["--2021-04-09 10:51:21--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/en_vi_iwslt_bert.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22918476 (22M) [application/octet-stream]\n","Saving to: ‘en_vi_iwslt_bert.tar.gz’\n","\n","en_vi_iwslt_bert.ta 100%[===================>]  21.86M  53.2MB/s    in 0.4s    \n","\n","2021-04-09 10:51:21 (53.2 MB/s) - ‘en_vi_iwslt_bert.tar.gz’ saved [22918476/22918476]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617965497540,"user_tz":-420,"elapsed":12179,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"58d0be36-9ea2-4bd8-b514-adec755b4c39"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":21,"outputs":[{"output_type":"stream","text":["[2021-04-09 10:51:26,970 INFO] Extracting features...\n","[2021-04-09 10:51:26,974 INFO]  * number of source features: 0.\n","[2021-04-09 10:51:26,974 INFO]  * number of target features: 0.\n","[2021-04-09 10:51:26,974 INFO] Building `Fields` object...\n","[2021-04-09 10:51:26,974 INFO] Building & saving training data...\n","[2021-04-09 10:51:27,157 INFO] Building shard 0.\n","[2021-04-09 10:51:31,724 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-09 10:51:35,258 INFO]  * tgt vocab size: 18250.\n","[2021-04-09 10:51:35,318 INFO]  * src vocab size: 39660.\n","[2021-04-09 10:51:35,524 INFO] Building & saving validation data...\n","[2021-04-09 10:51:35,655 INFO] Building shard 0.\n","[2021-04-09 10:51:35,951 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617984577284,"user_tz":-420,"elapsed":19089978,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"5fec53be-bfa7-42d5-8d20-6964b8abe2f3"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[2021-04-09 10:51:38,533 INFO]  * src vocab size = 39660\n","[2021-04-09 10:51:38,533 INFO]  * tgt vocab size = 18250\n","[2021-04-09 10:51:38,533 INFO] Building model...\n","[2021-04-09 10:51:46,438 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(39660, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(18250, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=18250, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-09 10:51:46,524 INFO] encoder: 39221248\n","[2021-04-09 10:51:46,524 INFO] decoder: 43931466\n","[2021-04-09 10:51:46,524 INFO] * number of parameters: 83152714\n","[2021-04-09 10:51:46,529 INFO] Starting training on GPU: [0]\n","[2021-04-09 10:51:46,529 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-09 10:51:46,529 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 10:51:49,704 INFO] number of examples: 77471\n","[2021-04-09 10:54:00,690 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 10:54:04,555 INFO] number of examples: 77471\n","[2021-04-09 10:56:15,610 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 10:56:18,973 INFO] number of examples: 77471\n","[2021-04-09 10:58:29,999 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 10:58:33,758 INFO] number of examples: 77471\n","[2021-04-09 11:00:44,729 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:00:48,527 INFO] number of examples: 77471\n","[2021-04-09 11:02:00,573 INFO] Step 1000/30000; acc:  13.52; ppl: 259.82; xent: 5.56; lr: 0.00012; 9947/12502 tok/s;    614 sec\n","[2021-04-09 11:02:00,574 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 11:02:01,389 INFO] number of examples: 10362\n","[2021-04-09 11:02:18,418 INFO] Validation perplexity: 112.412\n","[2021-04-09 11:02:18,419 INFO] Validation accuracy: 25.2094\n","[2021-04-09 11:02:18,631 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-09 11:03:22,595 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:03:26,154 INFO] number of examples: 77471\n","[2021-04-09 11:05:37,265 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:05:41,407 INFO] number of examples: 77471\n","[2021-04-09 11:07:52,470 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:07:56,086 INFO] number of examples: 77471\n","[2021-04-09 11:10:07,228 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:10:11,383 INFO] number of examples: 77471\n","[2021-04-09 11:12:22,533 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:12:26,859 INFO] number of examples: 77471\n","[2021-04-09 11:12:39,617 INFO] Step 2000/30000; acc:  40.09; ppl: 21.43; xent: 3.06; lr: 0.00025; 9537/11990 tok/s;   1253 sec\n","[2021-04-09 11:12:39,618 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 11:12:39,965 INFO] number of examples: 10362\n","[2021-04-09 11:12:57,021 INFO] Validation perplexity: 21.0446\n","[2021-04-09 11:12:57,021 INFO] Validation accuracy: 47.0357\n","[2021-04-09 11:12:57,222 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-09 11:15:00,167 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:15:03,823 INFO] number of examples: 77471\n","[2021-04-09 11:17:14,855 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:17:19,187 INFO] number of examples: 77471\n","[2021-04-09 11:19:30,309 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:19:34,070 INFO] number of examples: 77471\n","[2021-04-09 11:21:45,191 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:21:49,585 INFO] number of examples: 77471\n","[2021-04-09 11:23:13,693 INFO] Step 3000/30000; acc:  57.06; ppl:  6.82; xent: 1.92; lr: 0.00037; 9635/12100 tok/s;   1887 sec\n","[2021-04-09 11:23:13,694 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 11:23:14,049 INFO] number of examples: 10362\n","[2021-04-09 11:23:31,094 INFO] Validation perplexity: 16.2439\n","[2021-04-09 11:23:31,094 INFO] Validation accuracy: 50.5058\n","[2021-04-09 11:23:31,298 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-09 11:24:23,444 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:24:27,252 INFO] number of examples: 77471\n","[2021-04-09 11:26:38,341 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:26:42,773 INFO] number of examples: 77471\n","[2021-04-09 11:28:54,039 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:28:57,909 INFO] number of examples: 77471\n","[2021-04-09 11:31:09,002 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:31:12,793 INFO] number of examples: 77471\n","[2021-04-09 11:33:23,968 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:33:28,385 INFO] number of examples: 77471\n","[2021-04-09 11:33:53,060 INFO] Step 4000/30000; acc:  65.40; ppl:  4.16; xent: 1.42; lr: 0.00049; 9530/11982 tok/s;   2527 sec\n","[2021-04-09 11:33:53,061 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 11:33:53,424 INFO] number of examples: 10362\n","[2021-04-09 11:34:10,494 INFO] Validation perplexity: 16.5632\n","[2021-04-09 11:34:10,494 INFO] Validation accuracy: 51.3536\n","[2021-04-09 11:34:10,715 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-09 11:36:01,759 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:36:05,524 INFO] number of examples: 77471\n","[2021-04-09 11:38:16,626 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:38:20,976 INFO] number of examples: 77471\n","[2021-04-09 11:40:32,090 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:40:35,852 INFO] number of examples: 77471\n","[2021-04-09 11:42:47,000 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:42:51,402 INFO] number of examples: 77471\n","[2021-04-09 11:44:27,390 INFO] Step 5000/30000; acc:  71.71; ppl:  3.04; xent: 1.11; lr: 0.00062; 9630/12101 tok/s;   3161 sec\n","[2021-04-09 11:44:27,391 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 11:44:27,755 INFO] number of examples: 10362\n","[2021-04-09 11:44:44,815 INFO] Validation perplexity: 18.0399\n","[2021-04-09 11:44:44,816 INFO] Validation accuracy: 51.4887\n","[2021-04-09 11:44:45,042 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-09 11:45:24,834 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:45:29,328 INFO] number of examples: 77471\n","[2021-04-09 11:47:40,515 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:47:44,341 INFO] number of examples: 77471\n","[2021-04-09 11:49:55,519 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:49:59,324 INFO] number of examples: 77471\n","[2021-04-09 11:52:10,444 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:52:14,830 INFO] number of examples: 77471\n","[2021-04-09 11:54:25,998 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:54:29,763 INFO] number of examples: 77471\n","[2021-04-09 11:55:06,403 INFO] Step 6000/30000; acc:  76.96; ppl:  2.42; xent: 0.88; lr: 0.00074; 9539/11988 tok/s;   3800 sec\n","[2021-04-09 11:55:06,404 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 11:55:07,458 INFO] number of examples: 10362\n","[2021-04-09 11:55:24,527 INFO] Validation perplexity: 21.4534\n","[2021-04-09 11:55:24,527 INFO] Validation accuracy: 51.354\n","[2021-04-09 11:55:24,728 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-09 11:57:04,158 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:57:09,365 INFO] number of examples: 77471\n","[2021-04-09 11:59:20,469 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 11:59:24,413 INFO] number of examples: 77471\n","[2021-04-09 12:01:35,475 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:01:39,396 INFO] number of examples: 77471\n","[2021-04-09 12:03:50,570 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:03:54,446 INFO] number of examples: 77471\n","[2021-04-09 12:05:42,056 INFO] Step 7000/30000; acc:  81.02; ppl:  2.07; xent: 0.73; lr: 0.00086; 9601/12073 tok/s;   4436 sec\n","[2021-04-09 12:05:42,058 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:05:42,426 INFO] number of examples: 10362\n","[2021-04-09 12:05:59,484 INFO] Validation perplexity: 23.5479\n","[2021-04-09 12:05:59,484 INFO] Validation accuracy: 51.4652\n","[2021-04-09 12:05:59,707 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-09 12:06:29,467 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:06:33,926 INFO] number of examples: 77471\n","[2021-04-09 12:08:45,137 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:08:48,985 INFO] number of examples: 77471\n","[2021-04-09 12:11:00,216 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:11:03,945 INFO] number of examples: 77471\n","[2021-04-09 12:13:15,173 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:13:19,493 INFO] number of examples: 77471\n","[2021-04-09 12:15:30,789 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:15:35,346 INFO] number of examples: 77471\n","[2021-04-09 12:16:23,901 INFO] Step 8000/30000; acc:  84.08; ppl:  1.85; xent: 0.61; lr: 0.00099; 9511/11943 tok/s;   5077 sec\n","[2021-04-09 12:16:23,902 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:16:24,270 INFO] number of examples: 10362\n","[2021-04-09 12:16:41,346 INFO] Validation perplexity: 25.4631\n","[2021-04-09 12:16:41,346 INFO] Validation accuracy: 51.1539\n","[2021-04-09 12:16:41,548 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-09 12:18:09,024 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:18:12,851 INFO] number of examples: 77471\n","[2021-04-09 12:20:24,010 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:20:28,459 INFO] number of examples: 77471\n","[2021-04-09 12:22:39,545 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:22:43,360 INFO] number of examples: 77471\n","[2021-04-09 12:24:54,501 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:24:58,222 INFO] number of examples: 77471\n","[2021-04-09 12:26:57,570 INFO] Step 9000/30000; acc:  87.39; ppl:  1.65; xent: 0.50; lr: 0.00093; 9617/12102 tok/s;   5711 sec\n","[2021-04-09 12:26:57,571 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:26:58,620 INFO] number of examples: 10362\n","[2021-04-09 12:27:15,692 INFO] Validation perplexity: 25.6702\n","[2021-04-09 12:27:15,693 INFO] Validation accuracy: 52.0189\n","[2021-04-09 12:27:15,889 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-09 12:27:32,089 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:27:37,496 INFO] number of examples: 77471\n","[2021-04-09 12:29:48,903 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:29:52,888 INFO] number of examples: 77471\n","[2021-04-09 12:32:04,063 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:32:07,976 INFO] number of examples: 77471\n","[2021-04-09 12:34:19,125 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:34:23,042 INFO] number of examples: 77471\n","[2021-04-09 12:36:34,265 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:36:37,983 INFO] number of examples: 77471\n","[2021-04-09 12:37:38,475 INFO] Step 10000/30000; acc:  91.15; ppl:  1.47; xent: 0.39; lr: 0.00088; 9534/11967 tok/s;   6352 sec\n","[2021-04-09 12:37:38,477 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:37:39,528 INFO] number of examples: 10362\n","[2021-04-09 12:37:56,601 INFO] Validation perplexity: 28.4424\n","[2021-04-09 12:37:56,601 INFO] Validation accuracy: 52.1164\n","[2021-04-09 12:37:56,828 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-09 12:39:12,232 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:39:17,380 INFO] number of examples: 77471\n","[2021-04-09 12:41:28,679 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:41:32,692 INFO] number of examples: 77471\n","[2021-04-09 12:43:43,922 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:43:47,839 INFO] number of examples: 77471\n","[2021-04-09 12:45:59,107 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:46:02,998 INFO] number of examples: 77471\n","[2021-04-09 12:48:14,201 INFO] Step 11000/30000; acc:  93.33; ppl:  1.37; xent: 0.32; lr: 0.00084; 9579/12049 tok/s;   6988 sec\n","[2021-04-09 12:48:14,203 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:48:14,555 INFO] number of examples: 10362\n","[2021-04-09 12:48:31,625 INFO] Validation perplexity: 29.416\n","[2021-04-09 12:48:31,625 INFO] Validation accuracy: 52.2989\n","[2021-04-09 12:48:31,845 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-09 12:48:36,243 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:48:40,759 INFO] number of examples: 77471\n","[2021-04-09 12:50:52,304 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:50:56,166 INFO] number of examples: 77471\n","[2021-04-09 12:53:07,412 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:53:11,206 INFO] number of examples: 77471\n","[2021-04-09 12:55:22,474 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:55:26,920 INFO] number of examples: 77471\n","[2021-04-09 12:57:38,190 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 12:57:42,032 INFO] number of examples: 77471\n","[2021-04-09 12:58:54,282 INFO] Step 12000/30000; acc:  94.80; ppl:  1.31; xent: 0.27; lr: 0.00081; 9542/11993 tok/s;   7628 sec\n","[2021-04-09 12:58:54,284 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 12:58:54,650 INFO] number of examples: 10362\n","[2021-04-09 12:59:11,731 INFO] Validation perplexity: 29.6161\n","[2021-04-09 12:59:11,731 INFO] Validation accuracy: 52.6925\n","[2021-04-09 12:59:11,948 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-09 13:00:15,674 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:00:20,144 INFO] number of examples: 77471\n","[2021-04-09 13:02:31,421 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:02:35,188 INFO] number of examples: 77471\n","[2021-04-09 13:04:46,391 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:04:50,819 INFO] number of examples: 77471\n","[2021-04-09 13:07:02,039 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:07:05,878 INFO] number of examples: 77471\n","[2021-04-09 13:09:16,971 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:09:20,756 INFO] number of examples: 77471\n","[2021-04-09 13:09:33,572 INFO] Step 13000/30000; acc:  95.84; ppl:  1.27; xent: 0.24; lr: 0.00078; 9534/11985 tok/s;   8267 sec\n","[2021-04-09 13:09:33,574 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:09:34,645 INFO] number of examples: 10362\n","[2021-04-09 13:09:51,718 INFO] Validation perplexity: 30.9006\n","[2021-04-09 13:09:51,719 INFO] Validation accuracy: 52.8315\n","[2021-04-09 13:09:51,946 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-09 13:11:55,392 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:12:00,623 INFO] number of examples: 77471\n","[2021-04-09 13:14:11,886 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:14:15,878 INFO] number of examples: 77471\n","[2021-04-09 13:16:27,135 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:16:31,198 INFO] number of examples: 77471\n","[2021-04-09 13:18:42,415 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:18:46,268 INFO] number of examples: 77471\n","[2021-04-09 13:20:10,500 INFO] Step 14000/30000; acc:  96.59; ppl:  1.23; xent: 0.21; lr: 0.00075; 9591/12046 tok/s;   8904 sec\n","[2021-04-09 13:20:10,501 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:20:10,861 INFO] number of examples: 10362\n","[2021-04-09 13:20:27,938 INFO] Validation perplexity: 33.905\n","[2021-04-09 13:20:27,938 INFO] Validation accuracy: 52.0683\n","[2021-04-09 13:20:28,166 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-09 13:21:20,586 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:21:25,050 INFO] number of examples: 77471\n","[2021-04-09 13:23:36,347 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:23:40,282 INFO] number of examples: 77471\n","[2021-04-09 13:25:51,658 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:25:55,493 INFO] number of examples: 77471\n","[2021-04-09 13:28:06,764 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:28:11,230 INFO] number of examples: 77471\n","[2021-04-09 13:30:22,523 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:30:26,361 INFO] number of examples: 77471\n","[2021-04-09 13:30:51,051 INFO] Step 15000/30000; acc:  97.13; ppl:  1.21; xent: 0.19; lr: 0.00072; 9512/11960 tok/s;   9545 sec\n","[2021-04-09 13:30:51,053 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:30:51,427 INFO] number of examples: 10362\n","[2021-04-09 13:31:08,506 INFO] Validation perplexity: 31.1354\n","[2021-04-09 13:31:08,506 INFO] Validation accuracy: 53.2255\n","[2021-04-09 13:31:08,726 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-09 13:32:59,986 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:33:04,381 INFO] number of examples: 77471\n","[2021-04-09 13:35:15,702 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:35:19,420 INFO] number of examples: 77471\n","[2021-04-09 13:37:30,723 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:37:35,053 INFO] number of examples: 77471\n","[2021-04-09 13:39:46,365 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:39:50,846 INFO] number of examples: 77471\n","[2021-04-09 13:41:26,902 INFO] Step 16000/30000; acc:  97.56; ppl:  1.19; xent: 0.17; lr: 0.00070; 9607/12072 tok/s;  10180 sec\n","[2021-04-09 13:41:26,903 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:41:27,274 INFO] number of examples: 10362\n","[2021-04-09 13:41:44,364 INFO] Validation perplexity: 31.8071\n","[2021-04-09 13:41:44,365 INFO] Validation accuracy: 53.3324\n","[2021-04-09 13:41:44,572 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-09 13:42:24,768 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:42:28,601 INFO] number of examples: 77471\n","[2021-04-09 13:44:39,994 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:44:44,433 INFO] number of examples: 77471\n","[2021-04-09 13:46:55,839 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:46:59,627 INFO] number of examples: 77471\n","[2021-04-09 13:49:11,053 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:49:15,497 INFO] number of examples: 77471\n","[2021-04-09 13:51:26,922 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:51:30,751 INFO] number of examples: 77471\n","[2021-04-09 13:52:07,431 INFO] Step 17000/30000; acc:  97.88; ppl:  1.17; xent: 0.16; lr: 0.00068; 9517/11960 tok/s;  10821 sec\n","[2021-04-09 13:52:07,433 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 13:52:08,527 INFO] number of examples: 10362\n","[2021-04-09 13:52:25,634 INFO] Validation perplexity: 31.8079\n","[2021-04-09 13:52:25,634 INFO] Validation accuracy: 53.5709\n","[2021-04-09 13:52:25,855 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-09 13:54:05,390 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:54:09,506 INFO] number of examples: 77471\n","[2021-04-09 13:56:20,880 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:56:25,277 INFO] number of examples: 77471\n","[2021-04-09 13:58:36,594 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 13:58:40,349 INFO] number of examples: 77471\n","[2021-04-09 14:00:51,543 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:00:55,894 INFO] number of examples: 77471\n","[2021-04-09 14:02:43,574 INFO] Step 18000/30000; acc:  98.13; ppl:  1.16; xent: 0.15; lr: 0.00066; 9594/12064 tok/s;  11457 sec\n","[2021-04-09 14:02:43,575 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:02:43,923 INFO] number of examples: 10362\n","[2021-04-09 14:03:01,029 INFO] Validation perplexity: 34.0259\n","[2021-04-09 14:03:01,029 INFO] Validation accuracy: 52.8311\n","[2021-04-09 14:03:01,250 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-09 14:03:29,322 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:03:33,959 INFO] number of examples: 77471\n","[2021-04-09 14:05:45,291 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:05:49,132 INFO] number of examples: 77471\n","[2021-04-09 14:08:00,445 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:08:04,967 INFO] number of examples: 77471\n","[2021-04-09 14:10:16,163 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:10:19,874 INFO] number of examples: 77471\n","[2021-04-09 14:12:30,366 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:12:34,074 INFO] number of examples: 77471\n","[2021-04-09 14:13:22,338 INFO] Step 19000/30000; acc:  98.35; ppl:  1.14; xent: 0.14; lr: 0.00064; 9557/12001 tok/s;  12096 sec\n","[2021-04-09 14:13:22,340 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:13:22,702 INFO] number of examples: 10362\n","[2021-04-09 14:13:39,580 INFO] Validation perplexity: 34.6099\n","[2021-04-09 14:13:39,580 INFO] Validation accuracy: 52.9384\n","[2021-04-09 14:13:39,779 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-09 14:15:06,689 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:15:10,921 INFO] number of examples: 77471\n","[2021-04-09 14:17:21,396 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:17:25,026 INFO] number of examples: 77471\n","[2021-04-09 14:19:35,354 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:19:39,651 INFO] number of examples: 77471\n","[2021-04-09 14:21:50,123 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:21:53,982 INFO] number of examples: 77471\n","[2021-04-09 14:23:52,589 INFO] Step 20000/30000; acc:  98.52; ppl:  1.13; xent: 0.13; lr: 0.00062; 9670/12168 tok/s;  12726 sec\n","[2021-04-09 14:23:52,590 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:23:52,946 INFO] number of examples: 10362\n","[2021-04-09 14:24:09,820 INFO] Validation perplexity: 33.6627\n","[2021-04-09 14:24:09,820 INFO] Validation accuracy: 53.4753\n","[2021-04-09 14:24:10,020 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-09 14:24:26,025 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:24:30,592 INFO] number of examples: 77471\n","[2021-04-09 14:26:41,150 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:26:45,246 INFO] number of examples: 77471\n","[2021-04-09 14:28:55,637 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:28:59,926 INFO] number of examples: 77471\n","[2021-04-09 14:31:10,351 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:31:14,067 INFO] number of examples: 77471\n","[2021-04-09 14:33:24,460 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:33:28,098 INFO] number of examples: 77471\n","[2021-04-09 14:34:28,225 INFO] Step 21000/30000; acc:  98.65; ppl:  1.13; xent: 0.12; lr: 0.00061; 9613/12067 tok/s;  13362 sec\n","[2021-04-09 14:34:28,226 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:34:29,264 INFO] number of examples: 10362\n","[2021-04-09 14:34:46,151 INFO] Validation perplexity: 34.3751\n","[2021-04-09 14:34:46,151 INFO] Validation accuracy: 53.5572\n","[2021-04-09 14:34:46,360 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-09 14:36:02,782 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:36:06,827 INFO] number of examples: 77471\n","[2021-04-09 14:38:17,225 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:38:21,493 INFO] number of examples: 77471\n","[2021-04-09 14:40:31,895 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:40:35,653 INFO] number of examples: 77471\n","[2021-04-09 14:42:46,008 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:42:49,638 INFO] number of examples: 77471\n","[2021-04-09 14:44:59,998 INFO] Step 22000/30000; acc:  98.76; ppl:  1.12; xent: 0.11; lr: 0.00060; 9639/12125 tok/s;  13993 sec\n","[2021-04-09 14:44:59,999 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:45:01,029 INFO] number of examples: 10362\n","[2021-04-09 14:45:17,901 INFO] Validation perplexity: 34.0508\n","[2021-04-09 14:45:17,901 INFO] Validation accuracy: 53.3915\n","[2021-04-09 14:45:18,105 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-09 14:45:22,529 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:45:26,550 INFO] number of examples: 77471\n","[2021-04-09 14:47:37,236 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:47:41,489 INFO] number of examples: 77471\n","[2021-04-09 14:49:51,864 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:49:55,544 INFO] number of examples: 77471\n","[2021-04-09 14:52:05,837 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:52:09,420 INFO] number of examples: 77471\n","[2021-04-09 14:54:19,685 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:54:23,926 INFO] number of examples: 77471\n","[2021-04-09 14:55:35,592 INFO] Step 23000/30000; acc:  98.86; ppl:  1.11; xent: 0.11; lr: 0.00058; 9609/12078 tok/s;  14629 sec\n","[2021-04-09 14:55:35,593 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 14:55:35,953 INFO] number of examples: 10362\n","[2021-04-09 14:55:52,816 INFO] Validation perplexity: 34.0651\n","[2021-04-09 14:55:52,816 INFO] Validation accuracy: 53.6747\n","[2021-04-09 14:55:53,011 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-09 14:56:56,280 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:57:00,688 INFO] number of examples: 77471\n","[2021-04-09 14:59:10,999 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 14:59:14,822 INFO] number of examples: 77471\n","[2021-04-09 15:01:25,062 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:01:28,807 INFO] number of examples: 77471\n","[2021-04-09 15:03:38,948 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:03:42,581 INFO] number of examples: 77471\n","[2021-04-09 15:05:52,698 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:05:56,327 INFO] number of examples: 77471\n","[2021-04-09 15:06:08,944 INFO] Step 24000/30000; acc:  98.93; ppl:  1.11; xent: 0.10; lr: 0.00057; 9623/12097 tok/s;  15262 sec\n","[2021-04-09 15:06:08,945 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:06:09,973 INFO] number of examples: 10362\n","[2021-04-09 15:06:26,821 INFO] Validation perplexity: 35.5341\n","[2021-04-09 15:06:26,821 INFO] Validation accuracy: 53.5548\n","[2021-04-09 15:06:27,015 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-09 15:08:28,969 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:08:32,961 INFO] number of examples: 77471\n","[2021-04-09 15:10:43,152 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:10:47,387 INFO] number of examples: 77471\n","[2021-04-09 15:12:57,504 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:13:01,148 INFO] number of examples: 77471\n","[2021-04-09 15:15:11,347 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:15:14,911 INFO] number of examples: 77471\n","[2021-04-09 15:16:38,398 INFO] Step 25000/30000; acc:  99.01; ppl:  1.10; xent: 0.10; lr: 0.00056; 9705/12189 tok/s;  15892 sec\n","[2021-04-09 15:16:38,399 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:16:39,378 INFO] number of examples: 10362\n","[2021-04-09 15:16:56,232 INFO] Validation perplexity: 36.1338\n","[2021-04-09 15:16:56,233 INFO] Validation accuracy: 53.5235\n","[2021-04-09 15:16:56,427 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-09 15:17:47,757 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:17:52,572 INFO] number of examples: 77471\n","[2021-04-09 15:20:02,776 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:20:06,566 INFO] number of examples: 77471\n","[2021-04-09 15:22:16,629 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:22:20,323 INFO] number of examples: 77471\n","[2021-04-09 15:24:30,381 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:24:34,078 INFO] number of examples: 77471\n","[2021-04-09 15:26:44,142 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:26:47,815 INFO] number of examples: 77471\n","[2021-04-09 15:27:12,218 INFO] Step 26000/30000; acc:  99.07; ppl:  1.10; xent: 0.09; lr: 0.00055; 9613/12087 tok/s;  16526 sec\n","[2021-04-09 15:27:12,219 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:27:12,557 INFO] number of examples: 10362\n","[2021-04-09 15:27:29,402 INFO] Validation perplexity: 34.8678\n","[2021-04-09 15:27:29,402 INFO] Validation accuracy: 53.6868\n","[2021-04-09 15:27:29,591 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-09 15:29:19,919 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:29:24,141 INFO] number of examples: 77471\n","[2021-04-09 15:31:34,223 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:31:37,838 INFO] number of examples: 77471\n","[2021-04-09 15:33:47,963 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:33:51,613 INFO] number of examples: 77471\n","[2021-04-09 15:36:01,826 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:36:05,887 INFO] number of examples: 77471\n","[2021-04-09 15:37:41,066 INFO] Step 27000/30000; acc:  99.13; ppl:  1.09; xent: 0.09; lr: 0.00054; 9714/12206 tok/s;  17155 sec\n","[2021-04-09 15:37:41,068 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:37:41,408 INFO] number of examples: 10362\n","[2021-04-09 15:37:58,262 INFO] Validation perplexity: 36.7347\n","[2021-04-09 15:37:58,263 INFO] Validation accuracy: 53.444\n","[2021-04-09 15:37:58,466 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-09 15:38:38,043 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:38:42,097 INFO] number of examples: 77471\n","[2021-04-09 15:40:52,164 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:40:56,351 INFO] number of examples: 77471\n","[2021-04-09 15:43:06,464 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:43:10,136 INFO] number of examples: 77471\n","[2021-04-09 15:45:20,210 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:45:23,789 INFO] number of examples: 77471\n","[2021-04-09 15:47:33,903 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:47:38,046 INFO] number of examples: 77471\n","[2021-04-09 15:48:14,274 INFO] Step 28000/30000; acc:  99.17; ppl:  1.09; xent: 0.09; lr: 0.00053; 9627/12098 tok/s;  17788 sec\n","[2021-04-09 15:48:14,275 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:48:14,615 INFO] number of examples: 10362\n","[2021-04-09 15:48:31,458 INFO] Validation perplexity: 36.2651\n","[2021-04-09 15:48:31,458 INFO] Validation accuracy: 53.5587\n","[2021-04-09 15:48:31,648 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-09 15:50:10,026 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:50:14,312 INFO] number of examples: 77471\n","[2021-04-09 15:52:24,269 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:52:28,026 INFO] number of examples: 77471\n","[2021-04-09 15:54:37,923 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:54:41,625 INFO] number of examples: 77471\n","[2021-04-09 15:56:51,394 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:56:55,027 INFO] number of examples: 77471\n","[2021-04-09 15:58:41,512 INFO] Step 29000/30000; acc:  99.22; ppl:  1.09; xent: 0.08; lr: 0.00052; 9730/12235 tok/s;  18415 sec\n","[2021-04-09 15:58:41,514 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 15:58:41,852 INFO] number of examples: 10362\n","[2021-04-09 15:58:58,676 INFO] Validation perplexity: 36.6525\n","[2021-04-09 15:58:58,676 INFO] Validation accuracy: 53.769\n","[2021-04-09 15:58:58,863 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-09 15:59:26,998 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 15:59:31,358 INFO] number of examples: 77471\n","[2021-04-09 16:01:41,244 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:01:44,788 INFO] number of examples: 77471\n","[2021-04-09 16:03:54,607 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:03:58,083 INFO] number of examples: 77471\n","[2021-04-09 16:06:07,960 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:06:12,064 INFO] number of examples: 77471\n","[2021-04-09 16:08:21,874 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-09 16:08:25,344 INFO] number of examples: 77471\n","[2021-04-09 16:09:13,352 INFO] Step 30000/30000; acc:  99.26; ppl:  1.08; xent: 0.08; lr: 0.00051; 9662/12133 tok/s;  19047 sec\n","[2021-04-09 16:09:13,354 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-09 16:09:14,328 INFO] number of examples: 10362\n","[2021-04-09 16:09:31,157 INFO] Validation perplexity: 38.0242\n","[2021-04-09 16:09:31,157 INFO] Validation accuracy: 53.7017\n","[2021-04-09 16:09:31,349 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617984577285,"user_tz":-420,"elapsed":19088793,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"b6bc226a-6842-4414-f4f4-59695045b8fb"},"source":["!ls -al model model/"],"execution_count":23,"outputs":[{"output_type":"stream","text":["model:\n","total 29897985\n","-rw------- 1 root root 1020517439 Apr  9 12:38 en-vi_step_10000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:02 en-vi_step_1000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:48 en-vi_step_11000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:59 en-vi_step_12000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:09 en-vi_step_13000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:20 en-vi_step_14000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:31 en-vi_step_15000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:41 en-vi_step_16000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:52 en-vi_step_17000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:03 en-vi_step_18000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:13 en-vi_step_19000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:24 en-vi_step_20000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:13 en-vi_step_2000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:34 en-vi_step_21000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:45 en-vi_step_22000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:55 en-vi_step_23000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:06 en-vi_step_24000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:17 en-vi_step_25000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:27 en-vi_step_26000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:38 en-vi_step_27000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:48 en-vi_step_28000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:59 en-vi_step_29000.pt\n","-rw------- 1 root root 1020517439 Apr  9 16:09 en-vi_step_30000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:23 en-vi_step_3000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:34 en-vi_step_4000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:44 en-vi_step_5000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:55 en-vi_step_6000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:06 en-vi_step_7000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:16 en-vi_step_8000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:27 en-vi_step_9000.pt\n","\n","model/:\n","total 29897985\n","-rw------- 1 root root 1020517439 Apr  9 12:38 en-vi_step_10000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:02 en-vi_step_1000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:48 en-vi_step_11000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:59 en-vi_step_12000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:09 en-vi_step_13000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:20 en-vi_step_14000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:31 en-vi_step_15000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:41 en-vi_step_16000.pt\n","-rw------- 1 root root 1020517439 Apr  9 13:52 en-vi_step_17000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:03 en-vi_step_18000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:13 en-vi_step_19000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:24 en-vi_step_20000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:13 en-vi_step_2000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:34 en-vi_step_21000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:45 en-vi_step_22000.pt\n","-rw------- 1 root root 1020517439 Apr  9 14:55 en-vi_step_23000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:06 en-vi_step_24000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:17 en-vi_step_25000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:27 en-vi_step_26000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:38 en-vi_step_27000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:48 en-vi_step_28000.pt\n","-rw------- 1 root root 1020517439 Apr  9 15:59 en-vi_step_29000.pt\n","-rw------- 1 root root 1020517439 Apr  9 16:09 en-vi_step_30000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:23 en-vi_step_3000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:34 en-vi_step_4000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:44 en-vi_step_5000.pt\n","-rw------- 1 root root 1020517439 Apr  9 11:55 en-vi_step_6000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:06 en-vi_step_7000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:16 en-vi_step_8000.pt\n","-rw------- 1 root root 1020517439 Apr  9 12:27 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617987466285,"user_tz":-420,"elapsed":21976769,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"e04cd8a1-21ed-4da6-f529-941b415f0bda"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[2021-04-09 16:09:43,294 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-09 16:56:07,222 INFO] PRED AVG SCORE: -0.4450, PRED PPL: 1.5605\n","[2021-04-09 16:56:07,222 INFO] GOLD AVG SCORE: -3.6447, GOLD PPL: 38.2707\n","[2021-04-09 16:56:07,251 INFO] Translating shard 1.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-09 16:57:45,551 INFO] PRED AVG SCORE: -0.4410, PRED PPL: 1.5542\n","[2021-04-09 16:57:45,551 INFO] GOLD AVG SCORE: -3.6346, GOLD PPL: 37.8848\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617987466286,"user_tz":-420,"elapsed":21976015,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"1b25b949-fe68-41f9-9ef2-fcb1104f8ba2"},"source":["!tail vi_test"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Cà vạt thì loè loẹt .\n","và lí do là bởi vì có 2 lí do , theo tôi nghĩ\n","Ông thích nói về thiên tài tâm linh của lứa tuổi .\n","Chúng tôi đều là người Triều Tiên , nhưng đã trở nên rất khác nhau do hậu quả của 67 năm bị chia cắt .\n","Đó là cách bạn xử lý một vấn đề khi bạn nhìn thấy chúng và đó không chỉ là việc than phiền về vấn đề đó .\n","Tham vọng của các bạn được thoã mãn , nó rất đẹp .\n","Không có thứ nào trong những điều trên thực sự hữu ích bởi vì bạn đang điều trị những triệu chứng chứ không phải nguyên nhân của các vấn đề cơ bản ở Phi Châu .\n","Nhưng hiện nay nhiều người sống đến 90 hay 100 tuổi , trừ khi họ bắt tay quá nhiều hay làm những điều đại loại thế .\n","Nhưng quý vị phải có những công cụ đúng .\n","Những điều này là một phần cuộc đời ông và là những gì ông còn nhớ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617987487794,"user_tz":-420,"elapsed":21996584,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"f80a112b-63a7-4677-ad44-822559891358"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 29, done.\u001b[K\n","remote: Counting objects: 100% (29/29), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 17114 (delta 7), reused 8 (delta 4), pack-reused 17085\u001b[K\n","Receiving objects: 100% (17114/17114), 273.05 MiB | 19.04 MiB/s, done.\n","Resolving deltas: 100% (12323/12323), done.\n","Checking out files: 100% (228/228), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617987488270,"user_tz":-420,"elapsed":21996469,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"5e5affed-7c8b-4687-826f-4a4009fe8816"},"source":["!ls -al"],"execution_count":27,"outputs":[{"output_type":"stream","text":["total 95226\n","drwx------  2 root root     4096 Apr  9 10:51 data_bin\n","-rw-------  1 root root   996149 Apr  9 10:08 en_test\n","-rw-------  1 root root  8024744 Apr  9 10:08 en_train\n","-rw-------  1 root root  8654114 Apr  9 10:22 en_train_EM_0.8\n","-rw-------  1 root root  8307178 Apr  9 10:22 en_train_EM_0.85\n","-rw-------  1 root root  8154398 Apr  9 10:22 en_train_EM_0.9\n","-rw-------  1 root root  8069415 Apr  9 10:22 en_train_EM_0.95\n","-rw-------  1 root root  3494604 Apr  9 10:22 en_train_EM_factor_0.8\n","-rw-------  1 root root  3360444 Apr  9 10:22 en_train_EM_factor_0.85\n","-rw-------  1 root root  3300104 Apr  9 10:22 en_train_EM_factor_0.9\n","-rw-------  1 root root  3266074 Apr  9 10:22 en_train_EM_factor_0.95\n","-rw-------  1 root root   857727 Apr  9 10:22 en_train_EM_score_0.8\n","-rw-------  1 root root   857727 Apr  9 10:22 en_train_EM_score_0.85\n","-rw-------  1 root root   857727 Apr  9 10:22 en_train_EM_score_0.9\n","-rw-------  1 root root   857727 Apr  9 10:22 en_train_EM_score_0.95\n","-rw-------  1 root root  1000856 Apr  9 10:08 en_valid\n","-rw-------  1 root root 22918476 Apr  9 10:51 en_vi_iwslt_bert.tar.gz\n","drwx------  2 root root     4096 Apr  9 16:09 model\n","drwx------ 11 root root     4096 Apr  9 16:58 OpenNMT-py\n","drwx------  2 root root     4096 Apr  9 10:51 output\n","-rw-------  1 root root  1181936 Apr  9 16:57 predict.txt\n","-rw-------  1 root root  1327417 Apr  9 10:08 vi_test\n","-rw-------  1 root root 10671354 Apr  9 10:08 vi_train\n","-rw-------  1 root root  1330789 Apr  9 10:08 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617987491000,"user_tz":-420,"elapsed":21998581,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"7503dae0-873b-4cdf-af07-9c7dc588a8ef"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":28,"outputs":[{"output_type":"stream","text":["BLEU = 23.50, 59.6/33.5/19.7/11.8 (BP=0.900, ratio=0.905, hyp_len=220969, ref_len=244219)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1","executionInfo":{"status":"ok","timestamp":1617987491000,"user_tz":-420,"elapsed":21998065,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}}},"source":[""],"execution_count":28,"outputs":[]}]}