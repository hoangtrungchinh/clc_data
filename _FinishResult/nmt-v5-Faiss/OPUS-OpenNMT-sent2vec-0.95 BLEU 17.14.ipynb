{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OPUS-OpenNMT-sent2vec-0.95 BLEU 17.14.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LOhk_Tcumu7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583214290,"user_tz":-420,"elapsed":21049,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"ce5f0bd9-d11c-48e1-9f4d-1c7584a3e83c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42yosgiGoLTC"},"source":["# import os\n","# path = \"\"\n","# path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/'\n","# os.chdir(path)\n","# import time\n","# FOLDERNAME = \"OPUS-OpenNMT-sent2vec-0.9-\" + str(time.strftime(\"%Y%m%d-%H%M\"))\n","# !mkdir $FOLDERNAME\n","\n","# path = path + FOLDERNAME\n","# os.chdir(path)\n","# !pwd\n","\n","import os\n","path = '/content/drive/Shared drives/chinh-share/nmt-v5-Faiss/OPUS-OpenNMT-sent2vec-0.9-20210412-0416'\n","os.chdir(path)\n","!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHu74LOYETUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583220372,"user_tz":-420,"elapsed":908,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"273fb20a-f52d-41d0-fed1-b18248fd57a5"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Wed Apr 28 04:13:38 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xdmPYNIGrNdj"},"source":["## **Install libraries**"]},{"cell_type":"code","metadata":{"id":"r03SCFfjXABE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583244539,"user_tz":-420,"elapsed":17851,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"a8e9a889-b604-4be2-a6f5-d06b82283163"},"source":["!pip install OpenNMT-py==1.2.0\n","!pip install -U scikit-learn"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting OpenNMT-py==1.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/40f8b722aa0e35e259c144b6ec2d684f1aea7de869cf586c67cfd6fe1c55/OpenNMT_py-1.2.0-py3-none-any.whl (195kB)\n","\r\u001b[K     |█▊                              | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 15.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (2.4.1)\n","Collecting pyonmttok==1.*; platform_system == \"Linux\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/67/cd64b4c2fd0a83eb1088e31e0217b612281d014299993424420f933df3e7/pyonmttok-1.26.0-cp37-cp37m-manylinux1_x86_64.whl (14.3MB)\n","\u001b[K     |████████████████████████████████| 14.3MB 386kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (0.16.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.1.2)\n","Collecting configargparse\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c3/17846950db4e11cc2e71b36e5f8b236a7ab2f742f65597f3daf94f0b84b7/ConfigArgParse-1.4.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n","\u001b[?25hCollecting waitress\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cfd6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (3.13)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.8.1+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (4.41.1)\n","Collecting torchtext==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==1.2.0) (1.15.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.28.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.32.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.8.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.0.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.36.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.3.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (3.12.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (56.0.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.4)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (1.19.5)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==1.2.0) (0.12.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (2.11.3)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (7.1.2)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==1.2.0) (1.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==1.2.0) (3.7.4.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (4.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py==1.2.0) (2.10)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.10.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py==1.2.0) (1.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py==1.2.0) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==1.2.0) (3.1.0)\n","Building wheels for collected packages: configargparse\n","  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for configargparse: filename=ConfigArgParse-1.4-cp37-none-any.whl size=19638 sha256=3d576a888b19f4e0ade1720ba88fe090c259c00a197a56229f81d51d93e8a532\n","  Stored in directory: /root/.cache/pip/wheels/d6/61/f7/626bbd080a9f2f70015f92025e0af663c595146083f3d9aa05\n","Successfully built configargparse\n","Installing collected packages: pyonmttok, configargparse, waitress, torchtext, OpenNMT-py\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed OpenNMT-py-1.2.0 configargparse-1.4 pyonmttok-1.26.0 torchtext-0.4.0 waitress-2.0.0\n","Collecting scikit-learn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fFQX3CyRxJPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583248611,"user_tz":-420,"elapsed":8590,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"099c71d4-ac0d-4040-fcab-3f8d3a4984af"},"source":["!wget https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/opus_sent2vec.tar.gz\n","!mkdir data_bin\n","!tar -xvf 'opus_sent2vec.tar.gz'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2021-04-28 04:14:02--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/dataset/opus_sent2vec.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 94255466 (90M) [application/octet-stream]\n","Saving to: ‘opus_sent2vec.tar.gz’\n","\n","opus_sent2vec.tar.g 100%[===================>]  89.89M   125MB/s    in 0.7s    \n","\n","2021-04-28 04:14:04 (125 MB/s) - ‘opus_sent2vec.tar.gz’ saved [94255466/94255466]\n","\n","en_train_EM_score_0.95\n","vi_valid\n","en_train_EM_0.95\n","en_train_EM_factor_0.85\n","en_train_EM_score_0.8\n","vi_train\n","en_train_EM_factor_0.8\n","en_train_EM_0.8\n","en_valid\n","en_train_EM_factor_0.95\n","en_train\n","en_train_EM_score_0.85\n","vi_test\n","en_train_EM_0.85\n","en_train_EM_score_0.9\n","en_test\n","en_train_EM_factor_0.9\n","en_train_EM_0.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LswvFB4cxzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619583309668,"user_tz":-420,"elapsed":60587,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"ada1a6c9-4e1b-4ffd-cfee-8b8bb90d90d6"},"source":["!mkdir -p output\n","!onmt_preprocess -train_src 'en_train_EM_0.95' \\\\\n","-train_tgt 'vi_train' \\\\\n","-valid_src 'en_valid' \\\\\n","-valid_tgt 'vi_valid' \\\\\n","-save_data 'output/en-vi' "],"execution_count":5,"outputs":[{"output_type":"stream","text":["[2021-04-28 04:14:11,336 INFO] Extracting features...\n","[2021-04-28 04:14:11,336 INFO]  * number of source features: 0.\n","[2021-04-28 04:14:11,336 INFO]  * number of target features: 0.\n","[2021-04-28 04:14:11,336 INFO] Building `Fields` object...\n","[2021-04-28 04:14:11,337 INFO] Building & saving training data...\n","[2021-04-28 04:14:12,420 INFO] Building shard 0.\n","[2021-04-28 04:14:43,732 INFO]  * saving 0th train data shard to output/en-vi.train.0.pt.\n","[2021-04-28 04:15:01,052 INFO]  * tgt vocab size: 50004.\n","[2021-04-28 04:15:01,370 INFO]  * src vocab size: 50002.\n","[2021-04-28 04:15:01,998 INFO] Building & saving validation data...\n","[2021-04-28 04:15:02,542 INFO] Building shard 0.\n","[2021-04-28 04:15:04,804 INFO]  * saving 0th valid data shard to output/en-vi.valid.0.pt.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYyQECmi0TX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619608268025,"user_tz":-420,"elapsed":24958356,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"d0df0517-126c-4863-e50d-94838da03479"},"source":["!mkdir -p model\n","!onmt_train -data 'output/en-vi' \\\\\n","-save_model 'model/en-vi' \\\\\n","-layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 \\\\\n","-encoder_type transformer -decoder_type transformer -position_encoding \\\\\n","-train_steps 30000  -max_generator_batches 2 -dropout 0.1 -batch_size 4096 \\\\\n","-batch_type tokens -normalization tokens  -accum_count 2 -optim adam -adam_beta2 0.998 \\\\\n","-decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 \\\\\n","-param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 \\\\\n","-report_every 1000 -world_size 1 -gpu_ranks 0"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[2021-04-28 04:15:12,354 INFO]  * src vocab size = 50002\n","[2021-04-28 04:15:12,354 INFO]  * tgt vocab size = 50004\n","[2021-04-28 04:15:12,354 INFO] Building model...\n","[2021-04-28 04:15:20,421 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50002, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=50004, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-04-28 04:15:20,489 INFO] encoder: 44516352\n","[2021-04-28 04:15:20,489 INFO] decoder: 76479316\n","[2021-04-28 04:15:20,489 INFO] * number of parameters: 120995668\n","[2021-04-28 04:15:20,493 INFO] Starting training on GPU: [0]\n","[2021-04-28 04:15:20,494 INFO] Start training loop and validate every 1000 steps...\n","[2021-04-28 04:15:20,494 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 04:15:38,792 INFO] number of examples: 802833\n","[2021-04-28 04:26:43,355 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 04:27:05,075 INFO] number of examples: 802833\n","[2021-04-28 04:27:44,027 INFO] Step 1000/30000; acc:  13.72; ppl: 551.58; xent: 6.31; lr: 0.00012; 7230/9678 tok/s;    744 sec\n","[2021-04-28 04:27:44,028 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 04:27:45,483 INFO] number of examples: 100400\n","[2021-04-28 04:29:17,960 INFO] Validation perplexity: 257.026\n","[2021-04-28 04:29:17,961 INFO] Validation accuracy: 19.5565\n","[2021-04-28 04:29:19,442 INFO] Saving checkpoint model/en-vi_step_1000.pt\n","[2021-04-28 04:39:55,738 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 04:40:28,058 INFO] number of examples: 802833\n","[2021-04-28 04:41:40,927 INFO] Step 2000/30000; acc:  28.26; ppl: 65.83; xent: 4.19; lr: 0.00025; 6427/8629 tok/s;   1580 sec\n","[2021-04-28 04:41:40,928 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 04:41:42,406 INFO] number of examples: 100400\n","[2021-04-28 04:43:14,447 INFO] Validation perplexity: 52.8732\n","[2021-04-28 04:43:14,447 INFO] Validation accuracy: 36.5581\n","[2021-04-28 04:43:15,913 INFO] Saving checkpoint model/en-vi_step_2000.pt\n","[2021-04-28 04:53:14,423 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 04:53:39,415 INFO] number of examples: 802833\n","[2021-04-28 04:55:24,119 INFO] Step 3000/30000; acc:  39.05; ppl: 25.49; xent: 3.24; lr: 0.00037; 6535/8747 tok/s;   2404 sec\n","[2021-04-28 04:55:24,121 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 04:55:25,608 INFO] number of examples: 100400\n","[2021-04-28 04:56:57,900 INFO] Validation perplexity: 27.4395\n","[2021-04-28 04:56:57,900 INFO] Validation accuracy: 42.8941\n","[2021-04-28 04:56:59,378 INFO] Saving checkpoint model/en-vi_step_3000.pt\n","[2021-04-28 05:06:26,280 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:06:51,976 INFO] number of examples: 802833\n","[2021-04-28 05:09:08,750 INFO] Step 4000/30000; acc:  44.12; ppl: 16.11; xent: 2.78; lr: 0.00049; 6531/8738 tok/s;   3228 sec\n","[2021-04-28 05:09:08,751 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:09:10,248 INFO] number of examples: 100400\n","[2021-04-28 05:10:42,483 INFO] Validation perplexity: 20.6713\n","[2021-04-28 05:10:42,484 INFO] Validation accuracy: 45.8797\n","[2021-04-28 05:10:43,965 INFO] Saving checkpoint model/en-vi_step_4000.pt\n","[2021-04-28 05:19:38,963 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:20:05,293 INFO] number of examples: 802833\n","[2021-04-28 05:22:54,870 INFO] Step 5000/30000; acc:  46.86; ppl: 12.67; xent: 2.54; lr: 0.00062; 6518/8729 tok/s;   4054 sec\n","[2021-04-28 05:22:54,871 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:22:56,360 INFO] number of examples: 100400\n","[2021-04-28 05:24:28,583 INFO] Validation perplexity: 18.2606\n","[2021-04-28 05:24:28,583 INFO] Validation accuracy: 47.0141\n","[2021-04-28 05:24:30,063 INFO] Saving checkpoint model/en-vi_step_5000.pt\n","[2021-04-28 05:32:51,707 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:33:17,564 INFO] number of examples: 802833\n","[2021-04-28 05:36:38,844 INFO] Step 6000/30000; acc:  48.71; ppl: 10.84; xent: 2.38; lr: 0.00074; 6539/8733 tok/s;   4878 sec\n","[2021-04-28 05:36:38,846 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:36:40,383 INFO] number of examples: 100400\n","[2021-04-28 05:38:12,013 INFO] Validation perplexity: 17.3239\n","[2021-04-28 05:38:12,014 INFO] Validation accuracy: 47.5598\n","[2021-04-28 05:38:13,461 INFO] Saving checkpoint model/en-vi_step_6000.pt\n","[2021-04-28 05:46:02,953 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:46:34,277 INFO] number of examples: 802833\n","[2021-04-28 05:50:27,990 INFO] Step 7000/30000; acc:  50.09; ppl:  9.70; xent: 2.27; lr: 0.00086; 6495/8687 tok/s;   5707 sec\n","[2021-04-28 05:50:27,991 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 05:50:29,490 INFO] number of examples: 100400\n","[2021-04-28 05:52:01,193 INFO] Validation perplexity: 16.6793\n","[2021-04-28 05:52:01,194 INFO] Validation accuracy: 48.1235\n","[2021-04-28 05:52:02,644 INFO] Saving checkpoint model/en-vi_step_7000.pt\n","[2021-04-28 05:59:19,581 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 05:59:41,292 INFO] number of examples: 802833\n","[2021-04-28 06:04:12,792 INFO] Step 8000/30000; acc:  51.33; ppl:  8.83; xent: 2.18; lr: 0.00099; 6524/8724 tok/s;   6532 sec\n","[2021-04-28 06:04:12,793 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:04:14,304 INFO] number of examples: 100400\n","[2021-04-28 06:05:45,812 INFO] Validation perplexity: 16.9426\n","[2021-04-28 06:05:45,812 INFO] Validation accuracy: 48.2394\n","[2021-04-28 06:05:47,249 INFO] Saving checkpoint model/en-vi_step_8000.pt\n","[2021-04-28 06:12:31,822 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 06:13:04,834 INFO] number of examples: 802833\n","[2021-04-28 06:18:03,997 INFO] Step 9000/30000; acc:  52.75; ppl:  7.99; xent: 2.08; lr: 0.00093; 6460/8673 tok/s;   7364 sec\n","[2021-04-28 06:18:03,998 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:18:09,753 INFO] number of examples: 100400\n","[2021-04-28 06:19:41,307 INFO] Validation perplexity: 16.0721\n","[2021-04-28 06:19:41,308 INFO] Validation accuracy: 48.7468\n","[2021-04-28 06:19:42,741 INFO] Saving checkpoint model/en-vi_step_9000.pt\n","[2021-04-28 06:25:54,665 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 06:26:21,927 INFO] number of examples: 802833\n","[2021-04-28 06:31:52,549 INFO] Step 10000/30000; acc:  54.75; ppl:  7.05; xent: 1.95; lr: 0.00088; 6487/8690 tok/s;   8192 sec\n","[2021-04-28 06:31:52,550 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:31:54,057 INFO] number of examples: 100400\n","[2021-04-28 06:33:26,030 INFO] Validation perplexity: 15.9913\n","[2021-04-28 06:33:26,031 INFO] Validation accuracy: 49.1602\n","[2021-04-28 06:33:27,524 INFO] Saving checkpoint model/en-vi_step_10000.pt\n","[2021-04-28 06:39:07,929 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 06:39:35,198 INFO] number of examples: 802833\n","[2021-04-28 06:45:38,211 INFO] Step 11000/30000; acc:  56.64; ppl:  6.32; xent: 1.84; lr: 0.00084; 6529/8734 tok/s;   9018 sec\n","[2021-04-28 06:45:38,212 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:45:39,748 INFO] number of examples: 100400\n","[2021-04-28 06:47:11,463 INFO] Validation perplexity: 15.6916\n","[2021-04-28 06:47:11,463 INFO] Validation accuracy: 49.5458\n","[2021-04-28 06:47:12,897 INFO] Saving checkpoint model/en-vi_step_11000.pt\n","[2021-04-28 06:52:19,896 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 06:52:46,862 INFO] number of examples: 802833\n","[2021-04-28 06:59:22,391 INFO] Step 12000/30000; acc:  58.33; ppl:  5.75; xent: 1.75; lr: 0.00081; 6533/8730 tok/s;   9842 sec\n","[2021-04-28 06:59:22,392 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 06:59:23,898 INFO] number of examples: 100400\n","[2021-04-28 07:00:55,478 INFO] Validation perplexity: 16.0673\n","[2021-04-28 07:00:55,478 INFO] Validation accuracy: 49.5551\n","[2021-04-28 07:00:56,966 INFO] Saving checkpoint model/en-vi_step_12000.pt\n","[2021-04-28 07:05:31,793 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:05:58,030 INFO] number of examples: 802833\n","[2021-04-28 07:13:06,738 INFO] Step 13000/30000; acc:  59.86; ppl:  5.30; xent: 1.67; lr: 0.00078; 6532/8741 tok/s;  10666 sec\n","[2021-04-28 07:13:06,739 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:13:14,160 INFO] number of examples: 100400\n","[2021-04-28 07:14:45,761 INFO] Validation perplexity: 15.7318\n","[2021-04-28 07:14:45,761 INFO] Validation accuracy: 50.1078\n","[2021-04-28 07:14:47,179 INFO] Saving checkpoint model/en-vi_step_13000.pt\n","[2021-04-28 07:18:49,029 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:19:23,333 INFO] number of examples: 802833\n","[2021-04-28 07:27:04,495 INFO] Step 14000/30000; acc:  61.29; ppl:  4.92; xent: 1.59; lr: 0.00075; 6435/8590 tok/s;  11504 sec\n","[2021-04-28 07:27:04,496 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:27:06,022 INFO] number of examples: 100400\n","[2021-04-28 07:28:37,478 INFO] Validation perplexity: 16.4969\n","[2021-04-28 07:28:37,478 INFO] Validation accuracy: 50.1062\n","[2021-04-28 07:28:38,973 INFO] Saving checkpoint model/en-vi_step_14000.pt\n","[2021-04-28 07:32:08,716 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:32:36,298 INFO] number of examples: 802833\n","[2021-04-28 07:40:48,782 INFO] Step 15000/30000; acc:  62.55; ppl:  4.62; xent: 1.53; lr: 0.00072; 6540/8730 tok/s;  12328 sec\n","[2021-04-28 07:40:48,783 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:40:50,281 INFO] number of examples: 100400\n","[2021-04-28 07:42:21,880 INFO] Validation perplexity: 16.7866\n","[2021-04-28 07:42:21,880 INFO] Validation accuracy: 50.2906\n","[2021-04-28 07:42:23,295 INFO] Saving checkpoint model/en-vi_step_15000.pt\n","[2021-04-28 07:45:21,119 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:45:47,582 INFO] number of examples: 802833\n","[2021-04-28 07:54:32,108 INFO] Step 16000/30000; acc:  63.78; ppl:  4.35; xent: 1.47; lr: 0.00070; 6537/8748 tok/s;  13152 sec\n","[2021-04-28 07:54:32,109 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 07:54:39,431 INFO] number of examples: 100400\n","[2021-04-28 07:56:10,708 INFO] Validation perplexity: 16.8242\n","[2021-04-28 07:56:10,708 INFO] Validation accuracy: 50.4592\n","[2021-04-28 07:56:12,129 INFO] Saving checkpoint model/en-vi_step_16000.pt\n","[2021-04-28 07:58:37,952 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 07:59:12,280 INFO] number of examples: 802833\n","[2021-04-28 08:08:30,647 INFO] Step 17000/30000; acc:  64.88; ppl:  4.13; xent: 1.42; lr: 0.00068; 6405/8560 tok/s;  13990 sec\n","[2021-04-28 08:08:30,648 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:08:32,154 INFO] number of examples: 100400\n","[2021-04-28 08:10:03,404 INFO] Validation perplexity: 17.9255\n","[2021-04-28 08:10:03,404 INFO] Validation accuracy: 50.0982\n","[2021-04-28 08:10:04,866 INFO] Saving checkpoint model/en-vi_step_17000.pt\n","[2021-04-28 08:11:56,708 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:12:24,502 INFO] number of examples: 802833\n","[2021-04-28 08:22:19,827 INFO] Step 18000/30000; acc:  65.87; ppl:  3.94; xent: 1.37; lr: 0.00066; 6471/8674 tok/s;  14819 sec\n","[2021-04-28 08:22:19,829 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:22:21,483 INFO] number of examples: 100400\n","[2021-04-28 08:23:59,212 INFO] Validation perplexity: 17.9791\n","[2021-04-28 08:23:59,213 INFO] Validation accuracy: 50.529\n","[2021-04-28 08:24:00,919 INFO] Saving checkpoint model/en-vi_step_18000.pt\n","[2021-04-28 08:25:21,752 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:25:53,037 INFO] number of examples: 802833\n","[2021-04-28 08:36:19,475 INFO] Step 19000/30000; acc:  66.81; ppl:  3.77; xent: 1.33; lr: 0.00064; 6410/8557 tok/s;  15659 sec\n","[2021-04-28 08:36:19,476 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:36:21,031 INFO] number of examples: 100400\n","[2021-04-28 08:37:53,687 INFO] Validation perplexity: 18.1272\n","[2021-04-28 08:37:53,687 INFO] Validation accuracy: 50.2517\n","[2021-04-28 08:37:55,173 INFO] Saving checkpoint model/en-vi_step_19000.pt\n","[2021-04-28 08:38:42,341 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:39:04,991 INFO] number of examples: 802833\n","[2021-04-28 08:50:07,946 INFO] Step 20000/30000; acc:  67.70; ppl:  3.62; xent: 1.29; lr: 0.00062; 6488/8678 tok/s;  16487 sec\n","[2021-04-28 08:50:07,947 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 08:50:09,524 INFO] number of examples: 100400\n","[2021-04-28 08:51:41,794 INFO] Validation perplexity: 18.6421\n","[2021-04-28 08:51:41,794 INFO] Validation accuracy: 50.6569\n","[2021-04-28 08:51:43,295 INFO] Saving checkpoint model/en-vi_step_20000.pt\n","[2021-04-28 08:51:58,061 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 08:52:32,593 INFO] number of examples: 802833\n","[2021-04-28 09:03:38,616 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:04:05,395 INFO] number of examples: 802833\n","[2021-04-28 09:04:36,089 INFO] Step 21000/30000; acc:  68.52; ppl:  3.49; xent: 1.25; lr: 0.00061; 6183/8293 tok/s;  17356 sec\n","[2021-04-28 09:04:36,090 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:04:43,663 INFO] number of examples: 100400\n","[2021-04-28 09:06:16,093 INFO] Validation perplexity: 19.0838\n","[2021-04-28 09:06:16,094 INFO] Validation accuracy: 50.5142\n","[2021-04-28 09:06:17,585 INFO] Saving checkpoint model/en-vi_step_21000.pt\n","[2021-04-28 09:16:59,081 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:17:34,402 INFO] number of examples: 802833\n","[2021-04-28 09:18:38,260 INFO] Step 22000/30000; acc:  69.21; ppl:  3.39; xent: 1.22; lr: 0.00060; 6389/8564 tok/s;  18198 sec\n","[2021-04-28 09:18:38,261 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:18:39,802 INFO] number of examples: 100400\n","[2021-04-28 09:20:12,022 INFO] Validation perplexity: 18.7535\n","[2021-04-28 09:20:12,022 INFO] Validation accuracy: 50.5915\n","[2021-04-28 09:20:13,516 INFO] Saving checkpoint model/en-vi_step_22000.pt\n","[2021-04-28 09:30:21,575 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:30:49,831 INFO] number of examples: 802833\n","[2021-04-28 09:32:25,501 INFO] Step 23000/30000; acc:  69.99; ppl:  3.27; xent: 1.19; lr: 0.00058; 6509/8705 tok/s;  19025 sec\n","[2021-04-28 09:32:25,503 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:32:27,077 INFO] number of examples: 100400\n","[2021-04-28 09:34:00,519 INFO] Validation perplexity: 19.4436\n","[2021-04-28 09:34:00,519 INFO] Validation accuracy: 50.6354\n","[2021-04-28 09:34:01,989 INFO] Saving checkpoint model/en-vi_step_23000.pt\n","[2021-04-28 09:43:38,867 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:44:07,267 INFO] number of examples: 802833\n","[2021-04-28 09:46:15,203 INFO] Step 24000/30000; acc:  70.64; ppl:  3.18; xent: 1.16; lr: 0.00057; 6488/8688 tok/s;  19855 sec\n","[2021-04-28 09:46:15,204 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 09:46:16,744 INFO] number of examples: 100400\n","[2021-04-28 09:47:48,737 INFO] Validation perplexity: 20.0611\n","[2021-04-28 09:47:48,738 INFO] Validation accuracy: 50.6331\n","[2021-04-28 09:47:50,207 INFO] Saving checkpoint model/en-vi_step_24000.pt\n","[2021-04-28 09:56:53,700 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 09:57:21,869 INFO] number of examples: 802833\n","[2021-04-28 10:00:02,821 INFO] Step 25000/30000; acc:  71.35; ppl:  3.09; xent: 1.13; lr: 0.00056; 6504/8710 tok/s;  20682 sec\n","[2021-04-28 10:00:02,822 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 10:00:04,381 INFO] number of examples: 100400\n","[2021-04-28 10:01:37,218 INFO] Validation perplexity: 20.2577\n","[2021-04-28 10:01:37,219 INFO] Validation accuracy: 50.6577\n","[2021-04-28 10:01:38,781 INFO] Saving checkpoint model/en-vi_step_25000.pt\n","[2021-04-28 10:10:10,238 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 10:10:38,551 INFO] number of examples: 802833\n","[2021-04-28 10:13:51,767 INFO] Step 26000/30000; acc:  71.94; ppl:  3.01; xent: 1.10; lr: 0.00055; 6498/8692 tok/s;  21511 sec\n","[2021-04-28 10:13:51,768 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 10:13:53,285 INFO] number of examples: 100400\n","[2021-04-28 10:15:25,511 INFO] Validation perplexity: 20.7809\n","[2021-04-28 10:15:25,511 INFO] Validation accuracy: 50.5636\n","[2021-04-28 10:15:27,087 INFO] Saving checkpoint model/en-vi_step_26000.pt\n","[2021-04-28 10:23:25,235 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 10:23:54,399 INFO] number of examples: 802833\n","[2021-04-28 10:27:40,293 INFO] Step 27000/30000; acc:  72.58; ppl:  2.93; xent: 1.08; lr: 0.00054; 6512/8688 tok/s;  22340 sec\n","[2021-04-28 10:27:40,294 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 10:27:41,854 INFO] number of examples: 100400\n","[2021-04-28 10:29:14,319 INFO] Validation perplexity: 21.428\n","[2021-04-28 10:29:14,319 INFO] Validation accuracy: 50.6676\n","[2021-04-28 10:29:15,850 INFO] Saving checkpoint model/en-vi_step_27000.pt\n","[2021-04-28 10:36:43,945 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 10:37:06,375 INFO] number of examples: 802833\n","[2021-04-28 10:41:24,056 INFO] Step 28000/30000; acc:  73.11; ppl:  2.87; xent: 1.05; lr: 0.00053; 6519/8739 tok/s;  23164 sec\n","[2021-04-28 10:41:24,057 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 10:41:31,388 INFO] number of examples: 100400\n","[2021-04-28 10:43:03,258 INFO] Validation perplexity: 21.4699\n","[2021-04-28 10:43:03,258 INFO] Validation accuracy: 50.4956\n","[2021-04-28 10:43:04,720 INFO] Saving checkpoint model/en-vi_step_28000.pt\n","[2021-04-28 10:49:58,705 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 10:50:32,684 INFO] number of examples: 802833\n","[2021-04-28 10:55:23,426 INFO] Step 29000/30000; acc:  73.58; ppl:  2.81; xent: 1.03; lr: 0.00052; 6399/8583 tok/s;  24003 sec\n","[2021-04-28 10:55:23,428 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 10:55:30,961 INFO] number of examples: 100400\n","[2021-04-28 10:57:03,024 INFO] Validation perplexity: 21.333\n","[2021-04-28 10:57:03,024 INFO] Validation accuracy: 50.6587\n","[2021-04-28 10:57:04,478 INFO] Saving checkpoint model/en-vi_step_29000.pt\n","[2021-04-28 11:03:25,595 INFO] Loading dataset from output/en-vi.train.0.pt\n","[2021-04-28 11:04:00,795 INFO] number of examples: 802833\n","[2021-04-28 11:09:22,605 INFO] Step 30000/30000; acc:  74.09; ppl:  2.76; xent: 1.01; lr: 0.00051; 6407/8582 tok/s;  24842 sec\n","[2021-04-28 11:09:22,606 INFO] Loading dataset from output/en-vi.valid.0.pt\n","[2021-04-28 11:09:24,121 INFO] number of examples: 100400\n","[2021-04-28 11:10:56,041 INFO] Validation perplexity: 21.8044\n","[2021-04-28 11:10:56,041 INFO] Validation accuracy: 50.6442\n","[2021-04-28 11:10:57,494 INFO] Saving checkpoint model/en-vi_step_30000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1XOEz-j6IbNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619608268026,"user_tz":-420,"elapsed":24958355,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"0646771f-9e32-436d-9232-ee900ffda0f7"},"source":["!ls -al model model/"],"execution_count":7,"outputs":[{"output_type":"stream","text":["model:\n","total 43398008\n","drwxr-xr-x 2 root root       4096 Apr 28 11:10 .\n","drwxr-xr-x 1 root root       4096 Apr 28 04:15 ..\n","-rw-r--r-- 1 root root 1481313023 Apr 28 06:33 en-vi_step_10000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 04:29 en-vi_step_1000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 06:47 en-vi_step_11000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:01 en-vi_step_12000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:14 en-vi_step_13000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:28 en-vi_step_14000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:42 en-vi_step_15000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:56 en-vi_step_16000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 08:10 en-vi_step_17000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 08:24 en-vi_step_18000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 08:38 en-vi_step_19000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 08:51 en-vi_step_20000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 04:43 en-vi_step_2000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 09:06 en-vi_step_21000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 09:20 en-vi_step_22000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 09:34 en-vi_step_23000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 09:47 en-vi_step_24000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:01 en-vi_step_25000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:15 en-vi_step_26000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:29 en-vi_step_27000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:43 en-vi_step_28000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:57 en-vi_step_29000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 11:11 en-vi_step_30000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 04:57 en-vi_step_3000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 05:10 en-vi_step_4000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 05:24 en-vi_step_5000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 05:38 en-vi_step_6000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 05:52 en-vi_step_7000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 06:05 en-vi_step_8000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 06:19 en-vi_step_9000.pt\n","\n","model/:\n","total 43398008\n","drwxr-xr-x 2 root root       4096 Apr 28 11:10 .\n","drwxr-xr-x 1 root root       4096 Apr 28 04:15 ..\n","-rw-r--r-- 1 root root 1481313023 Apr 28 06:33 en-vi_step_10000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 04:29 en-vi_step_1000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 06:47 en-vi_step_11000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:01 en-vi_step_12000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:14 en-vi_step_13000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:28 en-vi_step_14000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:42 en-vi_step_15000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 07:56 en-vi_step_16000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 08:10 en-vi_step_17000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 08:24 en-vi_step_18000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 08:38 en-vi_step_19000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 08:51 en-vi_step_20000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 04:43 en-vi_step_2000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 09:06 en-vi_step_21000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 09:20 en-vi_step_22000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 09:34 en-vi_step_23000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 09:47 en-vi_step_24000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:01 en-vi_step_25000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:15 en-vi_step_26000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:29 en-vi_step_27000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:43 en-vi_step_28000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 10:57 en-vi_step_29000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 11:11 en-vi_step_30000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 04:57 en-vi_step_3000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 05:10 en-vi_step_4000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 05:24 en-vi_step_5000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 05:38 en-vi_step_6000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 05:52 en-vi_step_7000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 06:05 en-vi_step_8000.pt\n","-rw-r--r-- 1 root root 1481313023 Apr 28 06:19 en-vi_step_9000.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1S26AN4rHUAH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619619788950,"user_tz":-420,"elapsed":36479277,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"175b5c7e-a8a5-495b-d048-17ddaeb7d11b"},"source":["!onmt_translate -model model/en-vi_step_30000.pt -src en_test -tgt vi_test -output predict.txt"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[2021-04-28 11:11:13,252 INFO] Translating shard 0.\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [30, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:209: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [10, 5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n","  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n","[2021-04-28 11:29:54,355 INFO] PRED AVG SCORE: -0.6518, PRED PPL: 1.9190\n","[2021-04-28 11:29:54,355 INFO] GOLD AVG SCORE: -3.0834, GOLD PPL: 21.8329\n","[2021-04-28 11:29:54,383 INFO] Translating shard 1.\n","tcmalloc: large alloc 1518125056 bytes == 0x561ee0674000 @  0x7ff107faab6b 0x7ff107fca379 0x7ff0b470325e 0x7ff0b47049d2 0x7ff0f13e78e6 0x7ff0f1849dd9 0x7ff0f1d5477a 0x7ff0f1d1fef9 0x7ff0f1cd6657 0x7ff0f1b7a929 0x7ff0f1692516 0x7ff0f1d557af 0x7ff0f1b04846 0x7ff0f1b09e6f 0x7ff0f33edbcc 0x7ff0f33ee13f 0x7ff0f1f56a86 0x7ff0f1f5acaf 0x7ff0f168416a 0x7ff0f1684b3a 0x7ff0f1e697f8 0x7ff0f1e6983f 0x7ff0f1b04846 0x7ff0f1b0a22f 0x7ff0f16680b1 0x7ff0f1e684c0 0x7ff0f1e8b05d 0x7ff0f1c5ba59 0x7ff1031798de 0x561e6421f050 0x561e6421ede0\n","tcmalloc: large alloc 1518125056 bytes == 0x561f3ae40000 @  0x7ff107faab6b 0x7ff107fca379 0x7ff0b470325e 0x7ff0b47049d2 0x7ff0f13e78e6 0x7ff0f1849dd9 0x7ff0f1d5477a 0x7ff0f1d1fef9 0x7ff0f1cd6657 0x7ff0f1b7a929 0x7ff0f18536a2 0x7ff0f17e35c5 0x7ff0f1d55573 0x7ff0f1cc5904 0x7ff0f1b2ff09 0x7ff0f3377444 0x7ff0f3377783 0x7ff0f1cc5904 0x7ff0f1b2ff09 0x7ff0f17dc5d0 0x7ff0f1e690e0 0x7ff0f1e69132 0x7ff0f1cd3054 0x7ff0f1f77735 0x7ff102ed6f4f 0x561e6421f050 0x561e6431099d 0x561e64292fe9 0x561e6428db0e 0x561e6422077a 0x561e6428f86a\n","[2021-04-28 11:48:30,502 INFO] PRED AVG SCORE: -0.6549, PRED PPL: 1.9249\n","[2021-04-28 11:48:30,502 INFO] GOLD AVG SCORE: -3.0886, GOLD PPL: 21.9464\n","[2021-04-28 11:48:30,532 INFO] Translating shard 2.\n","[2021-04-28 12:07:58,034 INFO] PRED AVG SCORE: -0.6531, PRED PPL: 1.9214\n","[2021-04-28 12:07:58,034 INFO] GOLD AVG SCORE: -3.0842, GOLD PPL: 21.8506\n","[2021-04-28 12:07:58,054 INFO] Translating shard 3.\n","[2021-04-28 12:26:57,007 INFO] PRED AVG SCORE: -0.6508, PRED PPL: 1.9171\n","[2021-04-28 12:26:57,007 INFO] GOLD AVG SCORE: -3.0690, GOLD PPL: 21.5194\n","[2021-04-28 12:26:57,030 INFO] Translating shard 4.\n","[2021-04-28 12:46:26,800 INFO] PRED AVG SCORE: -0.6525, PRED PPL: 1.9203\n","[2021-04-28 12:46:26,800 INFO] GOLD AVG SCORE: -3.0873, GOLD PPL: 21.9173\n","[2021-04-28 12:46:26,832 INFO] Translating shard 5.\n","[2021-04-28 13:06:08,223 INFO] PRED AVG SCORE: -0.6514, PRED PPL: 1.9182\n","[2021-04-28 13:06:08,223 INFO] GOLD AVG SCORE: -3.0744, GOLD PPL: 21.6374\n","[2021-04-28 13:06:08,246 INFO] Translating shard 6.\n","[2021-04-28 13:25:28,938 INFO] PRED AVG SCORE: -0.6515, PRED PPL: 1.9185\n","[2021-04-28 13:25:28,938 INFO] GOLD AVG SCORE: -3.0585, GOLD PPL: 21.2946\n","[2021-04-28 13:25:28,960 INFO] Translating shard 7.\n","[2021-04-28 13:44:36,812 INFO] PRED AVG SCORE: -0.6510, PRED PPL: 1.9175\n","[2021-04-28 13:44:36,813 INFO] GOLD AVG SCORE: -3.0421, GOLD PPL: 20.9495\n","[2021-04-28 13:44:36,836 INFO] Translating shard 8.\n","[2021-04-28 14:03:18,090 INFO] PRED AVG SCORE: -0.6568, PRED PPL: 1.9286\n","[2021-04-28 14:03:18,090 INFO] GOLD AVG SCORE: -3.0880, GOLD PPL: 21.9321\n","[2021-04-28 14:03:18,112 INFO] Translating shard 9.\n","[2021-04-28 14:22:20,428 INFO] PRED AVG SCORE: -0.6568, PRED PPL: 1.9286\n","[2021-04-28 14:22:20,429 INFO] GOLD AVG SCORE: -3.0751, GOLD PPL: 21.6514\n","[2021-04-28 14:22:20,449 INFO] Translating shard 10.\n","[2021-04-28 14:23:07,367 INFO] PRED AVG SCORE: -0.6630, PRED PPL: 1.9407\n","[2021-04-28 14:23:07,367 INFO] GOLD AVG SCORE: -2.9156, GOLD PPL: 18.4590\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kPGsYFs_XpAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619619788951,"user_tz":-420,"elapsed":36479277,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"1a23ac5c-1e23-460a-f22d-caf6cca21d93"},"source":["!tail vi_test"],"execution_count":9,"outputs":[{"output_type":"stream","text":["And nobody questions him, because they don't want to hear the answer because it's a lie!\n","Kubo?\n","Họ rất vui vẻ, và lúc nào cũng hát với nến.\n","Nghe này, anh không thể nói chuyện bây giờ được.\n","Vậy thì con có thể dùng trí tưởng tượng của mình.\n","Không hề.\n","Tôi đang nhìn hắn ngay lúc này đây.\n","Bác không để tâm chứ?\n","Anh nghĩ cậu ta phản ứng với thuốc?\n","Bị làm sao mà anh lại đi dự lễ đặt tên em bé của Cuddy chứ?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rf5W-T8MzRK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619619802400,"user_tz":-420,"elapsed":36492724,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"73eaa199-fd65-4586-e2ef-29afa368dadf"},"source":["!git clone https://github.com/OpenNMT/OpenNMT-py.git"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cloning into 'OpenNMT-py'...\n","remote: Enumerating objects: 17287, done.\u001b[K\n","remote: Counting objects: 100% (243/243), done.\u001b[K\n","remote: Compressing objects: 100% (165/165), done.\u001b[K\n","remote: Total 17287 (delta 146), reused 132 (delta 76), pack-reused 17044\u001b[K\n","Receiving objects: 100% (17287/17287), 273.53 MiB | 38.91 MiB/s, done.\n","Resolving deltas: 100% (12446/12446), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iw_Gma2gz0PK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619619802400,"user_tz":-420,"elapsed":36492723,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"c154dff6-3352-4708-accc-f17e739fa667"},"source":["!ls -al"],"execution_count":11,"outputs":[{"output_type":"stream","text":["total 355556\n","drwxr-xr-x  1 root root     4096 Apr 28 14:23 .\n","drwxr-xr-x  1 root root     4096 Apr 28 04:11 ..\n","drwxr-xr-x  4 root root     4096 Apr 21 13:38 .config\n","drwxr-xr-x  2 root root     4096 Apr 28 04:14 data_bin\n","drwx------  6 root root     4096 Apr 28 04:13 drive\n","-rw-rw-r--  1 1000 1000  3318349 Apr 12 02:53 en_test\n","-rw-rw-r--  1 1000 1000 26563375 Apr 12 02:53 en_train\n","-rw-rw-r--  1 1000 1000 31608088 Apr 12 03:46 en_train_EM_0.8\n","-rw-rw-r--  1 1000 1000 29845474 Apr 12 03:46 en_train_EM_0.85\n","-rw-rw-r--  1 1000 1000 28377219 Apr 12 03:46 en_train_EM_0.9\n","-rw-rw-r--  1 1000 1000 27245135 Apr 12 03:46 en_train_EM_0.95\n","-rw-rw-r--  1 1000 1000 11930822 Apr 12 03:46 en_train_EM_factor_0.8\n","-rw-rw-r--  1 1000 1000 11270762 Apr 12 03:46 en_train_EM_factor_0.85\n","-rw-rw-r--  1 1000 1000 10719696 Apr 12 03:46 en_train_EM_factor_0.9\n","-rw-rw-r--  1 1000 1000 10293086 Apr 12 03:46 en_train_EM_factor_0.95\n","-rw-rw-r--  1 1000 1000  6897191 Apr 12 03:46 en_train_EM_score_0.8\n","-rw-rw-r--  1 1000 1000  6897191 Apr 12 03:46 en_train_EM_score_0.85\n","-rw-rw-r--  1 1000 1000  6897191 Apr 12 03:46 en_train_EM_score_0.9\n","-rw-rw-r--  1 1000 1000  6897191 Apr 12 03:46 en_train_EM_score_0.95\n","-rw-rw-r--  1 1000 1000  3328557 Apr 12 02:53 en_valid\n","drwxr-xr-x  2 root root     4096 Apr 28 11:10 model\n","drwxr-xr-x 11 root root     4096 Apr 28 14:23 OpenNMT-py\n","-rw-r--r--  1 root root 94255466 Apr 28 04:14 opus_sent2vec.tar.gz\n","drwxr-xr-x  2 root root     4096 Apr 28 04:15 output\n","-rw-r--r--  1 root root  3904407 Apr 28 14:23 predict.txt\n","drwxr-xr-x  1 root root     4096 Apr 21 13:39 sample_data\n","-rw-rw-r--  1 1000 1000  4365722 Apr 12 02:53 vi_test\n","-rw-rw-r--  1 1000 1000 35019161 Apr 12 02:53 vi_train\n","-rw-rw-r--  1 1000 1000  4382771 Apr 12 02:53 vi_valid\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7T7xCaDdR469","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619619809487,"user_tz":-420,"elapsed":36499807,"user":{"displayName":"Chinh hoang trung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64","userId":"05604119531382760831"}},"outputId":"2e4e3b17-3494-4787-80b6-a42036ebcc59"},"source":["!perl OpenNMT-py/tools/multi-bleu.perl vi_test < predict.txt"],"execution_count":12,"outputs":[{"output_type":"stream","text":["BLEU = 17.14, 41.4/23.1/14.3/9.6 (BP=0.902, ratio=0.907, hyp_len=687646, ref_len=758454)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLGJCSK_Qih1"},"source":[""],"execution_count":null,"outputs":[]}]}